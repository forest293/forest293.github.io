[{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"The chapter briefly illustrates the mechanics of using these commands in the context of a complex survey","date":"2024-01-16","objectID":"/19.chapter19complex-survey-data/","tags":["Interaction","stata"],"title":"Chapter19 ：Complex survey data","uri":"/19.chapter19complex-survey-data/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"The chapter briefly illustrates the mechanics of using these commands in the context of a complex survey The example dataset used in this chapter is the nhanes2.dta dataset. This is one of the Stata example datasets and is used via the Internet with the webuse command, shown below. webuse nhanes2 svyset The svyset command has already been used to declare the design for this survey, naming the primary sampling unit, the person weight, and the strata. Sampling weights: finalwgt\rVCE: linearized\rSingle unit: missing\rStrata 1: strata\rSampling unit 1: psu\rFPC 1: \u003czero\u003e\rLet’s now perform a regression analysis using this dataset. Let’s predict systolic blood pressure from the person’s age (in six age groups), sex, and weight. We use the svy prefix before the regress command to account for the survey design as specified by the svyset command. svy:regress bpsystol i.agegrp i.sex c.weight Survey: Linear regression\rNumber of strata = 31 Number of obs = 10,351\rNumber of PSUs = 62 Population size = 117,157,513\rDesign df = 31\rF(7, 25) = 328.16\rProb \u003e F = 0.0000\rR-squared = 0.3087\r------------------------------------------------------------------------------\r| Linearized\rbpsystol | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\ragegrp |\r30–39 | 1.20 0.57 2.11 0.043 0.04 2.37\r40–49 | 6.88 0.72 9.57 0.000 5.41 8.35\r50–59 | 16.04 0.71 22.44 0.000 14.58 17.49\r60–69 | 23.38 0.77 30.26 0.000 21.81 24.96\r70+ | 30.28 0.90 33.83 0.000 28.46 32.11\r|\rsex |\rFemale | -0.65 0.54 -1.20 0.239 -1.75 0.45\rweight | 0.43 0.02 24.85 0.000 0.39 0.46\r_cons | 88.07 1.32 66.49 0.000 85.36 90.77\r------------------------------------------------------------------------------\rWe can use the contrast, pwcompare, margins, and marginsplot commands to interpret these results. The use of these commands is briefly illustrated below. The contrast command can be used to make comparisons among the groups formed by a factor variable. The contrast command below tests the equality of the adjusted means for the six age groups. The test shows that the average systolic blood pressure is not equal among the six age groups. contrast agegrp Contrasts of marginal linear predictions\rDesign df = 31\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\ragegrp | 5 297.86 0.0000\rDesign | 31\r------------------------------------------------\rNote: F statistics are adjusted for the survey\rdesign.\rThe output of the contrast command indicates the $F$ test is adjusted for the survey design. If you wanted to omit the adjustment for the design degrees of freedom, youcould add the nosvyadjust option, as shown below. (See [R] contrast for more details about this option.) contrast agegrp,nosvyadjust Contrasts of marginal linear predictions\rDesign df = 31\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\ragegrp | 5 341.99 0.0000\r|\rDesign | 31\r------------------------------------------------\rThe pwcompare command can also be used to form pairwise comparisons among the different age groups. In the example below, the mcompare(sidak) option is included to adjust for multiple comparisons. pwcompare agegrp,pveffects mcompare(sidak) Pairwise comparisons of marginal linear predictions\rDesign df = 31\rMargins: asbalanced\r---------------------------\r| Number of\r| comparisons\r-------------+-------------\ragegrp | 15\r---------------------------\r--------------------------------------------------------\r| Sidak\r| Contrast Std. err. t P\u003e|t|\r----------------+---------------------------------------\ragegrp |\r30–39 vs 20–29 | 1.20 0.57 2.11 0.482\r40–49 vs 20–29 | 6.88 0.72 9.57 0.000\r50–59 vs 20–29 | 16.04 0.71 22.44 0.000\r60–69 vs 20–29 | 23.38 0.77 30.26 0.000\r70+ vs 20–29 | 30.28 0.90 33.83 0.000\r40–49 vs 30–39 | 5.68 0.65 8.76 0.000\r50–59 vs 30–39 | 14.83 0.76 19.51 0.000\r60–69 vs 30–39 | 22.","date":"2024-01-16","objectID":"/19.chapter19complex-survey-data/:0:0","tags":["Interaction","stata"],"title":"Chapter19 ：Complex survey data","uri":"/19.chapter19complex-survey-data/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"The chapter begins with a discussion of logistic regression models(most detailed)","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"The chapter begins with a discussion of logistic regression models(most detailed) ","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:0:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Binary logistic regression ","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:1:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 A logistic model with one categorical predictor Let’s consider a simple logistic regression model that predicts whether a person smokes (smoke) by the person’s self-reported social class (class). The variable class is a categorical variable that is coded: 1 = lower class, 2 = working class, 3 = middle class, and 4 = upper class. logit smoke i.class,nolog Logistic regression Number of obs = 15,464\rLR chi2(3) = 198.45\rProb \u003e chi2 = 0.0000\rLog likelihood = -9904.5707 Pseudo R2 = 0.0099\r--------------------------------------------------------------------------------\rsmoke | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rclass |\rworking class | -0.32 0.07 -4.37 0.000 -0.46 -0.18\rmiddle class | -0.72 0.07 -9.80 0.000 -0.86 -0.58\rupper class | -0.92 0.12 -7.54 0.000 -1.16 -0.68\r|\r_cons | -0.13 0.07 -1.85 0.064 -0.26 0.01\r--------------------------------------------------------------------------------\rWe can interpret and visualize the results of this model using the contrast, pwcompare, margins, and marginsplot commands, as described in the following sections. 1.1.1 Using the contrast command If we want to test the overall equality of the four social class groups in terms of their log odds of smoking. logit smoke i.class,nolog Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rclass | 3 196.71 0.0000\r------------------------------------------------\rWe can also apply contrast operators to form specific comparisons among the levels of the social class. contrast ar.class,nowald pveffects //(adjacent (previous) level) Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rclass |\r(working class vs lower class) | -0.32 0.07 -4.37 0.000\r(middle class vs working class) | -0.40 0.04 -11.26 0.000\r(upper class vs middle class) | -0.20 0.10 -1.92 0.055\r-------------------------------------------------------------------------\rThis test shows that the four social class groups are not all equal in terms of their log odds of smoking We can add the or option to the contrast command to display the results as odds ratios. contrast ar.class,nowald pveffects or Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| Odds ratio Std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rclass |\r(working class vs lower class) | 0.73 0.05 -4.37 0.000\r(middle class vs working class) | 0.67 0.02 -11.26 0.000\r(upper class vs middle class) | 0.82 0.09 -1.92 0.055\r-------------------------------------------------------------------------\rthe results can now be interpreted using odds ratios. For example, the odds of smoking for a person who identifies as middle class is 0.669 times the odds of smoking for someone who identifies as working class. 1.1.2 Using the pwcompare command We can also use the pwcompare command to form comparisons among the levels of the social class. Like the contrast command, these comparisons are made in the logodds metric. pwcompare class,pveffects Pairwise comparisons of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------------\r| Unadjusted\r| Contrast Std. err. z P\u003e|z|\r-------------------------------+---------------------------------------\rsmoke |\rclass |\rworking class vs lower class | -0.32 0.07 -4.37 0.000\rmiddle class vs lower class | -0.72 0.07 -9.80 0.000\rupper class vs lower class | -0.92 0.12 -7.54 0.000\rmiddle class vs working class | -0.40 0.04 -11.26 0.000\rupper class vs working class | -0.60 0.10 -5.80 0.000\rupper class vs middle class | -0.20 0.10 -1.92 0.055\r----","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:1:1","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 A logistic model with one continuous predictor Let’s now briefly consider a model with one continuous predictor, predicting whether a person smokes (smoke) from his or her education level. use gss_ivrm.dta logit smoke educ,nolog Logistic regression Number of obs = 16,332\rLR chi2(1) = 174.04\rProb \u003e chi2 = 0.0000\rLog likelihood = -10483.854 Pseudo R2 = 0.0082\r------------------------------------------------------------------------------\rsmoke | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\reduc | -0.07 0.01 -13.10 0.000 -0.08 -0.06\r_cons | 0.22 0.07 3.36 0.001 0.09 0.35\r------------------------------------------------------------------------------\rLet’s use the margins and marginsplot commands to visualize the relationship between education and the log odds of smoking. (Note the inclusion of the predict(xb) option on the margins command to specify the use of the log-odds metric.) margins,at(educ=(5(1)20))predict(xb) Adjusted predictions Number of obs = 16,332\rModel VCE: OIM\rExpression: Linear prediction (log odds), predict(xb)\r1._at: educ = 5\r2._at: educ = 6\r3._at: educ = 7\r4._at: educ = 8\r5._at: educ = 9\r6._at: educ = 10\r7._at: educ = 11\r8._at: educ = 12\r9._at: educ = 13\r10._at: educ = 14\r11._at: educ = 15\r12._at: educ = 16\r13._at: educ = 17\r14._at: educ = 18\r15._at: educ = 19\r16._at: educ = 20\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\r_at |\r1 | -0.12 0.04 -2.95 0.003 -0.20 -0.04\r2 | -0.19 0.04 -5.22 0.000 -0.26 -0.12\r3 | -0.26 0.03 -8.13 0.000 -0.32 -0.20\r4 | -0.33 0.03 -11.91 0.000 -0.38 -0.27\r5 | -0.40 0.02 -16.84 0.000 -0.44 -0.35\r6 | -0.46 0.02 -23.09 0.000 -0.50 -0.42\r7 | -0.53 0.02 -30.20 0.000 -0.57 -0.50\r8 | -0.60 0.02 -36.37 0.000 -0.63 -0.57\r9 | -0.67 0.02 -39.31 0.000 -0.70 -0.64\r10 | -0.74 0.02 -38.80 0.000 -0.78 -0.70\r11 | -0.81 0.02 -36.50 0.000 -0.85 -0.76\r12 | -0.88 0.03 -33.82 0.000 -0.93 -0.82\r13 | -0.94 0.03 -31.36 0.000 -1.00 -0.88\r14 | -1.01 0.03 -29.27 0.000 -1.08 -0.94\r15 | -1.08 0.04 -27.52 0.000 -1.16 -1.00\r16 | -1.15 0.04 -26.08 0.000 -1.24 -1.06\r------------------------------------------------------------------------------\rmarginsplot Note how the relationship between education and the log odds of smoking is linear. For every additional year of education, the log odds of smoking decreases by 0.07. Log odds of smoking by education level\rLet’s now visualize this relationship in terms of the probability of smoking. margins,at(educ=(5(1)20)) Adjusted predictions Number of obs = 16,332\rModel VCE: OIM\rExpression: Pr(smoke), predict()\r1._at: educ = 5\r2._at: educ = 6\r3._at: educ = 7\r4._at: educ = 8\r5._at: educ = 9\r6._at: educ = 10\r7._at: educ = 11\r8._at: educ = 12\r9._at: educ = 13\r10._at: educ = 14\r11._at: educ = 15\r12._at: educ = 16\r13._at: educ = 17\r14._at: educ = 18\r15._at: educ = 19\r16._at: educ = 20\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\r_at |\r1 | 0.47 0.01 45.90 0.000 0.45 0.49\r2 | 0.45 0.01 50.26 0.000 0.44 0.47\r3 | 0.44 0.01 55.77 0.000 0.42 0.45\r4 | 0.42 0.01 62.72 0.000 0.41 0.43\r5 | 0.40 0.01 71.30 0.000 0.39 0.41\r6 | 0.39 0.00 81.08 0.000 0.38 0.40\r7 | 0.37 0.00 90.01 0.000 0.36 0.38\r8 | 0.35 0.00 93.68 0.000 0.35 0.36\r9 | 0.34 0.00 88.76 0.000 0.33 0.35\r10 | 0.32 0.00 77.69 0.000 0.32 0.33\r11 | 0.31 0.00 65.44 0.000 0.30 0.32\r12 | 0.29 0.01 54.74 0.000 0.28 0.30\r13 | 0.28 0.01 46.16 0.000 0.27 0.29\r14 | 0.27 0.01 39.41 0.000 0.25 0.28\r15 | 0.25 0.01 34.10 0.000 0.24 0.27\r16 | 0.24 0.01 29.87 0.000 0.22 0.26\r------------------------------------------------------------------------------\rmarginsplot Predicted probability of smoking by education level\r","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:1:2","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 A logistic model with covariates Let’s add some covariates to this model, predicting smoking from class as well as education, age, and year of interview logit smoke i.class educ age yrint,nolog Logistic regression Number of obs = 15,375\rLR chi2(6) = 742.33\rProb \u003e chi2 = 0.0000\rLog likelihood = -9580.0723 Pseudo R2 = 0.0373\r--------------------------------------------------------------------------------\rsmoke | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rclass |\rworking class | -0.26 0.07 -3.47 0.001 -0.41 -0.11\rmiddle class | -0.46 0.08 -5.89 0.000 -0.61 -0.30\rupper class | -0.52 0.13 -4.11 0.000 -0.77 -0.27\r|\reduc | -0.09 0.01 -13.88 0.000 -0.10 -0.08\rage | -0.02 0.00 -18.12 0.000 -0.02 -0.02\ryrint | -0.03 0.00 -9.48 0.000 -0.04 -0.03\r_cons | 65.46 6.72 9.74 0.000 52.29 78.63\r--------------------------------------------------------------------------------\rcontrast class //test the overall effect of class Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rclass | 3 49.68 0.0000\r------------------------------------------------\rWe can use the margins command to help us interpret this effect by computing the predictive margins of the probability of smoking by class, as shown below. margins class,nopvalues Predictive margins Number of obs = 15,375\rModel VCE: OIM\rExpression: Pr(smoke), predict()\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\rclass |\rlower class | 0.43 0.02 0.39 0.46\rworking class | 0.37 0.01 0.36 0.38\rmiddle class | 0.32 0.01 0.31 0.34\rupper class | 0.31 0.02 0.27 0.35\r----------------------------------------------------------------\rWe can use marginsplot command to graph these predictive margins marginsplot,xlabel(,angle(45)) The predictive marginal probability of smoking by class(adding covariance)\rIn the predicted probability metric, the size of the effect of a variable can (and will) vary as a function of the value of the covariates. By comparison, in the logit metric (like any linear model), the size of the effect of a variable remains constant regardless of the values of the covariate. Let’s explore this point by using the contrast command to estimate the effect of class. contrast ar.class,nowald pveffects //Compare each level of class with the previous level of class Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rclass |\r(working class vs lower class) | -0.26 0.07 -3.47 0.001\r(middle class vs working class) | -0.19 0.04 -5.14 0.000\r(upper class vs middle class) | -0.07 0.11 -0.64 0.523\r-------------------------------------------------------------------------\rThese differences are computed and expressed in the log-odds metric, the natural (linear) metric for the model. The magnitude of these group differences and their significance would remain constant at any level of the covariates. Let’s form these same comparisons but instead using the margins command, forming the comparisons using the predicted probability metric. margins ar.class,contrast(nowald pveffects) Contrasts of predictive margins Number of obs = 15,375\rModel VCE: OIM\rExpression: Pr(smoke), predict()\r-------------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rclass |\r(working class vs lower class) | -0.06 0.02 -3.41 0.001\r(middle class vs working class) | -0.04 0.01 -5.14 0.000\r(upper class vs middle class) | -0.01 0.02 -0.65 0.519\r--------------------------------------------------","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:1:3","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Multinomial logistic regression Let’s now consider a multinomial logistic regression model, focusing on how the commands contrast, pwcompare, margins, and marginsplot can be used after fitting such a model. Let’s model this happiness rating as a function of gender, class, education, and year of interview. The mlogit command chooses the most frequent outcome (which was the second outcome, pretty happy) as the base outcome. use gss_ivrm.dta mlogit haprate i.gender i.class educ yrint,nolog Multinomial logistic regression Number of obs = 48,409\rLR chi2(12) = 2076.07\rProb \u003e chi2 = 0.0000\rLog likelihood = -44799.143 Pseudo R2 = 0.0226\r--------------------------------------------------------------------------------\rhaprate | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rnot_too_happy |\rgender |\rFemale | 0.02 0.03 0.67 0.502 -0.04 0.08\r|\rclass |\rworking class | -0.99 0.05 -20.60 0.000 -1.08 -0.90\rmiddle class | -1.19 0.05 -23.33 0.000 -1.29 -1.09\rupper class | -0.89 0.10 -8.65 0.000 -1.09 -0.69\r|\reduc | -0.08 0.00 -16.13 0.000 -0.09 -0.07\ryrint | 0.00 0.00 2.55 0.011 0.00 0.01\r_cons | -6.38 2.65 -2.41 0.016 -11.59 -1.18\r---------------+----------------------------------------------------------------\rpretty_happy | (base outcome)\r---------------+----------------------------------------------------------------\rvery_happy |\rgender |\rFemale | 0.07 0.02 3.47 0.001 0.03 0.11\r|\rclass |\rworking class | 0.33 0.06 5.82 0.000 0.22 0.44\rmiddle class | 0.74 0.06 12.91 0.000 0.63 0.85\rupper class | 1.18 0.08 15.25 0.000 1.03 1.33\r|\reduc | -0.00 0.00 -0.04 0.966 -0.01 0.01\ryrint | -0.01 0.00 -6.59 0.000 -0.01 -0.00\r_cons | 11.27 1.88 5.99 0.000 7.58 14.96\r--------------------------------------------------------------------------------\rI find it hard to interpret the model using the coefficients. I find it far easier to interpret the results using the contrast, pwcompare, margins, and marginsplot commands. We can use the contrast command to obtain the overall effect of class. By default, this test is performed for the first equation (that is, for outcome 1, not too happy). This test is significant. contrast class Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rnot_too_ha~y |\rclass | 3 558.71 0.0000\r------------------------------------------------\rAdding the equation(3) option performs the contrast with respect to the third outcome (that is, very happy). This test is also significant. contrast class,equation(3) Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rvery_happy |\rclass | 3 564.26 0.0000\r------------------------------------------------\rThe atequations option can be used to apply the contrast command with respect to all the equations. The output of this command matches what we saw in the previous two contrast commands. contrast class,atequations Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rnot_too_ha~y |\rclass | 3 558.71 0.0000\r-------------+----------------------------------\rpretty_happy |\rclass | (omitted)\r-------------+----------------------------------\rvery_happy |\rclass | 3 564.26 0.0000\r------------------------------------------------\rWe can use contrast operators with the contrast command to make specific comparisons among groups. In the example below, the ar. contrast operator is used to compare adjacent levels of class for the third equation. I also included the rrr option to interpret the results in terms of relative-risk ratios. Each of these contrasts is significant. contrast ar.class,equation(3) nowald pveffects rrr Contrasts of marginal linear predictions\rMargins: a","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:2:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Ordinal logistic regression Let’s use the variable haprate from the previous section as the outcome but now model it using an ordinal logistic regression. Let’s use the ologit command to model the three-level variable haprate (1 = not too happy, 2 = pretty happy, and 3 = very happy) as a function of gender, class, education, and year of interview. use gss_ivrm.dta ologit haprate i.gender i.class educ yrint,nolog Ordered logistic regression Number of obs = 48,409\rLR chi2(6) = 1799.46\rProb \u003e chi2 = 0.0000\rLog likelihood = -44937.445 Pseudo R2 = 0.0196\r--------------------------------------------------------------------------------\rhaprate | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rgender |\rFemale | 0.06 0.02 3.34 0.001 0.02 0.10\r|\rclass |\rworking class | 0.96 0.04 23.15 0.000 0.88 1.04\rmiddle class | 1.36 0.04 32.12 0.000 1.28 1.44\rupper class | 1.66 0.06 25.75 0.000 1.54 1.79\r|\reduc | 0.03 0.00 10.55 0.000 0.03 0.04\ryrint | -0.01 0.00 -7.84 0.000 -0.01 -0.00\r---------------+----------------------------------------------------------------\r/cut1 | -13.41 1.65 -16.64 -10.19\r/cut2 | -10.60 1.65 -13.82 -7.37\r--------------------------------------------------------------------------------\rI will bypass interpreting the coefficients and briefly illustrate the use of the contrast, pwcompare, margins, and marginsplot commands. First, let’s consider the contrast command. The contrast command below tests the overall effect of class. contrast class //test the overall effect of class Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rhaprate |\rclass | 3 1286.31 0.0000\r------------------------------------------------\rWe can further dissect the overall effect of class through the use of contrast operators. The contrast command below uses the ar. contrast operator to compare each level of class with the previous level. contrast ar.class,nowald pveffects eform //Compare each level of class with the previous level. Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| exp(b) Std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rhaprate |\rclass |\r(working class vs lower class) | 2.61 0.11 23.15 0.000\r(middle class vs working class) | 1.50 0.03 20.95 0.000\r(upper class vs middle class) | 1.35 0.07 5.86 0.000\r-------------------------------------------------------------------------\rThe exponentiated coefficients can be very abstract. Instead, let’s compute the predictive marginal probability of being very happy (the third response) as a function of self-identified social class. The predictive marginal probability of rating oneself as very happy was 43.7% for those identifying themselves as upper class. margins class,predict(pr outcome(3)) Predictive margins Number of obs = 48,409\rModel VCE: OIM\rExpression: Pr(haprate==3), predict(pr outcome(3))\r--------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rclass |\rlower class | 0.13 0.00 28.33 0.000 0.12 0.14\rworking class | 0.28 0.00 97.08 0.000 0.27 0.28\rmiddle class | 0.37 0.00 115.21 0.000 0.36 0.37\rupper class | 0.44 0.01 35.61 0.000 0.41 0.46\r--------------------------------------------------------------------------------\rBy applying the ar. contrast operator, we can obtain comparisons among the adjacent levels of social class. margins ar.class,predict(pr outcome(3)) contrast(pveffects nowald) //Comparisons among the adjacent levels of social class. Contrasts of predictive margins Number of obs = 48,409\rModel VCE: OIM\rExpression: Pr(haprate==3), predict(pr outcome(3))\r---------------------------------","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:3:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Poisson regression Let’s now briefly consider a Poisson model, showing the use of the contrast, pwcompare, margins, and marginsplot commands following the use of the poisson command. Let’s fit a model predicting the number of children a person has from gender, class, education, and year of interview use gss_ivrm.dta poisson children i.gender i.class educ yrint Iteration 0: Log likelihood = -95914.71 Iteration 1: Log likelihood = -95914.709 Poisson regression Number of obs = 51,417\rLR chi2(6) = 5773.21\rProb \u003e chi2 = 0.0000\rLog likelihood = -95914.709 Pseudo R2 = 0.0292\r--------------------------------------------------------------------------------\rchildren | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rgender |\rFemale | 0.13 0.01 20.47 0.000 0.12 0.14\r|\rclass |\rworking class | -0.09 0.01 -7.18 0.000 -0.12 -0.07\rmiddle class | -0.05 0.01 -3.58 0.000 -0.07 -0.02\rupper class | 0.06 0.02 2.87 0.004 0.02 0.10\r|\reduc | -0.07 0.00 -68.73 0.000 -0.07 -0.07\ryrint | -0.00 0.00 -3.75 0.000 -0.00 -0.00\r_cons | 3.68 0.58 6.38 0.000 2.55 4.82\r--------------------------------------------------------------------------------\rAs we have seen before, the contrast command can be used to test the overall effect of class. Contrasts of marginal linear predictions Margins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rclass | 3 129.31 0.0000\r------------------------------------------------\rThe ar. contrast operator is used to compare adjacent levels of class, comparing each class with the previous class. contrast ar.class,nowald pveffects //compare the adjacent levels of class,comparing each class with the previous class Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r---------------------------------+---------------------------------------\rclass |\r(working class vs lower class) | -0.09 0.01 -7.18 0.000\r(middle class vs working class) | 0.05 0.01 6.69 0.000\r(upper class vs middle class) | 0.11 0.02 6.00 0.000\r-------------------------------------------------------------------------\rWe can use the pwcompare command to form pairwise comparisons among the four class groups. pwcompare class,pveffects Pairwise comparisons of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------------\r| Unadjusted\r| Contrast Std. err. z P\u003e|z|\r-------------------------------+---------------------------------------\rchildren |\rclass |\rworking class vs lower class | -0.09 0.01 -7.18 0.000\rmiddle class vs lower class | -0.05 0.01 -3.58 0.000\rupper class vs lower class | 0.06 0.02 2.87 0.004\rmiddle class vs working class | 0.05 0.01 6.69 0.000\rupper class vs working class | 0.15 0.02 8.48 0.000\rupper class vs middle class | 0.11 0.02 6.00 0.000\r-----------------------------------------------------------------------\rWhen using the margins command, the default is to compute the predicted number of events. The margins command below computes the predicted number of children by class. margins class,nopvalues //compute the predicted number of children class Predictive margins Number of obs = 51,417\rModel VCE: OIM\rExpression: Predicted number of events, predict()\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\rclass |\rlower class | 2.08 0.03 2.03 2.12\rworking class | 1.89 0.01 1.87 1.91\rmiddle class | 1.98 0.01 1.96 2.00\rupper class | 2.21 0.04 2.13 2.28\r----------------------------------------------------------------\rThe margins command is used to compute the predicted number of children for those with 5 to 18 years of education. margins,at(educ=(5(1)18)) marginsplot Predictive margins Number of obs = 51,417\rMod","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:4:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 More applications of nonlinear models ","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:5:0","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5.1 Categorical by categorical interaction This section illustrates a categorical by categorical interaction using a logistic regression. For this example, let’s use the variable fepol as the outcome variable. The respondent was asked if they believed that women are not suited for politics. The variable fepol is coded: 1 = yes and 0 = no. Thus using fepol as our outcome, we will model endorsement of the statement as a function of two categorical predictors: gender (gender) and a three-level measure of education (educ3). This analysis is restricted to interviews conducted between 1972 and 1980. use gss_ivrm keep if yrint \u003c= 1980 logit fepol i.educ3##gender age,nolog Logistic regression Number of obs = 5,014\rLR chi2(6) = 310.52\rProb \u003e chi2 = 0.0000\rLog likelihood = -3313.7435 Pseudo R2 = 0.0448\r------------------------------------------------------------------------------\rfepol | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\reduc3 |\rHS | -0.23 0.10 -2.26 0.024 -0.43 -0.03\rColl | -0.65 0.13 -4.99 0.000 -0.91 -0.40\r|\rgender |\rFemale | 0.19 0.10 1.94 0.052 -0.00 0.39\r|\reduc3#gender |\rHS#Female | -0.14 0.13 -1.06 0.287 -0.39 0.12\rColl#Female | -0.57 0.19 -2.97 0.003 -0.95 -0.20\r|\rage | 0.02 0.00 11.48 0.000 0.02 0.02\r_cons | -0.84 0.12 -6.99 0.000 -1.07 -0.60\r------------------------------------------------------------------------------\rThe contrast command is used to test the overall interaction of educ3 by gender. contrast educ3#gender //test the overall interaction of educ3 by gender Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\reduc3#gender | 2 8.85 0.0120\r------------------------------------------------\rTo help understand this interaction, let’s use the margins command to estimate the log odds of believing that women are not suited for politics by educ3 and gender. Then, let’s make a graph of these predicted logits using the marginsplot command. margins educ3#gender,nopvalues predict(xb) Predictive margins Number of obs = 5,014\rModel VCE: OIM\rExpression: Linear prediction (log odds), predict(xb)\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\reduc3#gender |\rnot hs#Male | 0.07 0.08 -0.08 0.22\rnot hs#Female | 0.27 0.07 0.14 0.40\rHS#Male | -0.16 0.06 -0.28 -0.03\rHS#Female | -0.10 0.05 -0.20 0.00\rColl#Male | -0.58 0.11 -0.79 -0.37\rColl#Female | -0.96 0.13 -1.21 -0.71\r----------------------------------------------------------------\rmarginsplot,legend(subtitle(Gender)) Predicted log odds of believing women are not suited for politics by gender and education\rAlthough the log-odds metric is not easy to interpret, we can still glean the trends implied by the gender by education interaction. The graph suggests that the log odds of agreeing with this statement declines with increasing education, and that this decline appears to be stronger for females than for males. test by interaction gender with comparisons of adjacent education levels，test partial interaction by applying the ar.contrast operator to educ3 and interacting that with gender. contrast ar.educ3#gender Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------\r| df chi2 P\u003echi2\r------------------------+----------------------------------\reduc3#gender |\r(HS vs not hs) (joint) | 1 1.13 0.2874\r(Coll vs HS) (joint) | 1 5.60 0.0180\rJoint | 2 8.85 0.0120\r-----------------------------------------------------------\rLet’s now assess the gender difference at each level of education. We can do this by testing the simple effect of gender at each level of education using the contrast command below. contrast gender@educ3 Contrasts of marginal linear predictions\rMargins: asbalanced\r----","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:5:1","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5.2 Categorical by continuous interaction This section illustrates a categorical by continuous interaction using a binary logistic regression. The outcome for this example is the variable fepres, which is coded: 1 = would vote for a woman president and 0 = would not vote for a woman president. Let’s model this as a function of time (that is, year of interview) and education to see if the linear change in this attitude over time differed by education level. With respect to the year of interview, this question was asked in 17 different years ranging from 1972 to 1998, then it was asked again in 2008 and 2010. Because of the large 10-year gap between 1998 and 2008, we will omit the data for 2008 onward. With respect to education, let’s use the three-level categorical variable educ3, which is coded: 1 = non–high school graduate, 2 = high school graduate, and 3 = college graduate. use gss_ivrm.dta drop if yrint\u003e=2008 logit fepres i.yrint72##educ3 age gender Let’s begin by assessing the trend in the log odds of the outcome across years.we first fit a model using fepres as the outcome predicted by i.yrint72##educ3 as well as age and gender. logit fepres i.yrint72##educ3 age gender Iteration 0: Log likelihood = -9680.7297 Iteration 1: Log likelihood = -8870.722 Iteration 2: Log likelihood = -8766.7906 Iteration 3: Log likelihood = -8765.9168 Iteration 4: Log likelihood = -8765.9147 Iteration 5: Log likelihood = -8765.9147 Logistic regression Number of obs = 23,926\rLR chi2(52) = 1829.63\rProb \u003e chi2 = 0.0000\rLog likelihood = -8765.9147 Pseudo R2 = 0.0945\r-------------------------------------------------------------------------------\rfepres | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r--------------+----------------------------------------------------------------\ryrint72 |\r2 | 0.17 0.14 1.25 0.211 -0.10 0.43\r3 | 0.13 0.13 0.95 0.340 -0.13 0.39\r5 | 0.09 0.13 0.70 0.486 -0.17 0.35\r6 | 0.13 0.14 0.96 0.339 -0.14 0.40\r10 | 0.54 0.14 3.99 0.000 0.28 0.81\r11 | 0.72 0.15 4.67 0.000 0.42 1.02\r13 | 0.23 0.14 1.58 0.114 -0.05 0.51\r14 | 0.60 0.15 3.94 0.000 0.30 0.89\r16 | 0.68 0.18 3.75 0.000 0.33 1.04\r17 | 0.31 0.18 1.70 0.089 -0.05 0.67\r18 | 0.51 0.20 2.50 0.012 0.11 0.91\r19 | 0.89 0.20 4.35 0.000 0.49 1.29\r21 | 0.98 0.21 4.58 0.000 0.56 1.39\r22 | 1.17 0.18 6.36 0.000 0.81 1.52\r24 | 1.10 0.19 5.92 0.000 0.73 1.46\r26 | 1.16 0.19 6.02 0.000 0.78 1.54\r|\reduc3 |\rHS | 0.05 0.13 0.43 0.666 -0.19 0.30\rColl | 0.85 0.24 3.60 0.000 0.39 1.31\r|\ryrint72#educ3 |\r2#HS | 0.44 0.19 2.27 0.023 0.06 0.81\r2#Coll | -0.05 0.33 -0.15 0.884 -0.70 0.60\r3#HS | 0.46 0.19 2.41 0.016 0.08 0.83\r3#Coll | 0.22 0.35 0.63 0.529 -0.47 0.91\r5#HS | 0.36 0.19 1.95 0.051 -0.00 0.73\r5#Coll | 0.53 0.36 1.47 0.142 -0.18 1.23\r6#HS | 0.59 0.19 3.08 0.002 0.22 0.97\r6#Coll | 0.19 0.34 0.55 0.582 -0.48 0.86\r10#HS | 0.61 0.19 3.12 0.002 0.23 0.99\r10#Coll | 0.06 0.35 0.16 0.870 -0.62 0.74\r11#HS | 0.20 0.21 0.97 0.330 -0.20 0.61\r11#Coll | -0.16 0.34 -0.47 0.641 -0.83 0.51\r13#HS | 0.48 0.20 2.45 0.014 0.10 0.86\r13#Coll | 0.31 0.34 0.91 0.365 -0.36 0.99\r14#HS | 0.34 0.21 1.63 0.104 -0.07 0.75\r14#Coll | 0.54 0.39 1.39 0.163 -0.22 1.31\r16#HS | 0.45 0.25 1.78 0.075 -0.04 0.93\r16#Coll | 0.39 0.43 0.89 0.372 -0.46 1.23\r17#HS | 0.83 0.25 3.36 0.001 0.34 1.31\r17#Coll | 0.41 0.41 1.02 0.309 -0.38 1.21\r18#HS | 0.88 0.27 3.20 0.001 0.34 1.41\r18#Coll | 0.78 0.44 1.76 0.078 -0.09 1.64\r19#HS | 0.54 0.27 2.00 0.045 0.01 1.08\r19#Coll | 0.51 0.47 1.09 0.274 -0.41 1.43\r21#HS | 0.39 0.27 1.42 0.156 -0.15 0.92\r21#Coll | 0.31 0.43 0.72 0.470 -0.54 1.16\r22#HS | 0.40 0.23 1.70 0.089 -0.06 0.86\r22#Coll | 0.04 0.35 0.11 0.909 -0.65 0.73\r24#HS | 0.61 0.24 2.53 0.011 0.14 1.08\r24#Coll | 0.58 0.39 1.49 0.137 -0.18 1.34\r26#HS | 0.70 0.25 2.77 0.006 0.21 1.19\r26#Coll | 0.53 0.40 1.32 0.186 -0.25 1.31\r|\rage | -0.03 0.00 -23.33 0.000 -0.03 -0.02\rgender | -0.02 0.04 -0.50 0.617 -0.10 0.06\r_cons | 2.19 0.12 17.85 0.000 1.95 2.43\r-------------------------------------------------------------------------------\rWe then use t","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:5:2","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5.3 Piecewise modeling This section illustrates modeling a continuous predictor fit using piecewise modeling in the context of a logistic regression model. Let’s begin by inspecting the nature of the relationship between education and smoking status. we first fit a model predicting smoking status from education, treating education as a categorical variable. Age is also included in the model as a covariate. The output of the logit command is omitted to save space. use gss_ivrm.dta logit smoke i.educ age // treating education as a categorical variable. Iteration 0: Log likelihood = -10539.7 Iteration 1: Log likelihood = -10121.92 Iteration 2: Log likelihood = -10117.862 Iteration 3: Log likelihood = -10117.858 Iteration 4: Log likelihood = -10117.858 Logistic regression Number of obs = 16,274\rLR chi2(21) = 843.69\rProb \u003e chi2 = 0.0000\rLog likelihood = -10117.858 Pseudo R2 = 0.0400\r------------------------------------------------------------------------------\rsmoke | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\reduc |\r1 | 0.05 0.66 0.08 0.940 -1.24 1.34\r2 | -0.33 0.57 -0.58 0.563 -1.44 0.78\r3 | 0.63 0.42 1.49 0.136 -0.20 1.46\r4 | -0.05 0.41 -0.11 0.912 -0.85 0.76\r5 | 0.16 0.40 0.39 0.694 -0.63 0.94\r6 | -0.08 0.39 -0.22 0.828 -0.84 0.67\r7 | 0.05 0.38 0.12 0.901 -0.69 0.79\r8 | -0.01 0.36 -0.03 0.975 -0.73 0.70\r9 | 0.35 0.37 0.95 0.342 -0.37 1.07\r10 | 0.44 0.37 1.21 0.227 -0.27 1.16\r11 | 0.35 0.36 0.97 0.333 -0.36 1.07\r12 | -0.17 0.36 -0.47 0.639 -0.88 0.54\r13 | -0.36 0.36 -0.97 0.330 -1.07 0.36\r14 | -0.40 0.36 -1.09 0.276 -1.11 0.32\r15 | -0.43 0.37 -1.15 0.248 -1.15 0.30\r16 | -0.84 0.36 -2.31 0.021 -1.56 -0.13\r17 | -1.16 0.38 -3.06 0.002 -1.91 -0.42\r18 | -1.14 0.38 -3.00 0.003 -1.88 -0.39\r19 | -0.86 0.40 -2.15 0.032 -1.65 -0.08\r20 | -0.93 0.39 -2.36 0.018 -1.70 -0.16\r|\rage | -0.02 0.00 -18.58 0.000 -0.02 -0.02\r_cons | 0.49 0.37 1.33 0.185 -0.23 1.20\r------------------------------------------------------------------------------\rLet’s now make a graph that shows the predicted logit of smoking as a function of education, adjusting for age. margins educ,predict(xb) marginsplot,xline(12 16) Log odds of smoking by education\rThe graph in figure above includes vertical lines at 12 and 16 years of education. These junctures seem like excellent candidates for the placement of knots where there is a change in slope and a change in intercept. Let’s fit such a model below mkspline edprehsm 12 edhsm 16 edcom = educ,marginal logit smoke c.edprehsm c.edhsm c.edcom hsgrad cograd age,nolog Logistic regression Number of obs = 16,274\rLR chi2(6) = 806.95\rProb \u003e chi2 = 0.0000\rLog likelihood = -10136.225 Pseudo R2 = 0.0383\r------------------------------------------------------------------------------\rsmoke | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\redprehsm | 0.05 0.01 3.68 0.000 0.03 0.08\redhsm | -0.16 0.03 -5.83 0.000 -0.21 -0.10\redcom | 0.06 0.04 1.40 0.161 -0.02 0.14\rhsgrad | -0.60 0.06 -9.60 0.000 -0.72 -0.48\rcograd | -0.30 0.10 -3.18 0.001 -0.49 -0.12\rage | -0.02 0.00 -19.10 0.000 -0.02 -0.02\r_cons | 0.27 0.15 1.76 0.078 -0.03 0.57\r------------------------------------------------------------------------------\rBefore interpreting the results, let’s create a graph of the predicted log odds of smoking as a function of education. margins,at(edprehsm=0 edhsm=0 edcom=0 hsgrad=0 cograd=0) /// at(edprehsm=12 edhsm=0 edcom=0 hsgrad=0 cograd=0) /// at(edprehsm=12 edhsm=0 edcom=0 hsgrad=1 cograd=0) /// at(edprehsm=16 edhsm=4 edcom=0 hsgrad=1 cograd=0) /// at(edprehsm=16 edhsm=4 edcom=0 hsgrad=1 cograd=1) /// at(edprehsm=20 edhsm=8 edcom=4 hsgrad=1 cograd=1) /// predict(xb) noatlegend mat yhat = r(b)' mat educ = (0 \\ 12 \\ 12 \\ 16 \\ 16\\ 20) svmat yhat svmat educ graph twoway line yhat1 educ1,xline(12 16) title(\"Piecewise Model\") Predicted log odds of smoking from education fit using a piecew","date":"2024-01-15","objectID":"/18.chapter18nonlinear-models/:5:3","tags":["Interaction","stata"],"title":"Chapter18 ：Nonlinear models","uri":"/18.chapter18nonlinear-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models where time is treated as a categorical variable","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models where time is treated as a categorical variable The models presented in this chapter will use the mixed command to fit a model that is a hybrid of a traditional repeated-measures analysis of variance (ANOVA) and a mixed model. Like the repeated-measures ANOVA, there will be one fixed intercept (rather than having random intercepts that we commonly see when using the mixed command). By specifying the noconstant option in the random-effects portion of the mixed command, a fixed intercept will be estimated. To account for the nonindependence of residuals across time points, we will use the residuals() option within the random-effects portion of the mixed command. This allows us to model the structure of the residual covariances across time points. The following examples will use an unstructured residual covariance, which estimates a separate residual variance for each time point and a separate residual correlation among each pair of the time points. ","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:0:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Example 1: Time treated as a categorical variable Sleep was measured at three time points, the first a control (baseline) condition and the second and third measurements while taking a sleep medication. here are two aims of this study. The first aim is to assess the initial impact of sleep medication on duration of sleep.So the second aim is to the assess the sustained effectiveness of the medication on sleep, comparing the amount of sleep in the second and third months use sleep_cat3.dta summarize Note! Wide and long datasets Data for this kind of study might be stored with one observation per person and three variables representing the different time points. Sometimes, this is called a multivariate format, and Stata would call this a wide format. If your dataset is in that kind of form, you can use the reshape command to convert it to a long format. Let’s now use the mixed command to predict sleep from month, treating month as a categorical variable. Specifying || id: introduces the random-effects part of the model and indicates that the observations are nested within id. Next, the noconstant option is specified in the random-effects options so only one fixed intercept is fit. Furthermore, the residuals() option is included to specify covariance structure of the residuals between months (within each level of the person’s ID). The residuals() option specifies an unstructured residual covariance among the different months within each person. This accounts for the nonindependence of the observations among time points for each person. mixed sleep i.month || id:,noconstant residuals(unstructured,t(month))nolog Mixed-effects ML regression Number of obs = 300\rGroup variable: id Number of groups = 100\rObs per group:\rmin = 3\ravg = 3.0\rmax = 3\rWald chi2(2) = 35.94\rLog likelihood = -1437.3712 Prob \u003e chi2 = 0.0000\r------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\rmonth |\r2 | 21.07 3.83 5.50 0.000 13.56 28.58\r3 | 18.43 3.81 4.84 0.000 10.97 25.89\r|\r_cons | 348.24 3.14 110.73 0.000 342.08 354.40\r------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: (empty) |\r-----------------------------+------------------------------------------------\rResidual: Unstructured |\rvar(e1) | 989.04 139.87 749.61 1304.95\rvar(e2) | 928.55 131.32 703.77 1225.14\rvar(e3) | 731.36 103.43 554.31 964.96\rcov(e1,e2) | 224.17 98.42 31.27 417.06\rcov(e1,e3) | 135.43 86.12 -33.37 304.22\rcov(e2,e3) | 107.72 83.11 -55.17 270.61\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(5) = 11.61 Prob \u003e chi2 = 0.0405\rNote: The reported degrees of freedom assumes the null hypothesis is not on the boundary of the parameter\rspace. If this is not true, then the reported test is conservative.\rBefore we interpret the coefficients from this model, let’s use the margins command to compute the predicted mean of sleep for each level of month, as shown below. margins month,nopvalues Adjusted predictions Number of obs = 300\rExpression: Linear prediction, fixed portion, predict()\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\rmonth |\r1 | 348.24 3.14 342.08 354.40\r2 | 369.31 3.05 363.34 375.28\r3 | 366.67 2.70 361.37 371.97\r--------------------------------------------------------------\rWe can use the marginsplot command to create a graph showing the predicted mean of sleep across the three months, as shown below. marginsplot Estimated minutes of sleep at night by month\rBefore making those spec","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:1:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Example 2: Time (categorical) by two groups This study includes 100 participants in the treatment group and 100 participants in the control group. The main predictors for this example are group (a two-level categorical variable) and month (a three-level categorical variable). use sleep_catcat23.dta list in 1/6,sepby(id) summarize mixed sleep i.group##i.month || id:,noconstant residuals(un,t(month))nolog Mixed-effects ML regression Number of obs = 600\rGroup variable: id Number of groups = 200\rObs per group:\rmin = 3\ravg = 3.0\rmax = 3\rWald chi2(5) = 68.47\rLog likelihood = -2879.78 Prob \u003e chi2 = 0.0000\r-------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r--------------+----------------------------------------------------------------\rgroup |\rMedication | -7.08 4.38 -1.62 0.106 -15.66 1.50\r|\rmonth |\r2 | -3.73 3.75 -1.00 0.319 -11.07 3.61\r3 | -0.57 4.26 -0.13 0.893 -8.91 7.77\r|\rgroup#month |\rMedication#2 | 28.06 5.30 5.30 0.000 17.67 38.45\rMedication#3 | 24.94 6.02 4.14 0.000 13.14 36.74\r|\r_cons | 350.63 3.10 113.24 0.000 344.56 356.70\r-------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: (empty) |\r-----------------------------+------------------------------------------------\rResidual: Unstructured |\rvar(e1) | 958.68 95.87 788.05 1166.26\rvar(e2) | 721.30 72.13 592.92 877.48\rvar(e3) | 980.26 98.03 805.78 1192.50\rcov(e1,e2) | 138.07 59.61 21.25 254.90\rcov(e1,e3) | 63.24 68.69 -71.40 197.87\rcov(e2,e3) | 119.72 60.06 2.01 237.43\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(5) = 15.70 Prob \u003e chi2 = 0.0078\rNote: The reported degrees of freedom assumes the null hypothesis is not on the boundary of the parameter\rspace. If this is not true, then the reported test is conservative.\rWe can estimate the mean sleep by group and month using the margins command below. margins month#group,nopvalues marginsplot,noci Adjusted predictions Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\r---------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r--------------+------------------------------------------------\rmonth#group |\r1#Control | 350.63 3.10 344.56 356.70\r1#Medication | 343.55 3.10 337.48 349.62\r2#Control | 346.90 2.69 341.64 352.16\r2#Medication | 367.88 2.69 362.62 373.14\r3#Control | 350.06 3.13 343.92 356.20\r3#Medication | 367.92 3.13 361.78 374.06\r---------------------------------------------------------------\rEstimated sleep by month and treatment group\rBefore testing our two main questions of interest, let’s assess the overall interaction of group by month using the contrast command below. The overall interaction is significant. contrast group#month Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rsleep |\rgroup#month | 2 30.21 0.0000\r------------------------------------------------\rNow to test our questions of interest regarding the initial effect of medication and the sustained effect of medication, we can apply the ar. contrast operator to month and interact that with group, as shown below. contrast ar.month#group,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r-------------------------------+---------------------------------------\rsleep |\rmonth#group |\r(2 vs 1) (Medication vs base) | 28.06 5.30 5.30 0.000\r(3 vs 2) (Medication vs base) | -3.12 5.41 -0.58 0.564\r--------------------------------------------","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:2:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Example 3: Time (categorical) by three groups This study includes 300 participants, 100 assigned to each of the three treatment groups. The main variables of interest in this study are treatment group (with three levels) and month (with three levels). use sleep_catcat33.dta list in 1/6,sepby(id) summarize mixed sleep i.group##i.month ||id:,noconstant residuals(un,t(month)) nolog Mixed-effects ML regression Number of obs = 900\rGroup variable: id Number of groups = 300\rObs per group:\rmin = 3\ravg = 3.0\rmax = 3\rWald chi2(8) = 284.84\rLog likelihood = -4318.4068 Prob \u003e chi2 = 0.0000\r-------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r--------------+----------------------------------------------------------------\rgroup |\rMedication | 2.60 4.25 0.61 0.540 -5.72 10.92\rEducation | 3.17 4.25 0.75 0.455 -5.15 11.49\r|\rmonth |\r2 | 8.06 3.72 2.17 0.030 0.77 15.35\r3 | 13.35 4.06 3.29 0.001 5.39 21.31\r|\rgroup#month |\rMedication#2 | 21.88 5.26 4.16 0.000 11.57 32.19\rMedication#3 | 18.22 5.75 3.17 0.002 6.96 29.48\rEducation#2 | 7.11 5.26 1.35 0.177 -3.20 17.42\rEducation#3 | 34.49 5.75 6.00 0.000 23.23 45.75\r|\r_cons | 344.70 3.00 114.80 0.000 338.82 350.58\r-------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: (empty) |\r-----------------------------+------------------------------------------------\rResidual: Unstructured |\rvar(e1) | 901.52 73.61 768.20 1057.98\rvar(e2) | 836.25 68.28 712.59 981.38\rvar(e3) | 918.42 74.99 782.60 1077.81\rcov(e1,e2) | 177.08 51.16 76.80 277.35\rcov(e1,e3) | 84.56 52.76 -18.85 187.97\rcov(e2,e3) | 160.48 51.44 59.66 261.30\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(5) = 24.71 Prob \u003e chi2 = 0.0002\rNote: The reported degrees of freedom assumes the null hypothesis is not on the boundary of the parameter\rspace. If this is not true, then the reported test is conservative.\rThe margins and marginsplot commands are used below to estimate the predicted mean of sleep by group and month and to graph the results. margins month#group,nopvalues marginsplot,noci Adjusted predictions Number of obs = 900\rExpression: Linear prediction, fixed portion, predict()\r---------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r--------------+------------------------------------------------\rmonth#group |\r1#Control | 344.70 3.00 338.82 350.58\r1#Medication | 347.30 3.00 341.42 353.18\r1#Education | 347.87 3.00 341.99 353.75\r2#Control | 352.76 2.89 347.09 358.43\r2#Medication | 377.24 2.89 371.57 382.91\r2#Education | 363.04 2.89 357.37 368.71\r3#Control | 358.05 3.03 352.11 363.99\r3#Medication | 378.87 3.03 372.93 384.81\r3#Education | 395.71 3.03 389.77 401.65\r---------------------------------------------------------------\rSleep by month and treatment group\rLet’s now use the contrast command to test the group by month interaction. This overall interaction is significant. contrast group#month Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df chi2 P\u003echi2\r-------------+----------------------------------\rsleep |\rgroup#month | 4 62.05 0.0000\r------------------------------------------------\rLet’s form an interaction contrast in which we apply reference group contrasts to treatment group (r.group) and reverse adjacent group contrasts to month (ar.month). contrast ar.month#r.group,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r----------------------------------+---------------------------------------\rslee","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:3:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Comparing models with different residual covariance structures The selection of the covariance structure impacts the estimates of the standard errors of the coefficients, but not the point estimates of the coefficients. When you have only three time points, an unstructured covariance can be a good choice. However, as the number of time points increases, the number of variances and covariances estimated by an unstructured covariance matrix increases dramatically. For example, if you have five time points, an unstructured covariance estimates five variances and 10 covariances (a total of 15 parameters). In such cases, you might consider more parsimonious covariance structures, such as the exchangeable, ar (autoregressive), or banded residual types. This leads to the question of how to choose among models using different covariance structures. My first recommendation would be to select a residual covariance structure that is grounded in theory or suggested by previous research. However, such information may be scarce or nonexistent. In such cases, you can fit different covariance structures seeking the residual covariance structure that combines the fewest parameters with the best measure of fit—using, for example, Akaike information criterion (AIC) or Bayesian information criterion (BIC). Stata makes this process easy, as illustrated below use sleep_cat3.dta mixed sleep i.month || id:,noconstant residuals(unstructured,t(month)) estimate store m_un mixed sleep i.month || id:,noconstant residuals(exchangeable,t(month)) estimate store m_ex mixed sleep i.month || id:,noconstant residuals(ar 1,t(month)) estimate store m_ar1 Using the dataset from example 1, models are fit using three different covariance structures: unstructured, exchangeable, and ar 1. After fitting each model, the estimates store command is used to store the estimates from the respective model. estimate stats m_un m_ex m_ar1 Akaike's information criterion and Bayesian information criterion\r-----------------------------------------------------------------------------\rModel | N ll(null) ll(model) df AIC BIC\r-------------+---------------------------------------------------------------\rm_un | 900 . -4367.631 9 8753.262 8796.484\rm_ex | 900 . -4372.205 5 8754.409 8778.421\rm_ar1 | 900 . -4370.91 5 8751.82 8775.832\r-----------------------------------------------------------------------------\rNote: BIC uses N = number of observations. See [R] IC note.\rRemember that when it comes to AIC and BIC, smaller is better. The ar 1 and exchangeable models have smaller AIC values than the unstructured model. Likewise, the ar 1 and exchangeable models also have smaller BIC values than the unstructured model. The ar 1 and exchangeable models also have the added benefit of including four fewer residual covariance parameters (5 versus 9). The ar 1 and exchangeable covariance structure appear to provide a fairly similar quality of fit, and both fit better than the unstructured covariance structure. Warning! Likelihood-ratio test It is tempting to ask whether the difference in covariance structures is significantly different and to want to use a command like lrtest to test whether one covariance structure fits significantly better than another. A key assumption of a likelihood-ratio test is that one model is nested within another model, where one model can be created from the other by omitting one or more parameters. In many (or perhaps most) cases, the models formed by comparing two different residual covariance structures are not nested within each other and the likelihood-ratio test is not valid. However, the AIC and BIC indices can be used even when models are not nested within each other. See [ME] mixed for a list of all available covariance structures you can choose within the residuals() option. Furthermore, chapter 7 of Singer and Willett (2003) provides additional descriptions of these residual covariance structures, including information to help you choose among the different st","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:4:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Analyses with small samples The mixed command uses large-sample methods. Applying such methods with smallsample sizes may lead to overly liberal statistical tests (that is, greater type I error rates). The mixed command allows you to specify the dfmethod() option to select testing methods that are more appropriate for small-sample sizes. Specifying the dfmethod() option is easy—knowing the best method to select is not so easy. For an introduction to the different small-sample methods you can choose from, I encourage you to see help mixed, especially the section in the PDF documentation titled Small-sample inference for fixed effects. That section describes five different small-sample adjustment methods: residual, repeated, anova, satterthwaite, and kroger. This leaves two remaining methods to consider: dfmethod(kroger) and dfmethod(satterthwaite). The dfmethod(kroger) option (described in Kenward and Roger (1997)) and dfmethod(satterthwaite) option (described in Satterthwaite (1946)) offer methods that are more applicable when making inferences with longitudinal models with small-sample sizes. There will likely be continued research in this area, and the potential for new techniques and options to arise. For now, it seems that the Kenward–Roger method is probably the most generally useful method available, although sensitivity analyses considering the Satterthwaite method would seem prudent. use sleep_catcat23small.dta count tab group month sort id month list in 1/20,sepby(id) summarize use large-sample statistical methods.(note how the significance of each parameter is tested using z-test) mixed sleep i.group##i.month || id:,noconstant residuals(un,t(month)) Performing gradient-based optimization: Iteration 0: Log likelihood = -364.19065 Iteration 1: Log likelihood = -363.52715 Iteration 2: Log likelihood = -363.12776 Iteration 3: Log likelihood = -363.1244 Iteration 4: Log likelihood = -363.1244 Computing standard errors ...\rMixed-effects ML regression Number of obs = 80\rGroup variable: id Number of groups = 30\rObs per group:\rmin = 1\ravg = 2.7\rmax = 3\rWald chi2(5) = 27.47\rLog likelihood = -363.1244 Prob \u003e chi2 = 0.0000\r-------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r--------------+----------------------------------------------------------------\rgroup |\rMedication | -19.76 9.34 -2.12 0.034 -38.06 -1.47\r|\rmonth |\r2 | -6.20 8.58 -0.72 0.470 -23.01 10.62\r3 | -20.99 10.16 -2.07 0.039 -40.91 -1.07\r|\rgroup#month |\rMedication#2 | 41.98 11.93 3.52 0.000 18.58 65.37\rMedication#3 | 48.40 14.15 3.42 0.001 20.68 76.13\r|\r_cons | 361.38 6.60 54.75 0.000 348.45 374.32\r-------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: (empty) |\r-----------------------------+------------------------------------------------\rResidual: Unstructured |\rvar(e1) | 612.04 163.59 362.46 1033.48\rvar(e2) | 459.72 122.77 272.38 775.92\rvar(e3) | 505.46 145.96 287.00 890.21\rcov(e1,e2) | 40.15 105.05 -165.75 246.05\rcov(e1,e3) | -111.18 115.76 -338.07 115.71\rcov(e2,e3) | 60.67 110.88 -156.66 277.99\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(5) = 2.13 Prob \u003e chi2 = 0.8305\rNote: The reported degrees of freedom assumes the null hypothesis is not on the boundary of the parameter\rspace. If this is not true, then the reported test is conservative.\rThe contrast command is used below to compare the change in sleep across months between the medication group versus the control group. contrast ar.month#group,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------------\r| Contrast Std. er","date":"2024-01-14","objectID":"/17.chapter17time-as-a-categorical-predictor/:5:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter17 ：Time as a categorical predictor","uri":"/17.chapter17time-as-a-categorical-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models that involve the interaction of two categorical predictors with a linear continuous predictor.","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models that involve the interaction of two categorical predictors with a linear continuous predictor. ","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:0:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Chapter overview This chapter blends these two modeling techniques by exploring how the slope of the continuous variable varies as a function of the interaction of the two categorical variables. Let’s consider a hypothetical example of a model with income as the outcome variable. The predictors include gender (a two-level categorical variable), education (treated as a three-level categorical variable), and age (a continuous variable). Income can be modeled as a function of each of the predictors, as well as the interactions of all the predictors. A three-way interaction of age by gender by education would imply that the effect of age interacts with gender by education. One way to visualize such an interaction would be to graph age on the $x$ axis, with separate lines for the levels of education and separate graphs for gender. Fitted values of income as a function of age, education, and gender\rThe age slope by level of education and gender\rBut consider the differences in the age slopes between females and males at each level of education. This difference is $-250 (150-400)$ for non–high school graduates, whereas this difference is $-350 (250-600)$ for high school graduates, and the difference is $-700 (600-1300)$ for college graduates. The difference in the age slopes between females and males seems to be much larger for college graduates than for high school graduates and non–high school graduates. Let’s explore this in more detail with an example using the GSS dataset. To focus on the linear effect of age, we will keep those who are 22 to 55 years old. use gss_ivrm.dta keep if (age\u003e=22 \u0026 age\u003c=55) reg realrinc i.gender##i.educ3##c.age i.race,vce(robust) noci Linear regression Number of obs = 25,718\rF(13, 25704) = 411.30\rProb \u003e F = 0.0000\rR-squared = 0.1839\rRoot MSE = 23556\r-----------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r-------------------+---------------------------------------\rgender |\rFemale | 1337.13 1693.69 0.79 0.430\r|\reduc3 |\rHS | 550.48 1782.19 0.31 0.757\rColl | -11156.10 2618.98 -4.26 0.000\r|\rgender#educ3 |\rFemale#HS | 783.10 2021.65 0.39 0.698\rFemale#Coll | 7657.91 3164.30 2.42 0.016\r|\rage | 413.87 45.62 9.07 0.000\r|\rgender#c.age |\rFemale | -264.98 50.66 -5.23 0.000\r|\reduc3#c.age |\rHS | 175.85 54.75 3.21 0.001\rColl | 897.33 77.47 11.58 0.000\r|\rgender#educ3#c.age |\rFemale#HS | -80.31 60.95 -1.32 0.188\rFemale#Coll | -414.66 93.27 -4.45 0.000\r|\rrace |\rblack | -2935.14 273.33 -10.74 0.000\rother | 185.40 956.34 0.19 0.846\r|\r_cons | 2691.23 1495.78 1.80 0.072\r-----------------------------------------------------------\rLet’s test the interaction of gender, education, and age using the contrast command below. The three-way interaction is significant. contrast i.gender#i.educ3#c.age Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------\r| df F P\u003eF\r-------------------+----------------------------------\rgender#educ3#c.age | 2 10.17 0.0000\r|\rDenominator | 25704\r------------------------------------------------------\rTo begin the process of interpreting the three-way interaction, let’s create a graph of the adjusted means as a function of age, education, and gender. compute the adjusted means by gender and education for age 22 and 55 margins gender#educ3,at(age=(22 55)) Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 22\r2._at: age = 55\r----------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-----------------+----------------------------------------------------------------\r_at#gender#educ3 |\r1#Male#not hs | 11404.29 542.03 21.04 0.000 10341.88 12466.70\r1#Male#HS | 15823.46 349.34 45.29 0.000 15138.72 16508.20\r1#Male#Coll | 19989.51 916.25 21.82 0.000 18193.61 21785.41\r1#Female#not hs | 6911.76 353.90 19.53 0.000 6218.10 7605.42\r1#Female#HS | 10347.31 219.7","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:1:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Simple effects of gender on the age slope We can use the contrast command to test the simple effect of gender on the age slope. This is illustrated below. contrast gender#c.age@educ3,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------------------+---------------------------------------\rgender@educ3#c.age |\r(Female vs base) not hs | -264.98 50.66 -5.23 0.000\r(Female vs base) HS | -345.29 33.99 -10.16 0.000\r(Female vs base) Coll | -679.64 78.45 -8.66 0.000\r-----------------------------------------------------------------\rThe first test compares the age slope for females versus males among non–high school graduates. Referring to table 14.2, this test compares $\\beta\\tiny 1F$with$\\beta\\tiny 1M$ . The difference in these age slopes is $-264.98(148.89 - 413.87)$, and this difference is significant. The age slope for females who did not graduate high school is 264.98 units smaller than the age slope for males who did not graduate high school. The second test is similar to the first, except the comparison is made among high school graduates, comparing $\\beta\\tiny 2F$ with $\\beta\\tiny 2M$ from table 14.2. This test is also significant. The third test compares the age slope between females and males among college graduates (that is, comparing $\\beta\\tiny 3F$ with $\\beta\\tiny 3M$ ). This test is also significant. ","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:2:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Simple effects of education on the age slope We can also look at the simple effects of education on the age slope at each level of gender. contrast educ3#c.age@gender Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------\r| df F P\u003eF\r-------------------+----------------------------------\reduc3@gender#c.age |\rMale | 2 70.96 0.0000\rFemale | 2 43.37 0.0000\rJoint | 4 57.21 0.0000\r|\rDenominator | 25704\r------------------------------------------------------\rThe first test compares the age slope among the three levels of education for males. $H\\tiny 0$:$\\beta\\tiny 1M$ = $\\beta\\tiny 2M$ = $\\beta\\tiny 3M$ This test is significant. The age slope significantly differs as a function of education among males. The second test is like the first test, except that the comparisons are made for females. $H\\tiny 0$:$\\beta\\tiny 1F$ = $\\beta\\tiny 2F$ = $\\beta\\tiny 3F$ This test is also significant. Among females, the age slope significantly differs among the three levels of education. ","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:3:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Simple contrasts on education for the age slope We can further dissect the simple effects tested above by applying contrast coefficients to the education factor.For example, say that we used the ar. contrast operator to form reverse adjacent group comparisons. contrast ar.educ3#c.age@gender,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------------+---------------------------------------\reduc3@gender#c.age |\r(HS vs not hs) Male | 175.85 54.75 3.21 0.001\r(HS vs not hs) Female | 95.54 26.84 3.56 0.000\r(Coll vs HS) Male | 721.48 69.75 10.34 0.000\r(Coll vs HS) Female | 387.13 49.39 7.84 0.000\r---------------------------------------------------------------\r","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:4:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Partial interaction on education for the age slope The three-way interaction can be dissected by forming contrasts on the three-level categorical variable. Say that we use reverse adjacent group comparisons on education, which compares high school graduates with non–high school graduates and college graduates with high school graduates. contrast ar.educ3#r.gender#c.age,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------------------------+---------------------------------------\reduc3#gender#c.age |\r(HS vs not hs) (Female vs Male) | -80.31 60.95 -1.32 0.188\r(Coll vs HS) (Female vs Male) | -334.35 85.49 -3.91 0.000\r-------------------------------------------------------------------------\rThe first comparison tests the interaction of the contrast of high school graduates versus non–high school graduates by gender by age. The difference in the age slope between high school graduates and non–high school graduates for females is 244.43 minus 148.89 (95.54). For males, this difference is 589.72 minus 413.87 (175.85). The difference in these differences is $-80.31$, which is not significant (see the first comparison from the margins command).The difference in the age slope comparing high school graduates with non–high school graduates is not significantly different for males and females. The second test forms the same kind of comparison, but compares college graduates with high school graduates. The difference in the age slope comparing female college graduates with female high school graduates is 631.56 minus 244.43 (387.13). This difference for males is 1,311.20 minus 589.72 (721.48). The difference of these differences is and is statistically significant (see the second comparison from the margins output). The increase in the age slope comparing college graduates with high school graduates is greater for males than it is for females. ","date":"2024-01-13","objectID":"/14.chapter14continuous-by-categorical-by-categorical-interactions/:5:0","tags":["Interaction","stata"],"title":"Chapter14 ：Continuous by continuous by categorical interactions","uri":"/14.chapter14continuous-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"One of the unique features of multilevel models is the ability to study cross-level interactions—the interactions of a level-1 variable with a level-2 variable. Such interactions allow you to explore the extent to which the effect of a level-1 variable is moderated by a level-2 variable. ","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"One of the unique features of multilevel models is the ability to study cross-level interactions—the interactions of a level-1 variable with a level-2 variable. Such interactions allow you to explore the extent to which the effect of a level-1 variable is moderated by a level-2 variable. ","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:0:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Chapter overview This chapter contains four examples, all illustrating multilevel models where students are nested within schools. These four examples provide the opportunity to explore four kinds of crosslevel interactions: continuous by continuous (example 1) continuous by categorical (example 2) categorical by continuous (example 3) categorical by categorical (example 4) All of these examples are completely hypothetical and have been constructed to simplify the interpretation and visualization of the results. ","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:1:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Example 1: Continuous by continuous interaction Consider a two-level multilevel model where students are nested within schools. One hundred schools were randomly sampled from a population of schools, and students were randomly sampled from each of the schools. Two student-level variables were measured: socioeconomic status (ses) and a standardized writing test score (write). Furthermore, a school-level variable was measured: the number students per computer within the school, stucomp use school_write.dta sum list in 1/5,abbreviate(30) Variable | Obs Mean Std. dev. Min Max\r-------------+---------------------------------------------------------\rschoolid | 3,026 50.71481 29.01184 1 100\rstuid | 3,026 17.08824 10.81501 1 52\rwrite | 3,026 542.1325 191.3663 0 1200\rses | 3,026 49.78352 10.18169 14.1897 85.06909\rstucomp | 3,026 5.857066 3.533295 1.149443 16.50701\r+------------------------------------------------+\r| schoolid stuid write ses stucomp |\r|------------------------------------------------|\r1. | 1 1 553 55.38129 3.350059 |\r2. | 1 2 530 61.13125 3.350059 |\r3. | 1 3 604 47.61407 3.350059 |\r4. | 1 4 433 48.26278 3.350059 |\r5. | 1 5 370 47.9762 3.350059 |\r+------------------------------------------------+\rThe aim of this hypothetical study is to determine if the greater availability of computers at a school reduces the strength of the relationship between socioeconomic status and writing test scores. In other words, the goal is to determine if there is a cross-level interaction of ses and stucomp in the prediction of write. The mixed command predicts write from c.ses, c.stucomp, and the interaction c.stucomp#c.ses. The random-effects portion of the model indicates that ses is a random effect across levels of schoolid. The covariance(un) (un is short for unstructured) option permits the random intercept and ses slope to be correlated. (In this and all subsequent examples in this chapter, the nolog and noheader options are used to save space.These options suppress the iteration log and the header information.) mixed write c.stucomp##c.ses || schoolid:ses,covariance(un)nolog noheader ---------------------------------------------------------------------------------\rwrite | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r----------------+----------------------------------------------------------------\rstucomp | -26.75 2.69 -9.95 0.000 -32.01 -21.48\rses | 0.36 0.68 0.53 0.597 -0.97 1.69\r|\rc.stucomp#c.ses | 0.24 0.10 2.28 0.023 0.03 0.44\r|\r_cons | 602.29 18.18 33.12 0.000 566.65 637.93\r---------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rschoolid: Unstructured |\rvar(ses) | 8.92 1.73 6.09 13.05\rvar(_cons) | 372.35 1229.73 0.58 241085.03\rcov(ses,_cons) | 19.20 35.82 -51.01 89.40\r-----------------------------+------------------------------------------------\rvar(Residual) | 9820.89 261.13 9322.20 10346.25\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(3) = 3253.82 Prob \u003e chi2 = 0.0000\rNote: LR test is conservative and provided only for reference.\rNote! Fixed and random effects The fixed effects are specified after the dependent variable and before the ||. The random effects are specified after the ||. As expected, the c.stucomp#c.ses interaction is significant. We can use themargins command below with the dydx(ses) option to compute the ses slope for schools that have between one and eight students per computer. margins,dydx(ses) at(stucomp=(1(1)8)) vsquish Average marginal effects Number of obs = 3,026\rExpression: Linear prediction, fixed portion, predict()\rdy/dx wrt: ses\r1._at: stucomp = 1\r2._at: stucomp = 2\r3._at: stucomp = 3\r4._at: stucomp = 4\r5._at: stucomp = 5\r6._at: stucomp = 6\r7._at: stucomp = 7\r8._at: stucomp = 8\r--","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:2:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Example 2: Continuous by categorical interaction In this study, standardized reading scores were measured as well as the socioeconomic status of the student. Of the 100 schools, 35 were private (non-Catholic), 35 were public, and 30 were Catholic schools The goal of this hypothetical study is to examine the relationship between socioeconomic status (ses) and reading scores (read), and to determine if the strength of that relationship varies as a function of the type of school (private, public, or Catholic). This involves examining the cross-level interaction of ses and schtype. The mixed command for performing this analysis is shown below. The variable read is predicted from ses, schtype, and the interaction of these two variables. The variable ses is specified as a random coefficient that varies across schools. use school_read.dta sum list in 1/5,abbreviate(30) mixed read i.schtype##c.ses || schoolid:ses,covariance(un) nolog noheader --------------------------------------------------------------------------------\rread | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r---------------+----------------------------------------------------------------\rschtype |\rPublic | 41.97 23.27 1.80 0.071 -3.64 87.57\rCatholic | 152.48 23.79 6.41 0.000 105.86 199.10\r|\rses | 4.04 0.67 6.00 0.000 2.72 5.36\r|\rschtype#c.ses |\rPublic | -1.24 0.95 -1.30 0.192 -3.11 0.62\rCatholic | -3.37 0.99 -3.41 0.001 -5.30 -1.44\r|\r_cons | 519.28 16.57 31.33 0.000 486.80 551.77\r--------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rschoolid: Unstructured |\rvar(ses) | 12.13 2.12 8.61 17.10\rvar(_cons) | 4.90 82.77 0.00 1.14e+15\rcov(ses,_cons) | 6.75 31.24 -54.47 67.97\r-----------------------------+------------------------------------------------\rvar(Residual) | 10015.68 264.26 9510.90 10547.24\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(3) = 4052.81 Prob \u003e chi2 = 0.0000\rNote: LR test is conservative and provided only for reference.\rThe contrast command is used below to test the overall schtype#c.ses interaction. This tests the following null hypothesis: $H\\tiny 0$:$\\beta\\tiny 1$ = $\\beta\\tiny 2$ = $\\beta\\tiny 3$ $\\beta\\tiny 1$ is the average ses slope for private schools,$\\beta\\tiny 2$ is the average ses slope for public schools, and $\\beta\\tiny 3$ is the average ses slope for Catholic schools. This test is significant, indicating that the ses slopes differ by schtype. contrast schtype#c.ses Margins: asbalanced\r-------------------------------------------------\r| df chi2 P\u003echi2\r--------------+----------------------------------\rread |\rschtype#c.ses | 2 11.82 0.0027\r-------------------------------------------------\rLet’s create a graph that illustrates the ses slopes by schtype. We do this using the margins command to compute the adjusted means of reading scores as a function of ses and schtype, and then graphing these adjusted means using the marginsplot. margins schtype, at(ses=(20(5)80)) marginsplot,noci Reading score by socioeconomic status and school type\rLet’s now use the margins command combined with the dydx(ses) option to estimate the ses slope for each of the three different types of schools. margins,dydx(ses) over(schtype) vsquish Average marginal effects Number of obs = 2,973\rExpression: Linear prediction, fixed portion, predict()\rdy/dx wrt: ses\rOver: schtype\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\rses |\rschtype |\rPrivate | 4.04 0.67 6.00 0.000 2.72 5.36\rPublic | 2.80 0.67 4.17 0.000 1.48 4.12\rCatholic | 0.67 0.72 0.93 0.350 -0.74 2.09\r-----------------------------","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:3:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Example 3: Categorical by continuous interaction The aim of this study is to look at gender differences in math performance and to determine if smaller class sizes are associated with smaller gender differences in math scores. In other words, the aim is to determine if there is a cross-level interaction between gender (a level-1 predictor) and class size (a level-2 predictor). use school_math.dta summarize list in 1/5 The mixed command is used to predict math from gender, clsize, and the interaction of these variables. The variable gender is specified as a random coefficient at the school level. mixed math i.gender##c.clsize ||schoolid:gender,covariance(un) nolog Mixed-effects ML regression Number of obs = 2,926\rGroup variable: schoolid Number of groups = 100\rObs per group:\rmin = 8\ravg = 29.3\rmax = 52\rWald chi2(3) = 59.38\rLog likelihood = -17691.732 Prob \u003e chi2 = 0.0000\r-----------------------------------------------------------------------------------\rmath | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r------------------+----------------------------------------------------------------\rgender |\rFemale | 13.83 12.41 1.11 0.265 -10.49 38.16\rclsize | -1.34 0.32 -4.15 0.000 -1.97 -0.71\r|\rgender#c.clsize |\rFemale | -1.10 0.48 -2.30 0.021 -2.04 -0.16\r|\r_cons | 451.94 8.34 54.18 0.000 435.59 468.29\r-----------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rschoolid: Unstructured |\rvar(gender) | 244.79 231.45 38.37 1561.80\rvar(_cons) | 35.46 96.33 0.17 7273.92\rcov(gender,_cons) | 78.98 115.00 -146.42 304.37\r-----------------------------+------------------------------------------------\rvar(Residual) | 10273.41 277.07 9744.46 10831.07\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(3) = 15.08 Prob \u003e chi2 = 0.0018\rNote: LR test is conservative and provided only for reference.\rTo help interpret this effect, we can graph the results using the margins and marginsplot commands margins gender, at(clsize=(15(5)40)) marginsplot,noci Math scores by gender and average class size\rLet’s assess the significance of the gender difference for class sizes ranging from 15 to 40 in five-student increments using the margins command below. margins r.gender,at(clsize=(15(5)40)) contrast(pveffects nowald) vsquish Contrasts of adjusted predictions Number of obs = 2,926\rExpression: Linear prediction, fixed portion, predict()\r1._at: clsize = 15\r2._at: clsize = 20\r3._at: clsize = 25\r4._at: clsize = 30\r5._at: clsize = 35\r6._at: clsize = 40\r------------------------------------------------------------\r| Delta-method\r| Contrast std. err. z P\u003e|z|\r--------------------+---------------------------------------\rgender@_at |\r(Female vs Male) 1 | -2.72 6.10 -0.45 0.656\r(Female vs Male) 2 | -8.24 4.61 -1.79 0.074\r(Female vs Male) 3 | -13.76 4.10 -3.35 0.001\r(Female vs Male) 4 | -19.27 4.88 -3.95 0.000\r(Female vs Male) 5 | -24.79 6.51 -3.81 0.000\r(Female vs Male) 6 | -30.31 8.51 -3.56 0.000\r------------------------------------------------------------\rThe margins command is repeated below for 15 to 40 students per class in onestudent increments (the output is omitted to save space). The marginsplot command is then used to visualize the gender differences (with a confidence interval) across the entire spectrum of class sizes margins r.gender,at(clsize=(15(1)40)) contrast(effects) marginsplot,recastci(rarea) ciopts(fcolor(%20)) yline(0) Gender difference in reading score by average class size\r","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:4:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Example 4: Categorical by continuous interaction This study focuses on gender differences in standardized science scores, and whether such differences vary by school size. In this study, each school is classified into one of three sizes: small, medium, or large. Thus, the focus of this study is on the cross-level interaction of gender by school size, where both gender and school size are categorical variables. use school_science.dta summarize list in 1/5 mixed science i.gender##i.schsize || schoolid: gender,covariance(un) nolog noheader -----------------------------------------------------------------------------------\rscience | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r------------------+----------------------------------------------------------------\rgender |\rFemale | -19.65 6.65 -2.96 0.003 -32.68 -6.62\r|\rschsize |\rMedium | 18.56 7.36 2.52 0.012 4.13 32.99\rLarge | 40.16 7.20 5.58 0.000 26.06 54.27\r|\rgender#schsize |\rFemale#Medium | 1.47 9.54 0.15 0.878 -17.23 20.17\rFemale#Large | 22.24 9.29 2.39 0.017 4.03 40.45\r|\r_cons | 394.97 5.14 76.89 0.000 384.90 405.04\r-----------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rschoolid: Unstructured |\rvar(gender) | 38.52 205.24 0.00 1.32e+06\rvar(_cons) | 155.78 115.88 36.25 669.43\rcov(gender,_cons) | 17.52 128.51 -234.35 269.38\r-----------------------------+------------------------------------------------\rvar(Residual) | 9772.30 271.33 9254.71 10318.83\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(3) = 12.15 Prob \u003e chi2 = 0.0069\rNote: LR test is conservative and provided only for reference.\rThe contrast command is used to test the overall gender#schsize interaction. This test is significant. contrast gender#schsize Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------\r| df chi2 P\u003echi2\r---------------+----------------------------------\rscience |\rgender#schsize | 2 7.17 0.0278\r--------------------------------------------------\rcontrast gender#schsize To help interpret this interaction, we can use the margins command to display the adjusted mean of science scores as a function of gender and schsize margins schsize#gender,nopvalues vsquish marginsplot,noci Adjusted predictions Number of obs = 2,764\rExpression: Linear prediction, fixed portion, predict()\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\rschsize#gender |\rSmall#Male | 394.97 5.14 384.90 405.04\rSmall#Female | 375.32 5.46 364.62 386.03\rMedium#Male | 413.53 5.27 403.20 423.86\rMedium#Female | 395.36 5.56 384.45 406.26\rLarge#Male | 435.14 5.04 425.26 445.01\rLarge#Female | 437.73 5.36 427.23 448.23\r----------------------------------------------------------------\rScience scores by gender and school size\rOne way to further understand this interaction is by testing the simple effect of gender for each school size. This is performed using the contrast command, as shown below. contrast gender@schsize,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r-------------------------+---------------------------------------\rscience |\rgender@schsize |\r(Female vs base) Small | -19.65 6.65 -2.96 0.003\r(Female vs base) Medium | -18.18 6.84 -2.66 0.008\r(Female vs base) Large | 2.59 6.49 0.40 0.690\r-----------------------------------------------------------------\rWe can also further probe the interaction by using partial interaction tests. Let’s apply the ar. contrast operator to school size (comparing each group with th","date":"2024-01-13","objectID":"/15.chapter15multilevel-models/:5:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter15 ：Multilevel models","uri":"/15.chapter15multilevel-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models involving the analysis of longitudinal data.  ","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter considers models involving the analysis of longitudinal data. Such designs involve participants that are observed at more than one time point and time is generally treated as one of the important predictors in the model. Like any predictor, we need to ask ourselves how we want to model the relationship between time and the outcome. A key distinction is whether time will be treated as a continuous variable or as a categorical variable. There are several approaches that can be used for modeling longitudinal data, including repeated-measures analysis of variance (ANOVA), generalized estimating equations (GEE), and multilevel modeling. This chapter will focus on using multilevel modeling for analyzing longitudinal models where time is treated as level 1 and the person will be treated as level 2. In such a model, characteristics that change as a function of time are level-1 predictors and characteristics that are a property of the person that do not change over time are level-2 predictors. ","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:0:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Example 1: Linear effect of time Let’s begin by considering a simple model in which we look at the linear effect of time on the outcome variable. For example, let’s consider a study in which we are looking at the number of minutes people sleep at night over a seven-week period. For the sake of this example, assume that the people were selected for the study because they have recently experienced a stressful event in their life, and the purpose of the study is to understand the natural course of sleep change over the seven weeks after a stressful event. use sleep_conlin.dta list in 1/5 summarize +---------------------+\r| id obsday sleep |\r|---------------------|\r1. | 1 1 382 |\r2. | 1 6 382 |\r3. | 1 13 390 |\r4. | 1 21 378 |\r5. | 1 27 401 |\r+---------------------+\rThe dataset for this study is organized in a long format, with one observation per person per night of observation. Variable | Obs Mean Std. dev. Min Max\r-------------+---------------------------------------------------------\rid | 600 38 21.66677 1 75\robsday | 600 23.565 14.82854 1 52\rsleep | 600 360.785 48.13086 175 528\rInstead, we can fit a random-intercept model that accounts for the nonindependence of the residuals within each person. Such a model is fit below first using the xtset command to specify that id is the panel variable and obsday is the time variable. We can then use the xtreg command to fit a random-intercept model predicting sleep from obsday xtset id obsday Panel variable: id (weakly balanced)\rTime variable: obsday, 1 to 52, but with gaps\rDelta: 1 unit\rxtreg sleep obsday Random-effects GLS regression Number of obs = 600\rGroup variable: id Number of groups = 75\rR-squared: Obs per group:\rWithin = 0.1652 min = 8\rBetween = 0.0062 avg = 8.0\rOverall = 0.0218 max = 8\rWald chi2(1) = 103.56\rcorr(u_i, X) = 0 (assumed) Prob \u003e chi2 = 0.0000\r------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\robsday | 0.51 0.05 10.18 0.000 0.41 0.61\r_cons | 348.80 5.31 65.66 0.000 338.39 359.21\r-------------+----------------------------------------------------------------\rsigma_u | 44.412437\rsigma_e | 18.051717\rrho | .85821678 (fraction of variance due to u_i)\r------------------------------------------------------------------------------\rThe interpretation of the obsday coefficient is straightforward. For each additional day in the study, nightly minutes of sleep increased by, on average, by 0.51 minutes. In this model, the coefficient for obsday is treated as a fixed effect. The model recognizes that people randomly vary in terms of their average sleep time at the start of the study (represented by the random intercept). But perhaps people also vary individually in their trajectory of sleep times across the weeks of the study. By adding obsday as a random coefficient (that is, a random slope), the model can account for both individual differences in the average length of sleep at the start of the study (that is, a random intercept) and individual differences in the trajectory of sleep times across the weeks of the study (that is, a random slope for obsday). mixed sleep obsday || id:obsday, covariance(un) nolog Mixed-effects ML regression Number of obs = 600\rGroup variable: id Number of groups = 75\rObs per group:\rmin = 8\ravg = 8.0\rmax = 8\rWald chi2(1) = 20.54\rLog likelihood = -2488.5378 Prob \u003e chi2 = 0.0000\r-----------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r------------------+----------------------------------------------------------------\robsday | 0.51 0.11 4.53 0.000 0.29 0.73\r_cons | 348.82 3.31 105.43 0.000 342.34 355.31\r-----------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. e","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:1:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Example 2: Linear effect of time by a categorical predictor Let’s consider another sleep study in which participants diagnosed with insomnia were randomly assigned to one of three different treatments to increase the number of minutes of sleep at night. The three different treatments were 1) control group (no treatment), 2) medication group (where a sleep medication is given), or 3) education group (where the participants receive education about how to sleep better and longer). This model involves a combination of a continuous predictor (time) and a threelevel categorical predictor (treatment group). use sleep_cat3conlin.dta list in 1/5 summarize We can fit a model that predicts sleep from the observation day, the group assignment, and the interaction of these two variables using the mixed command shown below. Note that the random-effects portion of the model specifies that obsday is a random effect. [Thinking in terms of a multilevel model, group#obsday is a crosslevel interaction of a level-2 variable (group) with a level-1 variable (obsday).] mixed sleep i.group##c.obsday || id:obsday,covariance(un)nolog Mixed-effects ML regression Number of obs = 600\rGroup variable: id Number of groups = 75\rObs per group:\rmin = 8\ravg = 8.0\rmax = 8\rWald chi2(5) = 66.55\rLog likelihood = -2482.6017 Prob \u003e chi2 = 0.0000\r-----------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r------------------+----------------------------------------------------------------\rgroup |\rMedication | 35.48 9.50 3.74 0.000 16.86 54.10\rEducation | 5.55 9.50 0.58 0.559 -13.07 24.17\r|\robsday | -0.07 0.18 -0.37 0.715 -0.42 0.29\r|\rgroup#c.obsday |\rMedication | 0.18 0.25 0.71 0.475 -0.32 0.68\rEducation | 0.83 0.25 3.27 0.001 0.33 1.33\r|\r_cons | 339.45 6.72 50.53 0.000 326.28 352.61\r-----------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: Unstructured |\rvar(obsday) | 0.72 0.13 0.50 1.03\rvar(_cons) | 1079.51 184.18 772.68 1508.17\rcov(obsday,_cons) | 22.52 4.23 14.22 30.82\r-----------------------------+------------------------------------------------\rvar(Residual) | 108.37 7.22 95.10 123.48\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(3) = 1425.42 Prob \u003e chi2 = 0.0000\rNote: LR test is conservative and provided only for reference.\rWe first use the margins command to estimate the predicted means by group at selected values of obsday. We follow that with the marginsplot command to graph the predicted means computed by the margins command. margins group,at(obsday=(0 45)) marginsplot,noci Adjusted predictions Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\r1._at: obsday = 0\r2._at: obsday = 45\r-------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. z P\u003e|z| [95% conf. interval]\r--------------+----------------------------------------------------------------\r_at#group |\r1#Control | 339.45 6.72 50.53 0.000 326.28 352.61\r1#Medication | 374.93 6.72 55.83 0.000 361.76 388.09\r1#Education | 345.00 6.72 51.36 0.000 331.83 358.16\r2#Control | 336.49 13.61 24.71 0.000 309.80 363.17\r2#Medication | 380.14 13.60 27.94 0.000 353.47 406.80\r2#Education | 379.42 13.61 27.88 0.000 352.75 406.10\r-------------------------------------------------------------------------------\rMinutes of sleep at night by time and treatment group\rThe slope appears to be slightly negative for the control group. In other words, their sleep durations appear to mildly decrease as a linear function of the observation day. For the medication group, the slope appears to be slightly positive. By contrast, sleep durations increase as a linear f","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:2:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Example 3:Piecewise modeling of time Time can be modeled in a piecewise fashion by breaking up the days of observation into the baseline phase and the treatment phase. In this example, we can assess the slope of the relationship between sleep duration and time (obsday) during the baseline and treatment phases. We can also test for a sudden jump in sleep duration on the 31st day, corresponding to the start of the treatment phase. use sleep_conpw.dta list in 1/5,sepby(id) summarize We need to create some variables to prepare for the piecewise analysis. First, we use the mkspline command to create the variables named obsday1m and obsday2m, placing the knot at 31 days (corresponding to the start of the treatment phase). mkspline obsday1m 31 obsday2m = obsday,marginal Next, we create the variable trtphase that is coded 0 for the baseline phase (where obsday was 1 to 30) and coded 1 during the treatment phase (where obsday is 31 or more). generate trtphase = 0 if obsday \u003c= 30 replace trtphase = 1 if obsday \u003e=31 \u0026 !missing(obsday) We are now ready to run a piecewise model that predicts sleep from obsday1m, obsday2m, and trtphase. In this example, obsday1m, obsday2m, and trtphase are also included as random effects. mixed sleep obsday1m obsday2m trtphase || id: obsday1m obsday2m trtphase,covariance(un)nolog Mixed-effects ML regression Number of obs = 600\rGroup variable: id Number of groups = 75\rObs per group:\rmin = 8\ravg = 8.0\rmax = 8\rWald chi2(3) = 70.48\rLog likelihood = -2601.8889 Prob \u003e chi2 = 0.0000\r----------------------------------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z| [95% conf. interval]\r-----------------------+----------------------------------------------------------------\robsday1m | -0.01 0.12 -0.05 0.961 -0.24 0.23\robsday2m | 0.54 0.17 3.27 0.001 0.22 0.87\rtrtphase | 11.14 1.94 5.74 0.000 7.33 14.94\r_cons | 349.01 10.64 32.80 0.000 328.15 369.87\r----------------------------------------------------------------------------------------\r------------------------------------------------------------------------------\rRandom-effects parameters | Estimate Std. err. [95% conf. interval]\r-----------------------------+------------------------------------------------\rid: Unstructured |\rvar(obsday1m) | 0.83 0.18 0.55 1.25\rvar(obsday2m) | 0.69 0.33 0.27 1.78\rvar(trtphase) | 59.53 48.90 11.90 297.83\rvar(_cons) | 8425.42 1386.81 6102.18 11633.16\rcov(obsday1m,obsday2m) | -0.37 0.19 -0.73 -0.00\rcov(obsday1m,trtphase) | -1.54 2.14 -5.73 2.65\rcov(obsday1m,_cons) | 32.85 11.53 10.25 55.46\rcov(obsday2m,trtphase) | 2.84 2.78 -2.62 8.29\rcov(obsday2m,_cons) | -5.19 15.46 -35.50 25.12\rcov(trtphase,_cons) | -133.63 180.15 -486.71 219.45\r-----------------------------+------------------------------------------------\rvar(Residual) | 101.86 8.07 87.20 118.97\r------------------------------------------------------------------------------\rLR test vs. linear model: chi2(10) = 2057.12 Prob \u003e chi2 = 0.0000\rNote: LR test is conservative and provided only for reference.\rWe can then use the margins command to compute the predicted means for these key days. When obsday equals 31, we estimate the predicted mean assuming trtphase is 0 and 1, to estimate the jump in the fitted values due to the start of the treatment phase. (The noatlegend option is included to save space.) margins,at(obsday1m = 1 obsday2m = 0 trtphase=0) /// at(obsday1m = 31 obsday2m = 0 trtphase=0) /// at(obsday1m = 31 obsday2m = 0 trtphase=1) /// at(obsday1m = 49 obsday2m = 18 trtphase=1) nopvalues noatlegend Adjusted predictions Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\r_at |\r1 | 349.01 10.68 328.07 369.94\r2 | 348.83 12.30 324.72 372.94\r3 | 359.97 12.16 336.14 383.79\r4 | 369.65 13.11 343.95 395.34\r---------------------------------","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:3:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Example 4: Piecewise effects of time by a categorical predictor Let’s consider an extension of the previous example that includes a baseline and treatment phase, but where participants are divided into different groups and receive different kinds of treatments during the treatment phase. The first 30 days of the study are a baseline period during which the sleep is observed, but no treatment is administered to any of the groups. Starting on the 31st day, the medication group receives sleep medication, the sleep education group receives education about how to lengthen their sleep, and the control group receives nothing. The first phase of the study (days 1 to 30) is called the baseline phase, and the second phase (day 31 until the end of the study) is called the treatment phase. We can study the slope of the relationship between sleep duration and time during each of these phases, as well as the change (jump or drop) in sleep that occurs at the transition from baseline to the treatment phase. Furthermore, we can investigate the impact of the treatment group assignment (control, medication, and education) on the slope in each phase, as well as the jump or drop in sleep due to the start of the treatment phase. use sleep_cat3pw.dta list in 1/5,sepby(id) summarize Imagine the educational periods (before high school graduation and after high school graduation) being replaced with the baseline and treatment phases. Also, imagine gender (male and female) being replaced with treatment group assignment (control, medication, and education). First, the mkspline command is used to create the variables obsday1m and obsday2m, specifying 31 as the knot. By including the marginal option, obsday1m will represent the slope for the baseline period and obsday2m will represent the change in the slope for the treatment period compared with the baseline period. mkspline obsday1m 31 obsday2m = obsday,marginal To account for the jump in sleep at the start of the treatment phase, we use the generate and replace commands to create the variable trtphase that is coded: 0 = baseline and 1 = treatment. generate trtphase = 0 if obsday \u003c 31 replace trtphase = 1 if obsday \u003e= 31 \u0026 !missing(obsday) label define trtlab 0 \"baseline\" 1 \"treatment\" label values trtphase trtlab The mixed command for fitting this model is shown below. Note the variables trtphase, obsday1m, and obsday2m are specified as random effects. The nolog, noheader, and noretable options are used to suppress the iteration log, header, and random-effects table to save space. mixed sleep i.group##(i.trtphase c.obsday1m c.obsday2m), || id:trtphase obsday1m obsday2m,covariance(un) nolog noheader noretable noci ---------------------------------------------------------------\rsleep | Coefficient Std. err. z P\u003e|z|\r-----------------------+---------------------------------------\rgroup |\rMedication | -2.07 3.41 -0.61 0.543\rEducation | 16.31 3.41 4.78 0.000\r|\rtrtphase |\rtreatment | -4.20 2.79 -1.51 0.132\robsday1m | -0.04 0.30 -0.14 0.890\robsday2m | -0.10 0.51 -0.19 0.849\r|\rgroup#trtphase |\rMedication#treatment | 34.28 4.00 8.58 0.000\rEducation#treatment | 1.65 3.97 0.41 0.678\r|\rgroup#c.obsday1m |\rMedication | 0.40 0.42 0.95 0.343\rEducation | -0.14 0.42 -0.34 0.735\r|\rgroup#c.obsday2m |\rMedication | -0.29 0.72 -0.40 0.686\rEducation | 2.48 0.72 3.45 0.001\r|\r_cons | 351.36 2.41 145.54 0.000\r---------------------------------------------------------------\rWe can now use the margins command to compute the predicted mean of sleep for each group at four key points—for the beginning of the study, the first day of the treatment phase (with and without treatment), and the 49th day of the study. (The noatlegend option is specified to save space.) margins group,at(obsday1m = 1 obsday2m = 0 trtphase=0) /// at(obsday1m = 31 obsday2m = 0 trtphase=0) /// at(obsday1m = 31 obsday2m = 0 trtphase=1) /// at(obsday1m = 49 obsday2m = 18 trtphase=1)nopvalues noatlegend Adjusted predictions Number of obs = 600\rExpression: Linear pre","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:4:0","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.1 Baseline slope [means the prior to the treatment phase] We can test the equality of all the baseline slopes using the contrast command below. This test is not significant. contrast group#c.obsday1m Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------\r| df chi2 P\u003echi2\r-----------------+----------------------------------\rsleep |\rgroup#c.obsday1m | 2 1.78 0.4108\r----------------------------------------------------\rYou can estimate the baseline slope for each group using the margins command below. margins, dydx(obsday1m) over(group) Average marginal effects Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\rdy/dx wrt: obsday1m\rOver: group\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\robsday1m |\rgroup |\rControl | -0.04 0.30 -0.14 0.890 -0.63 0.55\rMedication | 0.36 0.30 1.20 0.229 -0.23 0.95\rEducation | -0.19 0.30 -0.62 0.537 -0.77 0.40\r------------------------------------------------------------------------------\r","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:4:1","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.2 Change in slopes: Treatment versus baseline You can test the equality of the changes in slope coefficients for all three groups using the contrast command below. This test is significant. contrast group#c.obsday2m Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------\r| df chi2 P\u003echi2\r-----------------+----------------------------------\rsleep |\rgroup#c.obsday2m | 2 17.95 0.0001\r----------------------------------------------------\rYou can estimate the change in slope for each group using the margins command below. The change in slope for the control group and medication groups is not significant. For the education group (group 3), the slope during the treatment phase is significantly greater than the slope during the baseline phase. margins,dydx(obsday2m) over(group) Average marginal effects Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\rdy/dx wrt: obsday2m\rOver: group\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. z P\u003e|z| [95% conf. interval]\r-------------+----------------------------------------------------------------\robsday2m |\rgroup |\rControl | -0.10 0.51 -0.19 0.849 -1.09 0.90\rMedication | -0.39 0.51 -0.76 0.447 -1.39 0.61\rEducation | 2.38 0.51 4.70 0.000 1.39 3.38\r------------------------------------------------------------------------------\r","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:4:2","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.3 Jump at treatment We can test the equality of the jump or drop for all three groups using the contrast command below. This test is significant. contrast group#trtphase Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------\r| df chi2 P\u003echi2\r---------------+----------------------------------\rsleep |\rgroup#trtphase | 2 92.58 0.0000\r--------------------------------------------------\rWe can estimate the size of the jump or drop in sleep durations at the start of the treatment phase for each group using the contrast command below. contrast trtphase@group,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------------------------\r| Contrast Std. err. z P\u003e|z|\r--------------------------------+---------------------------------------\rsleep |\rtrtphase@group |\r(treatment vs base) Control | -4.20 2.79 -1.51 0.132\r(treatment vs base) Medication | 30.08 2.86 10.52 0.000\r(treatment vs base) Education | -2.56 2.83 -0.90 0.366\r------------------------------------------------------------------------\r","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:4:3","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.4 Comparisons among groups Let’s now use the margins command to compare each group with the control group at each of these days. (The noatlegend option is specified to save space.) margins r.group,at(obsday1m=30 obsday2m=0 trtphase=0) /// at(obsday1m=35 obsday2m=4 trtphase=1) /// at(obsday1m=40 obsday2m=9 trtphase=1) /// at(obsday1m=45 obsday2m=14 trtphase=1) /// contrast(nowald pveffects)noatlegend Contrasts of adjusted predictions Number of obs = 600\rExpression: Linear prediction, fixed portion, predict()\r-------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. z P\u003e|z|\r---------------------------+---------------------------------------\rgroup@_at |\r(Medication vs Control) 1 | 9.98 12.37 0.81 0.420\r(Medication vs Control) 2 | 45.10 12.87 3.50 0.000\r(Medication vs Control) 3 | 45.65 13.50 3.38 0.001\r(Medication vs Control) 4 | 46.21 14.68 3.15 0.002\r(Education vs Control) 1 | 12.00 12.38 0.97 0.332\r(Education vs Control) 2 | 22.84 12.87 1.77 0.076\r(Education vs Control) 3 | 34.51 13.50 2.56 0.011\r(Education vs Control) 4 | 46.18 14.67 3.15 0.002\r-------------------------------------------------------------------\rFocusing on the comparison of the medication group with the control group, the difference is not significant when observation day is 30 ($p=0.420$); prior to the treatment phase. However, the difference is significant at each of the time points tested during the treatment phase, when observation day is 35, 40, and 45 ( = 0.000, 0.001, and 0.002, respectively). Shifting our attention to the comparison of the education group with the control group, the comparison is not significant when observation day is 30 ($p=0.332$); prior to the start of the treatment phase. The difference remains nonsignificant early in the treatment phase when observation day is 35 ($p=0.076$) but is significant later inthe treatment phase when observation day is 40 ($p=0.011$) and 45 ($p=0.002$). ","date":"2024-01-13","objectID":"/16.chapter16time-as-a-continuous-predictor/:4:4","tags":["Multilevel","Interaction","stata"],"title":"Chapter16 ：Time as a continuous predictor","uri":"/16.chapter16time-as-a-continuous-predictor/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates how to fit models in which a continuous variable, fit in a piecewise manner, is interacted with a categorical variable.  ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates how to fit models in which a continuous variable, fit in a piecewise manner, is interacted with a categorical variable. ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:0:0","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 One knot and one jump For example, education was modeled in a piecewise manner including one knot at 12 years of education. This knot signifies both a change of slope and change in intercept (jump). The model also includes gender as a categorical variable and estimates separate slopes and intercepts for each level of gender Piecewise regression with one knot and one jump, labeled with estimated slopes\rFigure shows the adjusted means of income as a function of education with labels for each of the slopes. For men, the slope for non–high school graduates is labeled $\\beta\\tiny M1$ and the slope for high school graduates is labeled $\\beta\\tiny M2$ . For women, the slope for non–high school graduates is labeled $\\beta\\tiny F1$ and the slope for high school graduates is labeled $\\beta\\tiny F2$. The income jump at 12 years of education for men is labeled as $\\alpha\\tiny M1$. The corresponding jump at 12 years of education for women is labeled as $\\alpha\\tiny F1$. Note how an arrow head points to a sudden jump in income at 12 years of education To fit this model, we will use separate slope and separate intercept coding with respect to the gender groups. This means that we will estimate separate intercept terms for men and women (this includes separate jumps,$\\alpha\\tiny M1$ and $\\alpha\\tiny F1$ ). It will also estimate separate slope terms for men (that is, $\\beta\\tiny M1$ and $\\beta\\tiny M2$ ) and separate slope terms for women (that is,$\\beta\\tiny F1$ and $\\beta\\tiny F2$). We first use the mkspline command to create the variables ed1 and ed2 with a knot at 12 years of education. the variables ed1 and ed2 will reflect the slopes of the individual line segments before and after the knot. mkspline ed1 12 ed2 = educ We are now ready to run the piecewise regression model, shown in the regress command below. The regress command includes ibn.gender used in combination with the noconstant option to yield separate estimates of the intercept for each gender. reg realrinc ibn.gender ibn.gender#i.hsgrad /// ibn.gender#c.ed1 ibn.gender#c.ed2 i.race, vce(robust) noconstant noci Linear regression Number of obs = 3,126\rF(6, 3120) = 614.01\rProb \u003e F = 0.0000\rR-squared = 0.5132\rRoot MSE = 20860\r--------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rFemale | 10502.44 1991.84 5.27 0.000\r|\rgender#hsgrad |\rFemale#HS Grad | 2891.28 893.57 3.24 0.001\r|\rgender#c.ed1 |\rFemale | 95.54 211.64 0.45 0.652\r|\rgender#c.ed2 |\rFemale | 3260.42 247.08 13.20 0.000\r|\rrace |\rblack | -1174.41 902.16 -1.30 0.193\rother | -4732.20 1169.14 -4.05 0.000\r--------------------------------------------------------\rNote! Model shortcut Stata expands the expression ibn.gender#(i.hsgrad c.ed1 c.ed2) to become ibn.gender#i.hsgrad ibn.gender#c.ed1 ibn.gender#c.ed2, yielding the same model we saw before. The first two columns of the table repeat the name and estimate of the coefficient from the regress output. The third column shows the symbol used to represent the coefficient in figure above, providing a cross reference between the output of the regression model and figure. The last column shows the symbolic name of the regression coefficient that we can use with the lincom command for making comparisons among the coefficients. Summary of piecewise regression results with one knot\rLet’s begin by interpreting the change in intercept (jump) terms. The jump in the adjusted mean of income for men at 12 years of education is 3,382.01, and the corresponding jump for women is 1,748.10. Each of these jumps is statistically significant. Let’s now interpret the slopes. For men, the educ slope is 86.71 for non–high school graduates and is 4,057.64 for high school graduates. For women, the slope is 241.61 for non–high school graduates and is 2,529.55 for high school graduates. Aside from the educ slope for male non–high school graduates (86.71), all of these slopes are significantl","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:0","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Comparing slopes across gender Let’s begin by testing the equality of the educ slopes of women and men who have not graduated high school. In other words, is $\\beta\\tiny F1$= $\\beta\\tiny M1$ ? contrast gender#c.ed1,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender#c.ed1 |\r(Female vs base) | 154.90 179.32 0.86 0.388\r----------------------------------------------------------\rLet’s compare the educ slopes of men and women for those who graduated high school by testing whether $\\beta\\tiny F2$ = $\\beta\\tiny M2$ . contrast gender#c.ed2,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender#c.ed2 |\r(Female vs base) | -1528.09 187.09 -8.17 0.000\r----------------------------------------------------------\rThe difference in the slopes (women versus men) is $-1,528.09$. For every year of education beyond the 12th year, the income for men increases by $1,528.09$ more than for women. ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:1","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Comparing slopes across education let’s examine the change in slope between high school graduates and non–high school graduates for men. is $\\beta\\tiny M2$ = $\\beta\\tiny M1$ ? As shown in table , the symbolic names for these coefficients are 1.gender#ed2 and 1.gender#ed1. We can compare these coefficients using the lincom command, as shown below. lincom 1.gender#c.ed2 - 1.gender#c.ed1 ( 1) - 1bn.gender#c.ed1 + 1bn.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 3970.93 212.70 18.67 0.000 3554.04 4387.83\r------------------------------------------------------------------------------\rMen show a significantly higher slope after graduating high school than men who have not graduated high school. The difference (comparing high school graduates with non–high school graduates) is 3,970.93. We can formulate the same kind of test for women, comparing the educ slope for high school graduates with that for non–high school graduates. lincom 2.gender#c.ed2 - 2.gender#c.ed1 Is $\\beta\\tiny F2$ = $\\beta\\tiny F1$ ? ( 1) - 2.gender#c.ed1 + 2.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 2287.94 147.26 15.54 0.000 1999.30 2576.58\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:2","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 Difference in differences of slopes（gain in slope） The previous section showed that, for men, the educ slope after graduating high school minus the slope before graduating high school equals 3,970.93. Let’s call this the gain in slope due to graduating high school. For women, the gain in slope due to graduating high school is 2,287.94. We might ask if the gain in slope due to graduating high school differs by gender. The lincom command below tests the gain in slope for men compared with the gain in slope for women. lincom (1.gender#c.ed2 - 1.gender#c.ed1) - (2.gender#c.ed2 - 2.gender#c.ed1) ( 1) - 1bn.gender#c.ed1 + 2.gender#c.ed1 + 1bn.gender#c.ed2 - 2.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 1682.99 259.29 6.49 0.000 1174.78 2191.20\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:3","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.4 Comparing changes in intercepts Let’s now ask whether the jump in income at 12 years of education is equal for men and women. the income for men jumps by $3,382.01$ at 12 years of education, whereas the corresponding jump for women is $1,748.10$. Are these jumps equal? Is $\\alpha\\tiny F1$ = $\\alpha\\tiny M1$ ? contrast gender#hsgrad,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------------------------+---------------------------------------\rgender#hsgrad |\r(Female vs base) (HS Grad vs base) | -1633.91 766.98 -2.13 0.033\r----------------------------------------------------------------------------\rSome people might find that this test is more intuitive if performed using the following lincom command below. lincom 2.gender#1.hsgrad - 1.gender#1.hsgrad ( 1) - 1bn.gender#1.hsgrad + 2.gender#1.hsgrad = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | -1633.91 766.98 -2.13 0.033 -3137.23 -130.59\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:4","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.5 Computing and comparing adjusted means Let’s now turn our attention to how we can compute adjusted means for this regression model. Before we can compute adjusted means with respect to education (that is, educ), we need to know how to express the level of education in terms of hsgrad, ed1, and ed2. showcoding educ hsgrad ed1 ed2 //the command is not fit for stata18 Let’s now estimate the adjusted mean for a female (that is, gender=2) with 15 years of education, as shown below. To indicate 15 years of education, we specify that hsgrad equals 1, ed1 equals 12, and ed2 equals 3. margins,nopvalues at(gender=2 hsgrad=1 ed1=12 ed2=3) Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: gender = 2\rhsgrad = 1\red1 = 12\red2 = 3\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\r_cons | 18993.22 234.17 18534.24 19452.20\r--------------------------------------------------------------\rWe can estimate the adjusted mean of income for men and women with 15 years of education using the margins command below. margins gender,nopvalues at(hsgrad=1 ed1=12 ed2=3) Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: hsgrad = 1\red1 = 12\red2 = 3\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\rgender |\rMale | 33171.77 351.09 32483.62 33859.93\rFemale | 18993.22 234.17 18534.24 19452.20\r--------------------------------------------------------------\rSpecifying the r. contrast operator indicates we want to use reference group comparisons, comparing the adjusted mean of income for women versus men. margins r.gender,at(hsgrad=1 ed1=12 ed2=3) contrast(nowald pveffects) Contrasts of predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: hsgrad = 1\red1 = 12\red2 = 3\r----------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender |\r(Female vs Male) | -14178.55 422.06 -33.59 0.000\r----------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:5","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.6 Graphing adjusted means Let’s graph the adjusted means as a function of education and gender. To make this graph, we need to compute the adjusted means separately for men and women with 0 years of education, 12 years of education (assuming the absence and presence of a high school diploma), and 20 years of education. margins gender,at(hsgrad=0 ed1=0 ed2=0) /// at(hsgrad=0 ed1=12 ed2=0) /// at(hsgrad=1 ed1=12 ed2=0) /// at(hsgrad=1 ed1=12 ed2=8) nopvalues Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: hsgrad = 0\red1 = 0\red2 = 0\r2._at: hsgrad = 0\red1 = 12\red2 = 0\r3._at: hsgrad = 1\red1 = 12\red2 = 0\r4._at: hsgrad = 1\red1 = 12\red2 = 8\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\r_at#gender |\r1#Male | 16576.36 1384.62 13862.46 19290.26\r1#Female | 6757.19 910.63 4972.32 8542.05\r2#Male | 17616.85 590.78 16458.91 18774.80\r2#Female | 9656.48 345.83 8978.65 10334.32\r3#Male | 20998.86 297.50 20415.75 21581.96\r3#Female | 11404.58 179.77 11052.22 11756.94\r4#Male | 53459.97 1042.02 51417.56 55502.37\r4#Female | 31640.96 761.69 30148.02 33133.90\r--------------------------------------------------------------\rpreserve clear input educ yhatm yhatf 0 16576.36 6757.187 12 17616.85 9656.485 12 20998.86 11404.58 20 53459.97 31640.96 end graph twoway line yhatm yhatf educ,xline(12)legend(label(1 \"Men\")label(2 \"Women\")) /// xtitle(Education)ytitle(Adjusted mean) Fitted values from piecewise model with one knot and one jump at educ = 12\rWe can automate the creation of this graph by extending the strategy First, we use the matrix command to create a matrix named yhat that contains the adjusted means computed by the margins command. **First,rerun the -margins- command from above quietly margins gender, at(hsgrad=0 ed1=0 ed2=0) /// at(hsgrad=0 ed1=12 ed2=0) /// at(hsgrad=1 ed1=12 ed2=0) /// at(hsgrad=1 ed1=12 ed2=8) ** store the adjusted means in a matrix named -yhat- matrix yhat = r(b)' //NOTE: We must use transpose here Now, we encounter a twist because the adjusted means are computed as a function two variables (education and gender). Looking at the output of the margins command, let’s focus on the order in which the adjusted means are displayed with respect to education and gender. Eight adjusted means are shown, corresponding to the following levels of educ, hsgrad, and gender: educ=0, hsgrad=0, gender=1 educ=0, hsgrad=0, gender=2 educ=12, hsgrad=0, gender=1 educ=12, hsgrad=0, gender=2 educ=12, hsgrad=1, gender=1 educ=12, hsgrad=1, gender=2 educ=20, hsgrad=1, gender=1 educ=20, hsgrad=1, gender=2 The matrix command is used to create a matrix named educ that reflects the levels of education shown in the bulleted list above. The matrix command is used again, this time to create a matrix called gender that contains the levels of gender shown in the bulleted list above. * store levels of education in a matrix named -educ- matrix educ = (0\\0\\12\\12\\12\\12\\20\\20) * store levels of gender in a matrix named -gender- matrix gender = (1\\2\\1\\2\\1\\2\\1\\2) The svmat command is then used three times, to save the matrices named yhat, educ, and gender to the current dataset. The list command is then used to show the variables yhat1, educ1, and gender1 for the first 10 observations of the dataset. svmat yhat //save the matrix -yhat- to the current dataset svmat educ //save the matrix -educ- to the current dataset svmat gender //save the matrix -gender- to the current dataset list yhat1 educ1 gender1 in 1/10,sep(2) +----------------------------+\r| yhat1 educ1 gender1 |\r|----------------------------|\r1. | 16576.36 0 1 |\r2. | 6757.188 0 2 |\r|----------------------------|\r3. | 17616.85 12 1 |\r4. | 9656.484 12 2 |\r|----------------------------|\r5. | 20998.86 12 1 |\r6. | 11404.58 12 2 |\r|----------------------------|\r7. | 53459.96 20 1 |\r8. | 31640.96 20 2 |\r|----------------------","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:1:6","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Two knots and two jumps This section covers piecewise regression models with two knots and two jumps interacted with a categorical variable. For example,income was predicted from education modeled in a piecewise fashion with two knots and two jumps at 12 and 16 years of education.Furthermore, these piecewise terms were interacted with gender. Piecewise regression with two knots and two jumps, labeled with estimated slopes\rThe jump at 12 years of education for men is labeled as $\\alpha\\tiny M1$. The jump at 16 years of education for men is labeled as $\\alpha\\tiny M2$. These corresponding jumps for women are labeled $\\alpha\\tiny F1$and $\\alpha\\tiny F2$. Piecewise regression with two knots and two jumps, labeled with estimated intercepts\rLet’s now illustrate how to perform this analysis. First, the mkspline command is used to create the variables ed1, ed2, and ed3 based on the knots that are specified at 12 and 16 years of education use gss_ivrm.dta mkspline ed1 12 ed2 16 ed3 = educ The variables are now ready to run the piecewise regression model. The regress command, shown below, includes ibn.gender used in combination with the noconstant option. This models separate intercepts for men and women. The model also includes the interaction of ibn.gender with i.hsgrad and i.cograd. This models the jump in income due to graduating high school and graduating college separately for men and women. Finally, the model includes the interaction of ibn.gender with c.ed1, c.ed2, and c.ed3. This models the educ slope for non–high school graduates, high school graduates, and college graduates, estimating these slopes separately for men and women. The variable i.race is included as a covariate. reg realrinc ibn.gender ibn.gender#(hsgrad cograd c.ed1 c.ed2 c.ed3) i.race,vce(robust) noconstant noci Linear regression Number of obs = 32,183\rF(14, 32169) = 2602.08\rProb \u003e F = 0.0000\rR-squared = 0.4885\rRoot MSE = 24897\r--------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rMale | 17084.37 1389.70 12.29 0.000\rFemale | 7262.50 921.90 7.88 0.000\r|\rgender#hsgrad |\rMale#HS Grad | 4927.53 655.33 7.52 0.000\rFemale#HS Grad | 2400.89 372.21 6.45 0.000\r|\rgender#cograd |\rMale#CO Grad | 9230.72 1224.50 7.54 0.000\rFemale#CO Grad | 1615.19 789.62 2.05 0.041\r|\rgender#c.ed1 |\rMale | 89.40 151.40 0.59 0.555\rFemale | 243.64 98.84 2.46 0.014\r|\rgender#c.ed2 |\rMale | 1592.64 255.81 6.23 0.000\rFemale | 1724.74 182.70 9.44 0.000\r|\rgender#c.ed3 |\rMale | 4279.36 521.83 8.20 0.000\rFemale | 3608.45 496.99 7.26 0.000\r|\rrace |\rblack | -3361.24 246.84 -13.62 0.000\rother | -1813.49 840.47 -2.16 0.031\r--------------------------------------------------------\rLet’s now see how to form comparisons among these coefficients. Specifically, let’s learn how to compare slopes between men and women compare slopes across the levels of education, comparing college graduates, high school graduates, and non–high school graduates compare changes in slope between men and women due to graduating high school and due to graduating college compare changes in intercept (the jumps in income due to graduating high school and college) by gender compare changes in intercept (the jumps in income due to graduating high school and college) across levels of education ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:0","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Comparing slopes across gender (Cross Section) Let’s begin by testing the equality of the slopes between women and men who have not graduated high school—testing whether $\\beta\\tiny F1$= $\\beta\\tiny M1$. contrast gender#c.ed1,pveffects nowald //slope between Men and Women (not-grad) Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender#c.ed1 |\r(Female vs base) | 154.25 179.30 0.86 0.390\r----------------------------------------------------------\rthe difference in the educ slope between women and men before graduating high school is 154.25. However, this difference is not statistically significant. In other words, prior to graduating high school, the educ slope is not significantly different for men and women. contrast gender#c.ed2,pveffects nowald //slope between Men and Women (grad) Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender#c.ed2 |\r(Female vs base) | 132.11 314.04 0.42 0.674\r----------------------------------------------------------\rcontrast gender#c.ed3,pveffects nowald //slope between Men and Women (grad-col) Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender#c.ed3 |\r(Female vs base) | -670.91 721.07 -0.93 0.352\r----------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:1","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.2 Comparing slopes across education Let’s begin by comparing the slopes for high school graduates with non–high school graduates, starting with men. testing whether $\\beta\\tiny M2$ = $\\beta\\tiny M1$ . comparing the slopes for high school graduates with non-high school graduates (Men). lincom 1.gender#c.ed2 - 1.gender#c.ed1 ( 1) - 1bn.gender#c.ed1 + 1bn.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 1503.24 297.13 5.06 0.000 920.85 2085.63\r------------------------------------------------------------------------------\rcomparing the slopes for high school graduates with non-high school graduates (Women). lincom 2.gender#c.ed2 - 2.gender#c.ed1 ( 1) - 2.gender#c.ed1 + 2.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 1481.10 208.81 7.09 0.000 1071.82 1890.38\r------------------------------------------------------------------------------\rMen : cograd vs. hsgrad lincom 1.gender#c.ed3 - 1.gender#c.ed2 ( 1) - 1bn.gender#c.ed2 + 1bn.gender#c.ed3 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 2686.72 581.27 4.62 0.000 1547.41 3826.03\r------------------------------------------------------------------------------\rWomen : cograd vs. hsgrad lincom 2.gender#c.ed3 - 2.gender#c.ed2 ( 1) - 2.gender#c.ed2 + 2.gender#c.ed3 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 1883.71 530.20 3.55 0.000 844.49 2922.93\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:2","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.3 Difference in differences of slopes Let’s now test the gain in slope due to graduating high school for men compared with the gain in slope due to graduating high school for women, which is ($\\beta\\tiny M2$ - $\\beta\\tiny M1$) -($\\beta\\tiny F2$ - $\\beta\\tiny F1$) lincom (1.gender#c.ed2 - 1.gender#c.ed1) - (2.gender#c.ed2 - 2.gender#c.ed1) ( 1) - 1bn.gender#c.ed1 + 2.gender#c.ed1 + 1bn.gender#c.ed2 - 2.gender#c.ed2 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 22.14 361.97 0.06 0.951 -687.33 731.61\r------------------------------------------------------------------------------\rlincom (1.gender#c.ed3 - 1.gender#c.ed2) - (2.gender#c.ed3 - 2.gender#c.ed2) ( 1) - 1bn.gender#c.ed2 + 2.gender#c.ed2 + 1bn.gender#c.ed3 - 2.gender#c.ed3 = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 803.01 786.64 1.02 0.307 -738.84 2344.87\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:3","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.4 Comparing changes in intercepts by gender Let’s now ask whether the jump in income at 12 years of education is the same for men and women. Let’s test whether these jumps are equal (whether $\\alpha\\tiny F1$= $\\alpha\\tiny M1$ ). contrast gender#hsgrad,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------------------------+---------------------------------------\rgender#hsgrad |\r(Female vs base) (HS Grad vs base) | -2526.64 752.53 -3.36 0.001\r----------------------------------------------------------------------------\rtest whether these jump are equal(αF2=αM2？) contrast gender#cograd,pveffects nowald Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------------------------+---------------------------------------\rgender#cograd |\r(Female vs base) (CO Grad vs base) | -7615.52 1455.05 -5.23 0.000\r----------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:4","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.5 Comparing changes in intercepts by education We might ask whether the jump due to graduating college ($9,230.72$) is equal to the jump due to graduating high school ($4,927.53$). whether the jump due to graduating college is equal to the jump due to graduating high school(Men) lincom 1.gender#1.cograd - 1.gender#1.hsgrad ( 1) - 1bn.gender#1.hsgrad + 1bn.gender#1.cograd = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | 4303.19 1327.65 3.24 0.001 1700.93 6905.44\r------------------------------------------------------------------------------\rlincom 2.gender#1.cograd - 2.gender#1.hsgrad ( 1) - 2.gender#1.hsgrad + 2.gender#1.cograd = 0\r------------------------------------------------------------------------------\rrealrinc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r(1) | -785.70 831.22 -0.95 0.345 -2414.92 843.52\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:5","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.6 Computing and comparing adjusted means Let’s now see how to compute adjusted means in the context of this model. To compute adjusted means with respect to education, we need to express education in terms of hsgrad, cograd, ed1, ed2, and ed3. showcoding educ hsgrad cograd ed1 ed2 ed3 We can estimate the adjusted mean for men and women (separately) in one margins command. hoding education constant at 15-years of education margins gender,nopvalues at(hsgrad=1 cograd=0 ed1=12 ed2=3 ed3=0) Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: hsgrad = 1\rcograd = 0\red1 = 12\red2 = 3\red3 = 0\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\rgender |\rMale | 27322.43 652.72 26043.07 28601.78\rFemale | 17221.21 488.53 16263.68 18178.75\r--------------------------------------------------------------\rLet’s now use the margins command to compare the adjusted mean of income for women versus men among those with 15 years of education. Specifying the r. contrast operator indicates we want to use reference group comparisons. margins r.gender,at(hsgrad=1 cograd=0 ed1=12 ed2=3 ed3=0) Contrasts of predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: hsgrad = 1\rcograd = 0\red1 = 12\red2 = 3\red3 = 0\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rgender | 1 154.10 0.0000\r|\rDenominator | 32169\r------------------------------------------------\r-------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. [95% conf. interval]\r------------------+------------------------------------------------\rgender |\r(Female vs Male) | -10101.21 813.72 -11696.14 -8506.28\r-------------------------------------------------------------------\rat 15 years of education, the adjusted mean of income for men is $10,101.21$ higher than for women. ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:6","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.7 Graphing adjusted means margins gender,at(hsgrad=0 cograd=0 ed1=0 ed2=0 ed3=0) /// at(hsgrad=0 cograd=0 ed1=12 ed2=0 ed3=0) /// at(hsgrad=1 cograd=0 ed1=12 ed2=0 ed3=0) /// at(hsgrad=1 cograd=0 ed1=12 ed2=4 ed3=0) /// at(hsgrad=1 cograd=1 ed1=12 ed2=4 ed3=0) /// at(hsgrad=1 cograd=1 ed1=12 ed2=4 ed3=4) Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: hsgrad = 0\rcograd = 0\red1 = 0\red2 = 0\red3 = 0\r2._at: hsgrad = 0\rcograd = 0\red1 = 12\red2 = 0\red3 = 0\r3._at: hsgrad = 1\rcograd = 0\red1 = 12\red2 = 0\red3 = 0\r4._at: hsgrad = 1\rcograd = 0\red1 = 12\red2 = 4\red3 = 0\r5._at: hsgrad = 1\rcograd = 1\red1 = 12\red2 = 4\red3 = 0\r6._at: hsgrad = 1\rcograd = 1\red1 = 12\red2 = 4\red3 = 4\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r_at#gender |\r1#Male | 16544.24 1384.77 11.95 0.000 13830.04 19258.45\r1#Female | 6722.38 909.92 7.39 0.000 4938.90 8505.85\r2#Male | 17616.99 590.89 29.81 0.000 16458.82 18775.15\r2#Female | 9646.09 345.63 27.91 0.000 8968.64 10323.54\r3#Male | 22544.52 282.66 79.76 0.000 21990.49 23098.54\r3#Female | 12046.99 142.20 84.72 0.000 11768.27 12325.71\r4#Male | 28915.06 896.20 32.26 0.000 27158.47 30671.66\r4#Female | 18945.96 667.08 28.40 0.000 17638.46 20253.45\r5#Male | 38145.78 830.91 45.91 0.000 36517.16 39774.40\r5#Female | 20561.15 422.35 48.68 0.000 19733.33 21388.97\r6#Male | 55263.21 1736.33 31.83 0.000 51859.94 58666.48\r6#Female | 34994.95 1760.66 19.88 0.000 31543.99 38445.92\r------------------------------------------------------------------------------\rpreserve clear input educ yhatm yhatf 0 16544.24 6722.377 12 17616.99 9646.094 12 22544.52 12046.99 16 28915.06 18945.96 16 38145.78 20561.15 20 55263.21 34994.95 end graph twoway line yhatm yhatf educ,xlabel(0(4)20) xline(12 16) restore Fitted values from piecewise model with two knots and two jumps\rAutomate the creation of the graph *First,rerun the -margins- command from above quietly margins gender,at(hsgrad=0 cograd=0 ed1=0 ed2=0 ed3=0) /// at(hsgrad=0 cograd=0 ed1=12 ed2=0 ed3=0) /// at(hsgrad=1 cograd=0 ed1=12 ed2=0 ed3=0) /// at(hsgrad=1 cograd=0 ed1=12 ed2=4 ed3=0) /// at(hsgrad=1 cograd=1 ed1=12 ed2=4 ed3=0) /// at(hsgrad=1 cograd=1 ed1=12 ed2=4 ed3=4) /// *Store the adjusted means(from the -margins- command) in a matrix named -yhat- matrix yhat = r(b)' //note: we must transpose r(b) here *Store levels of education in a matrix named -educ- matrix educ = (0\\0\\12\\12\\12\\12\\16\\16\\16\\16\\20\\20) *Store levels of gender in a matrix named -gender- matrix gender = (1\\2\\1\\2\\1\\2\\1\\2\\1\\2\\1\\2) svmat yhat //save the matrix -yhat- to the current dataset svmat educ //save the matrix -educ- to the current dataset svmat gender //save the matrix -gender- to the current dataset graph twoway (line yhat1 educ1 if gender1==1) /// (line yhat1 educ1 if gender1==2), /// xline(12 16) legend(label(1 \"Men\") label(2 \"Women\")) /// xtitle(Education) ytitle(Adjusted mean) ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:2:7","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Comparing coding schemes This chapter has focused on one coding scheme for fitting models that interact a categorical variable and a continuous variable fit in a piecewise manner.Depending on your research question, another coding scheme might be more useful. ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:0","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Coding scheme #1 This coding scheme will be called coding scheme #1. The noheader option is used in this and subsequent examples to save space. use gss_ivrm.dta mkspline ed1 12 ed2 = educ reg realrinc ibn.gender ibn.gender#(i.hsgrad c.ed1 c.ed2) i.race,vce(robust) noconstant noheader noci --------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rMale | 17144.66 1389.51 12.34 0.000\rFemale | 7325.48 922.52 7.94 0.000\r|\rgender#hsgrad |\rMale#HS Grad | 3382.00 661.55 5.11 0.000\rFemale#HS Grad | 1748.10 389.36 4.49 0.000\r|\rgender#c.ed1 |\rMale | 86.71 151.38 0.57 0.567\rFemale | 241.61 98.92 2.44 0.015\r|\rgender#c.ed2 |\rMale | 4057.64 150.38 26.98 0.000\rFemale | 2529.55 110.43 22.91 0.000\r|\rrace |\rblack | -3521.34 246.66 -14.28 0.000\rother | -1946.16 839.73 -2.32 0.020\r--------------------------------------------------------\rIntercept and slope coefficients from piecewise regression fit using coding scheme #1\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:1","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.2 Coding scheme #2 Let’s now fit a model using what I call coding scheme #2. This coding scheme is the same as coding scheme #1, except that the marginal option is used on the mkspline command. use gss_ivrm.dta mkspline ed1m 12 ed2m = educ,marginal reg realrinc ibn.gender ibn.gender#(i.hsgrad c.ed1m c.ed2m) i.race,vce(robust) noconstant noheader noci --------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rMale | 17144.66 1389.51 12.34 0.000\rFemale | 7325.48 922.52 7.94 0.000\r|\rgender#hsgrad |\rMale#HS Grad | 3382.00 661.55 5.11 0.000\rFemale#HS Grad | 1748.10 389.36 4.49 0.000\r|\rgender#c.ed1m |\rMale | 86.71 151.38 0.57 0.567\rFemale | 241.61 98.92 2.44 0.015\r|\rgender#c.ed2m |\rMale | 3970.93 212.70 18.67 0.000\rFemale | 2287.94 147.26 15.54 0.000\r|\rrace |\rblack | -3521.34 246.66 -14.28 0.000\rother | -1946.16 839.73 -2.32 0.020\r--------------------------------------------------------\rSummary of regression results and meaning of coefficients for coding schemes #1 and #2\rYou can see that the only difference is in the final row of the table. Coding scheme #1 estimates $\\beta\\tiny M2$ and $\\beta\\tiny F2$, whereas coding scheme #2 estimates ($\\beta\\tiny M2$-$\\beta\\tiny M1$)and ($\\beta\\tiny F2$-$\\beta\\tiny F1$). ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:2","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.3 Coding scheme #3 This coding scheme is like coding scheme #1, in that the marginal option is omitted from the mkspline command. Unlike coding scheme #1, coding scheme #3 specifies i.gender (instead of ibn.gender) and omits the noconstant option use gss_ivrm.dta mkspline ed1 12 ed2 = educ reg realrinc i.gender##(i.hsgrad c.ed1 c.ed2) i.race,vce(robust) noheader noci --------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rFemale | -9819.17 1638.56 -5.99 0.000\r|\rhsgrad |\rHS Grad | 3382.00 661.55 5.11 0.000\red1 | 86.71 151.38 0.57 0.567\red2 | 4057.64 150.38 26.98 0.000\r|\rgender#hsgrad |\rFemale#HS Grad | -1633.91 766.98 -2.13 0.033\r|\rgender#c.ed1 |\rFemale | 154.90 179.32 0.86 0.388\r|\rgender#c.ed2 |\rFemale | -1528.09 187.09 -8.17 0.000\r|\rrace |\rblack | -3521.34 246.66 -14.28 0.000\rother | -1946.16 839.73 -2.32 0.020\r|\r_cons | 17144.66 1389.51 12.34 0.000\r--------------------------------------------------------\r","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:3","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.4 Coding scheme #4 Finally, let’s consider a fourth coding scheme. This coding scheme is like coding scheme #3, except that the marginal option is included on the mkspline command. use gss_ivrm.dta mkspline ed1m 12 ed2m = educ,marginal reg realrinc i.gender##(i.hsgrad c.ed1m c.ed2m) i.race,vce(robust) noheader noci --------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------+---------------------------------------\rgender |\rFemale | -9819.17 1638.56 -5.99 0.000\r|\rhsgrad |\rHS Grad | 3382.00 661.55 5.11 0.000\red1m | 86.71 151.38 0.57 0.567\red2m | 3970.93 212.70 18.67 0.000\r|\rgender#hsgrad |\rFemale#HS Grad | -1633.91 766.98 -2.13 0.033\r|\rgender#c.ed1m |\rFemale | 154.90 179.32 0.86 0.388\r|\rgender#c.ed2m |\rFemale | -1682.99 259.29 -6.49 0.000\r|\rrace |\rblack | -3521.34 246.66 -14.28 0.000\rother | -1946.16 839.73 -2.32 0.020\r|\r_cons | 17144.66 1389.51 12.34 0.000\r--------------------------------------------------------\rSummary of regression results and meaning of coefficients for coding schemes #3 and #4\rIn comparing coding schemes #3 and #4, the only difference is in the final row of the table. Coding scheme #3 estimates $\\beta\\tiny MM2$ and ($\\beta\\tiny F2$-$\\beta\\tiny M2$). By comparison, coding scheme #4 estimates ($\\beta\\tiny M2$-$\\beta\\tiny M1$) and($\\beta\\tiny F2$-$\\beta\\tiny F1$)-($\\beta\\tiny M2$-$\\beta\\tiny M1$) . ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:4","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.5 Choosing coding schemes We can deliberately choose the coding scheme that might make the most sense given our research question. Say that the emphasis of your research study was to test gender differences in the educ slope among high school graduates (that is,$\\beta\\tiny F2$-$\\beta\\tiny M2$). In that case, coding scheme #3 might be the most useful, because the coefficient associated with gender#ed2 directly estimates this difference ($\\beta\\tiny F2$-$\\beta\\tiny M2$). Had you chosen coding scheme #1, you could still estimate this difference, but would need to also use the contrast gender#c.ed1 command to compute this difference. Instead, imagine that your research question focused on gender differences in the educ slope for high school graduates versus non–high school graduates. In that case, coding system #4 might be the most useful because the coefficient associated with gender#ed2m directly estimates this difference ($\\beta\\tiny F2$-$\\beta\\tiny F1$)-($\\beta\\tiny M2$-$\\beta\\tiny M1$). ","date":"2024-01-11","objectID":"/12.chapter12piecewise-by-categorical-interactions/:3:5","tags":["Interaction","stata"],"title":"Chapter12 ：Piecewise by categorical interactions","uri":"/12.chapter12piecewise-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter explores models that include a categorical variable interacted with two continuous variables. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter explores models that include a categorical variable interacted with two continuous variables. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:0:0","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Linear by linear by categorical interactions In this section, we will explore whether the size of the c.age##c.educ interaction depends on gender. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:0","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Fitting separate models for males and females To get a general sense of the size of the c.age#c.educ interaction separately for males and females, let’s fit separate models for males and females. Doing so separately for each level of gender by including the by gender, sort: prefix. (The vsquish and noheader options are used to save space.) The first set of results is restricted to analyzing only males, and the second set is restricted to analyzing only females. use gss_ivrm.dta keep if (age\u003e=22 \u0026 age\u003c=55) \u0026 (educ\u003e=12) by gender,sort:regress realrinc c.age##c.educ,vce(robust)vsquish noheader --------------------------------------------------------------------------------------------------------------\r-\u003e gender = Male\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage | -1092.29 195.71 -5.58 0.000 -1475.92 -708.65\reduc | -1831.07 526.01 -3.48 0.001 -2862.14 -799.99\rc.age#c.educ | 134.46 14.35 9.37 0.000 106.33 162.60\r_cons | 25275.91 7128.77 3.55 0.000 11302.24 39249.58\r------------------------------------------------------------------------------\r--------------------------------------------------------------------------------------------------------------\r-\u003e gender = Female\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage | -876.56 158.24 -5.54 0.000 -1186.74 -566.39\reduc | -966.11 426.78 -2.26 0.024 -1802.69 -129.54\rc.age#c.educ | 87.95 11.97 7.34 0.000 64.47 111.42\r_cons | 17020.70 5661.95 3.01 0.003 5922.30 28119.10\r------------------------------------------------------------------------------\rWe can visualize this in two different ways, by focusing on the slope in the direction of age or by focusing on the slope in the direction of educ. Let’s begin by making a graph that focuses on the slope in the direction of age by placing age on the $x$ axis, with separate lines for educ. Fitted values for age by education interaction for males (left) and females (right)\rAmong males, the age slope increases by 134.46 units for every oneyear increase in educ. Among females, the age slope increases by 87.95 units for every one-year increase in educ. We can visualize the c.age#c.educ interaction another way, focusing on the educ slope by placing educ on the $x$ axis, with separate lines for age. Fitted values for age by education interaction for males (left) and females (right) with education on the $x$ axis\rFor males, the educ slope increases by 134.46 units for every one-year increase in age. For females, the educ slope increases by 87.95 units for every oneyear increase in age. To summarize, the coefficient for c.age#c.educ is 134.46 for males and is 87.95 for females. This suggests that the size of the c.age#c.educ coefficient may be significantly greater for males than for females. Let’s test this by analyzing males and females together in a single model. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:1","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Fitting a combined model for males and females We now create a regression model that includes both males and females and predicts realrinc from age, educ, and the interaction of these two continuous variables. By specifying ibn.gender in conjunction with the noconstant option, the model fits separate intercepts by gender. By specifying the interaction of ibn.gender with c.age, with c.educ, and with c.age#c.educ, the model fits separate estimates of age, educ, and age#educ by gender. reg realrinc ibn.gender ibn.gender#(c.age c.educ c.age#c.educ)i.race,vce(robust) noconstant noci Linear regression Number of obs = 22,367\rF(10, 22357) = 3126.19\rProb \u003e F = 0.0000\rR-squared = 0.5339\rRoot MSE = 24543\r------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r--------------------+---------------------------------------\rgender |\rMale | 27044.09 7125.42 3.80 0.000\rFemale | 19020.31 5695.44 3.34 0.001\r|\rgender#c.age |\rMale | -1116.24 195.43 -5.71 0.000\rFemale | -903.50 158.76 -5.69 0.000\r|\rgender#c.educ |\rMale | -1929.04 526.08 -3.67 0.000\rFemale | -1063.55 428.25 -2.48 0.013\r|\rgender#c.age#c.educ |\rMale | 136.00 14.34 9.48 0.000\rFemale | 89.52 12.01 7.46 0.000\r|\rrace |\rblack | -3067.11 305.07 -10.05 0.000\rother | 493.01 1192.16 0.41 0.679\r------------------------------------------------------------\rWe can express these results as two though there are two regression equations, one for males and one for females. \\begin{align} Males:\\widehat{realrinc} = 27044.09 + - 1116.24age + - 1929.04educ \\notag\\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ +136.00age*educ + -3067.11black + 493.01other \\notag \\ \\end{align} \\begin{align} Females:\\widehat{realrinc} = 19020.31 + - 903.50age + - 1063.55educ \\notag\\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ +89.52age*educ + -3067.11black + 493.01other \\notag \\ \\end{align} Let’s now test the difference of the c.age#c.educ interaction for females versus males using the contrast command below. contrast gender#c.age#c.educ,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r--------------------+---------------------------------------\rgender#c.age#c.educ |\r(Female vs base) | -46.48 18.71 -2.48 0.013\r------------------------------------------------------------\rThis test is significant,This means that the c.age#c.educ interaction is significantly lower for females than for males. Let’s explore how to interpret this interaction. Note! What about the lower order effects? We have been focusing on the gender#c.age#c.educ interaction, but you might wonder about the lower order effects, such as gender#c.age or gender#c.educ. It is important to include these effects in the model to preserve the interpretation of the gender#c.age#c.educ interaction. However, there is little to gain by trying to interpret these effects. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:2","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 Interpreting the interaction focusing in the age slope To help interpret this interaction, let’s visualize it by making a graph that focuses on the age slope. margins gender, at(age=(22 55) educ=(12(2)20)) marginsplot,bydimension(gender) plotdimension(educ,allsimple)legend(subtitle(Education) rows(2)) noci Fitted values by age ( axis), education (separate lines), and gender (separate panels)\rFor males, the age slope increases by 136.00 units for every one-unit increase in education. For females, the age slope increases by 89.52 units for every one-unit increase in education. The test of the gender#c.age#c.educ effect represents the difference in these interaction terms and this graph shows one way to visualize this. The margins command can be used to show the size of the age slope by specifying the dydx(age) option. Let’s use the margins command to estimate the age slope for each of the levels of education expressed as a separate line in figure margins gender,at(educ=(12(2)20)) dydx(age) Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: educ = 12\r2._at: educ = 14\r3._at: educ = 16\r4._at: educ = 18\r5._at: educ = 20\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage |\r_at#gender |\r1#Male | 515.76 34.61 14.90 0.000 447.93 583.60\r1#Female | 170.70 19.56 8.73 0.000 132.36 209.03\r2#Male | 787.76 28.15 27.98 0.000 732.58 842.94\r2#Female | 349.73 16.77 20.85 0.000 316.85 382.61\r3#Male | 1059.76 45.09 23.50 0.000 971.38 1148.14\r3#Female | 528.76 36.51 14.48 0.000 457.19 600.33\r4#Male | 1331.76 70.14 18.99 0.000 1194.28 1469.24\r4#Female | 707.80 59.48 11.90 0.000 591.20 824.39\r5#Male | 1603.76 97.22 16.50 0.000 1413.20 1794.32\r5#Female | 886.83 83.05 10.68 0.000 724.06 1049.60\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:3","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.4 Interpreting the interaction focusing on the educ slope Now, let’s visualize this interaction by making a graph that focuses on the educ slope. margins gender, at(age=(25(10)55) educ=(12 20)) marginsplot, bydimension(gender) xdimension(educ) noci legend(rows(2)subtitle(Age)) Fitted values by education ( axis), age (separate lines), and gender (separate panels)\rThis graph illustrates the gender#c.age#c.educ interaction by showing how the educ slope increases more rapidly as a function of age for males than for females. The dydx(educ) option can be used with the margins command to compute the educ slope for each of the lines displayed in figure margins gender,at(age=(25(10)55)) dydx(educ) Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: educ\r1._at: age = 25\r2._at: age = 35\r3._at: age = 45\r4._at: age = 55\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\reduc |\r_at#gender |\r1#Male | 1470.96 206.19 7.13 0.000 1066.82 1875.10\r1#Female | 1174.36 155.32 7.56 0.000 869.91 1478.81\r2#Male | 2830.96 144.29 19.62 0.000 2548.14 3113.78\r2#Female | 2069.52 104.23 19.85 0.000 1865.22 2273.83\r3#Male | 4190.97 200.68 20.88 0.000 3797.61 4584.32\r3#Female | 2964.69 162.58 18.24 0.000 2646.02 3283.35\r4#Male | 5550.97 317.61 17.48 0.000 4928.43 6173.50\r4#Female | 3859.85 266.13 14.50 0.000 3338.21 4381.49\r------------------------------------------------------------------------------\r","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:4","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.5 Estimating and comparing adjusted means by gender The difference in the adjusted means by gender varies as a function of age and educ due to the interaction of gender with c.age#c.educ. Thus, any comparisons by gender should be performed by specifying a particular value of age and educ. The size of the difference (as well as the significance of the difference) between males and females depends on both educ and age. You could repeat the margins commands above to obtain comparisons between males and females for a variety ofvalues of age and educ. Or you can specify multiple values at once within the margins command. or example, the margins command below estimates the adjusted mean for males and females for the combinations of 12, 15, and 20 years of education and 30, 40, and 50 years of age margins gender,at(educ=(12 16 20)age=(30 40 50)) Predictive margins Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 30\reduc = 12\r2._at: age = 30\reduc = 16\r3._at: age = 30\reduc = 20\r4._at: age = 40\reduc = 12\r5._at: age = 40\reduc = 16\r6._at: age = 40\reduc = 20\r7._at: age = 50\reduc = 12\r8._at: age = 50\reduc = 16\r9._at: age = 50\reduc = 20\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r_at#gender |\r1#Male | 18995.85 290.94 65.29 0.000 18425.60 19566.10\r1#Female | 11006.03 210.47 52.29 0.000 10593.50 11418.57\r2#Male | 27599.71 480.25 57.47 0.000 26658.37 28541.04\r2#Female | 17493.80 332.35 52.64 0.000 16842.37 18145.22\r3#Male | 36203.56 1106.97 32.71 0.000 34033.83 38373.29\r3#Female | 23981.56 788.13 30.43 0.000 22436.77 25526.36\r4#Male | 24153.48 377.11 64.05 0.000 23414.31 24892.64\r4#Female | 12713.02 213.38 59.58 0.000 12294.77 13131.26\r5#Male | 38197.33 507.34 75.29 0.000 37202.92 39191.75\r5#Female | 22781.44 373.68 60.96 0.000 22048.99 23513.88\r6#Male | 52241.19 1088.80 47.98 0.000 50107.08 54375.31\r6#Female | 32849.85 845.68 38.84 0.000 31192.26 34507.45\r7#Male | 29311.10 662.83 44.22 0.000 28011.91 30610.30\r7#Female | 14420.00 351.09 41.07 0.000 13731.84 15108.17\r8#Male | 48794.96 831.12 58.71 0.000 47165.91 50424.02\r8#Female | 28069.07 659.91 42.53 0.000 26775.61 29362.54\r9#Male | 68278.83 1742.40 39.19 0.000 64863.60 71694.06\r9#Female | 41718.15 1479.36 28.20 0.000 38818.50 44617.79\r------------------------------------------------------------------------------\rmargins r.gender,at(educ=(12 16 20) age=(30 40 50)) Contrasts of predictive margins Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 30\reduc = 12\r2._at: age = 30\reduc = 16\r3._at: age = 30\reduc = 20\r4._at: age = 40\reduc = 12\r5._at: age = 40\reduc = 16\r6._at: age = 40\reduc = 20\r7._at: age = 50\reduc = 12\r8._at: age = 50\reduc = 16\r9._at: age = 50\reduc = 20\r-------------------------------------------------------\r| df F P\u003eF\r--------------------+----------------------------------\rgender@_at |\r(Female vs Male) 1 | 1 499.54 0.0000\r(Female vs Male) 2 | 1 296.57 0.0000\r(Female vs Male) 3 | 1 80.27 0.0000\r(Female vs Male) 4 | 1 701.62 0.0000\r(Female vs Male) 5 | 1 595.57 0.0000\r(Female vs Male) 6 | 1 196.14 0.0000\r(Female vs Male) 7 | 1 395.11 0.0000\r(Female vs Male) 8 | 1 381.32 0.0000\r(Female vs Male) 9 | 1 134.57 0.0000\rJoint | 4 483.36 0.0000\r|\rDenominator | 22357\r-------------------------------------------------------\r---------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. [95% conf. interval]\r--------------------+------------------------------------------------\rgender@_at |\r(Female vs Male) 1 | -7989.82 357.48 -8690.50 -7289.14\r(Female vs Male) 2 | -10105.91 586.83 -11256.13 -8955.68\r(Female vs Male) 3 | -12222.00 1364.16 -14895.84 -9548.16\r(Female vs Male) 4 | -11440.46 431.91 -12287.03 -10593.89\r(Female vs Male) 5 | -15415.90 631.69 -16654.05 -14177.75\r(Female vs Male) 6 | ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:1:5","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Linear by quadratic by categorical interactions In this section, we will explore whether the size of the c.educ#c.age#c.age interaction depends on gender. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:2:0","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Fitting separate models for males and females Let’s begin by fitting a model that estimates the c.educ#c.age#c.age interaction in two separate models: one fit for males and another fit for females. This is performed by using the by gender, sort: prefix before the regress command that predicts realrinc from c.educ#c.age#c.age. use gss_ivrm.dta keep if (age\u003e=22 \u0026 age\u003c=80) \u0026 (educ\u003e=12) by gender,sort:reg realrinc c.educ##c.age##c.age,vce(robust)vsquish noheader ------------------------------------------------------------------------------------\r-\u003e gender = Male\r------------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------------+----------------------------------------------------------------\reduc | -12420.54 1305.49 -9.51 0.000 -14979.50 -9861.58\rage | -6160.36 876.56 -7.03 0.000 -7878.55 -4442.17\rc.educ#c.age | 661.99 65.00 10.18 0.000 534.57 789.41\rc.age#c.age | 56.96 9.96 5.72 0.000 37.43 76.48\rc.educ#c.age#c.age | -6.21 0.74 -8.43 0.000 -7.66 -4.77\r_cons | 131388.59 17570.69 7.48 0.000 96947.42 165829.75\r------------------------------------------------------------------------------------\r------------------------------------------------------------------------------------\r-\u003e gender = Female\r------------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------------+----------------------------------------------------------------\reduc | -6103.40 867.43 -7.04 0.000 -7803.68 -4403.12\rage | -3703.10 599.49 -6.18 0.000 -4878.18 -2528.02\rc.educ#c.age | 366.29 45.81 8.00 0.000 276.49 456.08\rc.age#c.age | 35.83 7.23 4.95 0.000 21.65 50.00\rc.educ#c.age#c.age | -3.57 0.56 -6.43 0.000 -4.66 -2.48\r_cons | 69959.52 11406.57 6.13 0.000 47600.98 92318.06\r------------------------------------------------------------------------------------\rThis suggests that the size of this interaction might be more negative for males than for females. Before pursuing whether this difference is significant, let’s first visualize the c.educ#c.age#c.age interaction by gender to gain a further understanding of what this interaction means. Fitted values for education by age-squared interaction for males (left) and females (right)\rthe male exhibit a greater increase in the curvature in the relationship between age and income as a function of education than do females. Let’s test whether the c.educ#c.age#c.age interaction is significantly different for males versus females. To do this, we fit a combined model that includes both males and females to permit a statistical test of c.educ#c.age#c.age by gender. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:2:1","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.2 Fitting a common model for males and females Let’s fit one model for males and females together using a separate intercept and separate slopes coding system that provides separate intercept and slope estimates for males and females. Separate intercepts by gender are obtained by specifying ibn.gender in conjunction with the noconstant option. Then, the model uses the shortcut notation to interact ibn.gender with each term created by c.educ#c.age#c.age. reg realrinc ibn.gender ibn.gender#(c.educ##c.age##c.age) i.race,vce(robust)noconstant noci Linear regression Number of obs = 25,964\rF(14, 25950) = 2544.34\rProb \u003e F = 0.0000\rR-squared = 0.5263\rRoot MSE = 25748\r------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r--------------------------+---------------------------------------\rgender |\rMale | 133604.98 17548.76 7.61 0.000\rFemale | 73711.44 11412.10 6.46 0.000\r|\rgender#c.educ |\rMale | -12550.64 1305.36 -9.61 0.000\rFemale | -6329.01 867.97 -7.29 0.000\r|\rgender#c.age |\rMale | -6202.10 875.06 -7.09 0.000\rFemale | -3809.82 598.99 -6.36 0.000\r|\rgender#c.educ#c.age |\rMale | 665.21 64.93 10.24 0.000\rFemale | 374.24 45.78 8.17 0.000\r|\rgender#c.age#c.age |\rMale | 57.18 9.95 5.75 0.000\rFemale | 36.76 7.22 5.09 0.000\r|\rgender#c.educ#c.age#c.age |\rMale | -6.23 0.74 -8.47 0.000\rFemale | -3.65 0.55 -6.58 0.000\r|\rrace |\rblack | -3474.03 291.35 -11.92 0.000\rother | -299.12 1110.20 -0.27 0.788\r------------------------------------------------------------------\rWe can express results as separate regression equations for males and females, as shown below \\begin{align} Males:\\widehat{realrinc} = 133605 + -12550.64educ + -6202.10age \\notag\\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ +665.21educ × age + 57.18age^2+-6.23educ × age^2 \\notag \\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\ +-3474.03black + -299.12other \\notag \\ \\end{align} \\begin{align} Females:\\widehat{realrinc} = 73711.44 + -6329.01educ + -3809.82age \\notag\\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ +665.21educ × age + 57.18age^2+-6.23educ × age^2 \\notag \\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\ +-3474.03black + -299.12other \\notag \\ \\end{align} The coefficient for the c.educ#c.age#c.age interaction is $-6.23$ for males and is $-3.65$ for females. We can compare these coefficients using the contrast command, as shown below. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:2:2","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.3 Interpreting the interaction To help us understand this interaction, let’s visualize it by making a graph showing the c.educ#c.age#c.age interaction separately for males and females. compute adjusted means for age 22 to 90(in one-year increments) and for 12 to 20 years of education (in two-year increments),separately for males and females. margins gender,at(age=(22(1)80) educ=(12(2)20)) marginsplot,bydimension(gender) xdimension(age)plotdimension(educ,allsimp) noci recast(line) scheme(s1mono)legend(subtitle(Education)rows(1)) Fitted values by age ( axis), education (separate lines), and gender (separate panels)\rWe see a similar pattern for both males and females; as educ increases, the inverted U-shape for the relationship between income and age becomes more pronounced. However, this effect appears stronger for males than for females. This is confirmed by the significant gender#c.educ#c.age#c.age interaction. In other words, this interaction shows that the degree to which the quadratic effect of age changes as a function of educ is stronger for males than it is for females. ","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:2:3","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.4 Estimating and comparing adjusted means by gender The difference in income for males and females depends on both age and gender. The margins command can be used to compute estimates of, and differences in, the adjusted means by gender. margins gender,at(educ=16 age=30) Predictive margins Number of obs = 25,964\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: educ = 16\rage = 30\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rgender |\rMale | 27288.24 430.84 63.34 0.000 26443.78 28132.71\rFemale | 17867.20 303.52 58.87 0.000 17272.28 18462.12\r------------------------------------------------------------------------------\rBy adding the r. contrast operator to gender, we estimate the difference in these adjusted means, comparing females with males. This difference is significant. margins r.gender,at(educ=16 age=30) contrast(nowald pveffects) Contrasts of predictive margins Number of obs = 25,964\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: educ = 16\rage = 30\r----------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r------------------+---------------------------------------\rgender |\r(Female vs Male) | -9421.04 529.92 -17.78 0.000\r----------------------------------------------------------\rWe can specify multiple values in the at() option to estimate the mean for males and females for various combinations of age and educ. The margins command below estimates the mean for males and females for the combinations of 12, 16, and 20 years of education and 30, 40, and 50 years of age. margins gender,at(educ=(12 16 20) age=(30 40 50)) Predictive margins Number of obs = 25,964\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: educ = 12\rage = 30\r2._at: educ = 12\rage = 40\r3._at: educ = 12\rage = 50\r4._at: educ = 16\rage = 30\r5._at: educ = 16\rage = 40\r6._at: educ = 16\rage = 50\r7._at: educ = 20\rage = 30\r8._at: educ = 20\rage = 40\r9._at: educ = 20\rage = 50\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\r_at#gender |\r1#Male | 20106.88 284.18 70.75 0.000 19549.88 20663.89\r1#Female | 11414.41 198.42 57.53 0.000 11025.50 11803.33\r2#Male | 25574.42 439.87 58.14 0.000 24712.25 26436.58\r2#Female | 13294.97 249.62 53.26 0.000 12805.70 13784.24\r3#Male | 27517.24 502.91 54.72 0.000 26531.51 28502.98\r3#Female | 13767.08 273.95 50.25 0.000 13230.11 14304.04\r4#Male | 27288.24 430.84 63.34 0.000 26443.78 28132.71\r4#Female | 17867.20 303.52 58.87 0.000 17272.28 18462.12\r5#Male | 41909.91 621.06 67.48 0.000 40692.60 43127.22\r5#Female | 24497.60 435.14 56.30 0.000 23644.71 25350.50\r6#Male | 48019.96 712.27 67.42 0.000 46623.87 49416.06\r6#Female | 26799.67 508.67 52.69 0.000 25802.64 27796.70\r7#Male | 34469.61 988.60 34.87 0.000 32531.90 36407.31\r7#Female | 24319.99 710.54 34.23 0.000 22927.30 25712.68\r8#Male | 58245.41 1334.69 43.64 0.000 55629.34 60861.49\r8#Female | 35700.24 981.01 36.39 0.000 33777.40 37623.07\r9#Male | 68522.68 1525.11 44.93 0.000 65533.38 71511.98\r9#Female | 39832.27 1144.65 34.80 0.000 37588.69 42075.85\r------------------------------------------------------------------------------\rmargins r.gender,at(educ=(12 16 20)age=(30 40 50)) Contrasts of predictive margins Number of obs = 25,964\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: educ = 12\rage = 30\r2._at: educ = 12\rage = 40\r3._at: educ = 12\rage = 50\r4._at: educ = 16\rage = 30\r5._at: educ = 16\rage = 40\r6._at: educ = 16\rage = 50\r7._at: educ = 20\rage = 30\r8._at: educ = 20\rage = 40\r9._at: educ = 20\rage = 50\r-------------------------------------------------------\r| df F P\u003eF\r--------------------+----------------------------------\rgender@_at |\r(Female vs","date":"2024-01-11","objectID":"/13.chapter13continuous-by-continuous-by-categorical-interactions/:2:4","tags":["Interaction","stata"],"title":"Chapter13 ：Continuous by continuous by categorical interactions","uri":"/13.chapter13continuous-by-continuous-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve a continuous variable modeled using a polynomial term interacted with a categorical variable. ","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve a continuous variable modeled using a polynomial term interacted with a categorical variable. This chapter covers two types of polynomial terms: quadratic and cubic. ","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/:0:0","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Quadratic by categorical interactions ","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/:1:0","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Quadratic by two-level categorical Let’s now use the GSS dataset to fit a model predicting income from age (modeled using a quadratic term), whether one is a college graduate, as well as the interaction of these variables. use gss_ivrm.dta keep if age\u003e=22 \u0026 age\u003c=80 lowess realrinc age,generate(yhat_lowess) nograph graph twoway line yhat_lowess age,sort Let’s begin by looking at the relationship between age and income using a lowess smoother. The lowess command is used to create the variable yhat_lowess that contains the lowess smoothed values of realrinc. The graph command creates a graph showing the lowess smoothed values across age. Lowess smoothed values of income by age\rLet’s create this same kind of graph but separating people based on the variable cograd, which is coded: 0 = noncollege graduate and 1 = college graduate. The lowess command is issued twice, each with an if specification. lowess realrinc age if cograd == 0,generate(yhat_lowess0)nograph lowess realrinc age if cograd == 1,generate(yhat_lowess1)nograph graph twoway line yhat_lowess0 yhat_lowess1 age,sort Lowess smoothed values of income predicted from age by college graduation status\rBased on this visual inspection of the data, a regression model predicting realrinc from age and cograd would not only need to account for the quadratic trend in age, but also the difference in the quadratic trend in age for college graduates versus noncollege graduates. Let’s fit a model that includes an intercept, age, and age squared for noncollege graduates, and a separate intercept, age, and age squared for college graduates. Specifying ibn.cograd with the noconstant option yields separate intercept estimates by college graduation status. Specifying ibn.cograd#c.age yields separate age estimates by college graduation status, and ibn.cograd#c.age#c.age yields separate age#age estimates by college graduation status. reg realrinc ibn.cograd ibn.cograd#c.age ibn.cograd#c.age#c.age female,noconstant vce(robust) Linear regression Number of obs = 30,576\rF(7, 30569) = 5127.56\rProb \u003e F = 0.0000\rR-squared = 0.5088\rRoot MSE = 24865\r------------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------------+----------------------------------------------------------------\rcograd |\rNot CO Grad | -11096.99 1107.78 -10.02 0.000 -13268.29 -8925.69\rCO Grad | -52730.93 3688.05 -14.30 0.000 -59959.66 -45502.21\r|\rcograd#c.age |\rNot CO Grad | 1594.87 57.26 27.85 0.000 1482.64 1707.10\rCO Grad | 3941.46 194.37 20.28 0.000 3560.49 4322.43\r|\rcograd#c.age#c.age |\rNot CO Grad | -16.20 0.66 -24.48 0.000 -17.50 -14.90\rCO Grad | -37.81 2.30 -16.46 0.000 -42.31 -33.30\r|\rfemale | -12457.11 278.57 -44.72 0.000 -13003.12 -11911.11\r------------------------------------------------------------------------------------\rNote! Model shortcut Stata expands the expression ibn.cograd#(c.age c.age#c.age) to become ibn.cograd#c.age ibn.cograd#c.age#c.age, yielding the same model shown previously. $$Non-college-grad: \\widehat{realrinc}=-11096.99 + 1594.87age + - 16.20age^2 + - 12457.11female $$ $$College-grad: \\widehat{realrinc}=-52730.93 + 3941.46age + -37.81age^2 + -12457.11female $$ Let’s visualize the impact of the differences in these quadratic coefficients by graphing the adjusted means as a function of age and college graduation status (that is, cograd), adjusting for gender. margins cograd, nopvalues at(age=(22(1)80)) marginsplot,noci recast(line) scheme(simono) Fitted values from quadratic by two-level categorical model\rWe can ask whether the degree of curvature between college graduates and non-college graduates is significantly different. The contrast command below tests whether the quadratic term for non-college graduates is equal to the quadratic term for college graduates. contrast cograd#c.age#c.age Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/:1:1","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Quadratic by three-level categorical Let’s begin our exploration by using the lowess command to generate variables that contain the smoothed relationship between realrinc and age, separately for each of the three levels of educ3. use gss_ivrm.dta keep if age\u003e=22 \u0026 age\u003c=80 lowess realrinc age if educ3 == 1,generate(yhat_lowess1) nograph lowess realrinc age if educ3 == 2,generate(yhat_lowess2) nograph lowess realrinc age if educ3 == 3,generate(yhat_lowess3) nograph graph twoway line yhat_lowess1 yhat_lowess2 yhat_lowess3 age,sort legend(order(1 \"Non-HS grad\" 2 \"HS grad\" 3 \"CO grad\")) Lowess smoothed values of income by age, separated by three levels of education\rLet’s now fit a model that includes a quadratic term for age as well as an interaction of educ3 and the quadratic term for age. reg realrinc ibn.educ3 ibn.educ3#(c.age c.age#c.age) female,noconstant vce(robust) Linear regression Number of obs = 30,576\rF(10, 30566) = 3691.50\rProb \u003e F = 0.0000\rR-squared = 0.5129\rRoot MSE = 24761\r-----------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r------------------+----------------------------------------------------------------\reduc3 |\rnot hs | -8609.97 1907.08 -4.51 0.000 -12347.92 -4872.01\rHS | -11115.20 1375.93 -8.08 0.000 -13812.07 -8418.32\rColl | -52556.01 3687.82 -14.25 0.000 -59784.28 -45327.74\r|\reduc3#c.age |\rnot hs | 1245.11 93.00 13.39 0.000 1062.82 1427.40\rHS | 1625.58 72.45 22.44 0.000 1483.59 1767.58\rColl | 3940.66 194.33 20.28 0.000 3559.76 4321.57\r|\reduc3#c.age#c.age |\rnot hs | -12.46 1.00 -12.40 0.000 -14.43 -10.49\rHS | -16.04 0.87 -18.54 0.000 -17.74 -14.34\rColl | -37.81 2.30 -16.46 0.000 -42.31 -33.31\r|\rfemale | -12750.67 278.86 -45.72 0.000 -13297.24 -12204.10\r-----------------------------------------------------------------------------------\rThe regression equation is written in this fashion as shown below. $$NonHis-grad:\\widehat{realrinc}=-8609.67 + 1245.11age + - 12.46age^2 + - 12750.67female$$ $$His-grad:\\widehat{realrinc}=-11115.2 + 1625.59age + -16.04age^2 + -12750.67female$$ $$College-grad:\\widehat{realrinc}=-52556.01 + 3940.66age + -37.81age^2 + -12750.67female$$ To help interpret the regression coefficients, let’s use the margins and marginsplot commands to visualize the adjusted means as a function of age and educ3. margins educ3,at(age=(22(1)80)) marginsplot,noci recast(line) scheme(simono) Fitted values from age (quadratic) by education level\rThe contrast command can be used to compare the quadratic coefficients among the educational groups. The contrast command below tests the equality of the quadratic coefficient for all three levels of educ3. contrast educ3#c.age#c.age Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------\r| df F P\u003eF\r------------------+----------------------------------\reduc3#c.age#c.age | 2 51.24 0.0000\r|\rDenominator | 30566\r-----------------------------------------------------\rThis test is significant, indicating that the quadratic term for age is not equal across all three groups. the a. contrast operator is used below to compare the quadratic terms for adjacent education groups.(Specific compare) contrast a.educ3#c.age#c.age,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\reduc3#c.age#c.age |\r(not hs vs HS) | 3.58 1.33 2.70 0.007\r(HS vs Coll) | 21.77 2.45 8.87 0.000\r----------------------------------------------------------\rLet’s now see how to use the margins command to compute adjusted means. The margins command below computes the adjusted mean holding age constant at 30, separately for each education group. margins educ3,nopvalues at(age=30) Predictive margins Number of obs = 30,576\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: ","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/:1:2","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Cubic by categorical interactions This section describes models that involve interactions of a categorical variable with a continuous variable where the continuous variable is fit using a cubic polynomial term. A cubic by categorical interaction allows the groups formed by the categorical variable to differ in cubic trend. In that example, we saw a cubic relationship between year of birth and number of children. Suppose that we divided women into two groups: those who graduated college and those who did not graduate college. Those who graduated college might show a different kind of cubic trend across years of birth compared with non-college graduates. use gss_ivrm.dta keep if (age\u003e=45 \u0026 age \u003c=55) \u0026 (yrborn\u003e=1920 \u0026 yrborn\u003c=1960) \u0026 female==1 Let’s begin by visualizing the nature of the relationship between year of birth and number of children separately for college graduates and non-college graduates. We can do this using a lowess smoothed regression relating year of birth to number of children. lowess children yrborn if cograd==0,generate(yhatlowess0) nograph lowess children yrborn if cograd==1,generate(yhatlowess1) nograph graph twoway line yhatlowess0 yhatlowess1 yrborn,sort Lowess smoothed values of number of children by year of birth, separated by college graduation status\rThe graph in figure suggests that the relationship between year of birth and number of children may show a cubic trend. Furthermore, the cubic trend may differ based on whether the woman graduated college, suggesting an interaction of the cubic trend for year of birth and whether the woman graduated college. Let’s fit a model using a separate slope and separate intercept strategy that allows us to compare the cubic trend in year of birth for college graduates with non-college graduates. Such a model is fit using the regress command below. The first term in the model is ibn.cograd. When specified in combination with noconstant option, the model fits separate intercepts by college graduation status. The model also includes ibn.cograd interacted with the linear term for year of birth, the quadratic term for year of birth, and the cubic term for year of birth. This yields separate estimates of these terms by college graduation status. reg children ibn.cograd ibn.cograd#(c.yrborn40 c.yrborn40#c.yrborn40 c.yrborn40#c.yrborn40#c.yrborn40) i.race,noconstant noci Note：the centered variable, yrborn40, is used to represent year of birth to reduce collinearity. Source | SS df MS Number of obs = 5,037\r-------------+---------------------------------- F(10, 5027) = 1223.60\rModel | 34370.3789 10 3437.03789 Prob \u003e F = 0.0000\rResidual | 14120.6211 5,027 2.80895585 R-squared = 0.7088\r-------------+---------------------------------- Adj R-squared = 0.7082\rTotal | 48491 5,037 9.62696049 Root MSE = 1.676\r--------------------------------------------------------------------------------\rchildren | Coefficient Std. err. t P\u003e|t|\r----------------------------------------+---------------------------------------\rcograd |\rNot CO Grad | 2.80 0.04 65.64 0.000\rCO Grad | 1.96 0.09 22.43 0.000\r|\rcograd#c.yrborn40 |\rNot CO Grad | -0.09 0.01 -15.21 0.000\rCO Grad | -0.06 0.01 -5.35 0.000\r|\rcograd#c.yrborn40#c.yrborn40 |\rNot CO Grad | -0.00 0.00 -4.07 0.000\rCO Grad | 0.00 0.00 0.41 0.685\r|\rcograd#c.yrborn40#c.yrborn40#c.yrborn40 |\rNot CO Grad | 0.00 0.00 9.42 0.000\rCO Grad | 0.00 0.00 1.88 0.060\r|\rrace |\rblack | 0.57 0.07 8.49 0.000\rother | 0.67 0.13 5.26 0.000\r--------------------------------------------------------------------------------\rThe regression equation are devided to two part as shown below: \\begin{align} Non-college-grad:\\widehat{children} = -2.8 - 0.088yrborn40 + -0.00093yrborn40^2 \\notag\\ \\end{align} \\begin{align} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ +0.00021yrborn40^3 + 0.57black + 0.67other \\notag \\ \\end{align} \\begin{align} College-grad:\\widehat{children} = 1.96 + -0.063yrborn + 0.00024yrborn40^2 \\notag\\ \\end{align} \\beg","date":"2024-01-10","objectID":"/11.chapter11polynomial-by-categorical-interactions/:2:0","tags":["Interaction","stata"],"title":"Chapter11 ：Polynomial by categorical interactions","uri":"/11.chapter11polynomial-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve interactions of categorical and continuous variables.","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve interactions of categorical and continuous variables. ","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:0:0","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Linear and two-level categorical: No interaction ","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:1:0","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Overview This section introduces the concepts involving models that combine continuous and categorical predictors with no interaction. Let’s begin by considering a hypothetical simple regression model predicting income from age, focusing on people who are aged 22 to 55. $$ \\widehat{realrinc}=9000 + 400age $$ Simple linear regression predicting income from age\rLet’s now expand upon this model and introduce a categorical variable with two levels reflecting whether the respondent graduated college (named cograd in the dataset gss_ivrm.dta). It is coded 0 if the respondent did not graduate college and 1 if the respondent did graduate college. One continuous and one categorical predictor with labels for slopes and intercepts\rthe intercept for those who did not graduate college is 4,000 and for those who did graduate college is 21,000. The difference in theseintercepts is 17,000. One equation is given for noncollege graduates and another for college graduates, as shown below. $$ Noncollege - graduate:\\widehat{realrinc}=4000 + 400age $$ $$ College - graduate:\\widehat{realrinc}=21000 + 400age $$ This regression model can also be expressed as one equation, as shown below. $$ \\widehat{realrinc}=4000 + 17000cograd + 400age $$ The predicted values at 30, 40, and 50 years of age have been computed both for those who did and for those who did not graduate college and are graphed in figure below： One continuous and one categorical predictor with labels for predicted values\r","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:1:1","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Examples using the GSS This section applies the model predicting realrinc from age and cograd using the GSS dataset. use gss_ivrm.dta keep if age\u003e=22 \u0026 age\u003c=55 reg realrinc age i.cograd female,vce(robust) Linear regression Number of obs = 25,718\rF(3, 25714) = 906.12\rProb \u003e F = 0.0000\rR-squared = 0.1569\rRoot MSE = 23938\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage | 539.90 15.27 35.36 0.000 509.98 569.83\r|\rcograd |\rCO Grad | 14176.56 425.16 33.34 0.000 13343.22 15009.90\rfemale | -12119.58 295.27 -41.05 0.000 -12698.33 -11540.83\r_cons | 4171.57 518.76 8.04 0.000 3154.76 5188.37\r------------------------------------------------------------------------------\rBefore interpreting the coefficients for this model, let’s create a graph showing the adjusted means as a function of age and cograd.2 First, we use the margins command to compute the adjusted means at ages 22 and 55 for each level of cograd. margins cograd,nopvalues at(age=(22 55)) vsquish marginsplot,noci Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 22\r2._at: age = 55\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\r_at#cograd |\r1#Not CO Grad | 10048.09 216.20 9624.33 10471.85\r1#CO Grad | 24224.65 398.82 23442.95 25006.35\r2#Not CO Grad | 27864.91 344.23 27190.20 28539.62\r2#CO Grad | 42041.46 553.37 40956.82 43126.11\r----------------------------------------------------------------\rFitted values of continuous and categorical model without interaction\rThese parallel lines have the same slope, as represented by the coefficient for age. Regardless of whether you graduated college, the age slope is 539.90. We can use the margins command to compute adjusted means based on this model. For example, the adjusted mean for someone who graduated college and was 40 years old, adjusting for gender, is 33,942.91. margins,nopvalues at(cograd=1 age=40) Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: age = 40\rcograd = 1\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\r_cons | 33942.91 419.99 33119.71 34766.11\r--------------------------------------------------------------\rLet’s repeat this command, but this time obtain the adjusted means separately for those who did and for those who did not graduate college. margins cograd,nopvalues at(age=40) Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: age = 40\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\rcograd |\rNot CO Grad | 19766.35 151.46 19469.48 20063.23\rCO Grad | 33942.91 419.99 33119.71 34766.11\r--------------------------------------------------------------\rNote the difference between these two values corresponds to the main effect of cograd. Here $33942.91 - 19766.35 = 14176.56$ . You could repeat the above command for any given level of age and the difference in the adjusted means would remain the same. The adjusted means are computed by setting all the covariates (that is, age and female) to the average value of the entire sample. In this example, adding the at((mean) age female) option specifies that age and female should be held constant at their mean. margins cograd,nopvalues at((mean) age female) Adjusted predictions Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: age = 37.28214 (mean)\rfemale = .4951785 (mean)\r-----------------------------","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:1:2","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Linear by two-level categorical interactions ","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:2:0","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Overview Let’s build upon the model that was illustrated by including age and cograd as predictors, as well as the interaction between age and cograd. Linear by two-level categorical predictor with labels for intercepts and slopes\rThis figure includes labels showing the intercept and slope for those who did not graduate college (labeled “Int0” and “Slope0”) and the intercept and slope for those who did graduate college (labeled “Int1” and “Slope1”). The regression equation for this hypothetical example can be written as shown below. $$ \\widehat{realrinc}=9300 + - 1300cograd + 250age + 450cograd*age $$ The intercept in the regression equation corresponds to the intercept for those who did not graduate college (that is, 9,300). The coefficient for cograd is the difference in the intercepts (that is, ). Note how this represents the difference between a college graduate versus a noncollege graduate when age is held constant at zero (which is implausible and completely absurd). This is often called the main effect of cograd, but that is misleading because in the presence of the interaction, this term represents the effect of cograd when age is held constant at zero. The interaction term (cograd*age) is the difference in the slopes comparing those who graduated college with those who did not graduate college (that is,$700 - 250 = 450$ ). This interaction term compares the slope of college graduates with the slope of noncollege graduates. It can be easier to understand this model when it is written as two equations $$ Noncollege - graduate:\\widehat{realrinc}=9300 + 250age $$ $$ College - graduate:\\widehat{realrinc}=8000 + 700age $$ ","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:2:1","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.2 Examples using the GSS use gss_ivrm.dta keep if age\u003e=22 \u0026 age\u003c=55 reg realrinc i.cograd age i.cograd#c.age female,vce(robust) Linear regression Number of obs = 25,718\rF(4, 25713) = 710.76\rProb \u003e F = 0.0000\rR-squared = 0.1661\rRoot MSE = 23807\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rcograd |\rCO Grad | -8648.27 1426.59 -6.06 0.000 -11444.48 -5852.07\rage | 375.15 14.68 25.56 0.000 346.39 403.92\r|\rcograd#c.age |\rCO Grad | 607.52 42.24 14.38 0.000 524.73 690.31\r|\rfemale | -12004.56 293.46 -40.91 0.000 -12579.76 -11429.37\r_cons | 10224.97 480.32 21.29 0.000 9283.52 11166.41\r------------------------------------------------------------------------------\rAs a shorthand, we can specify i.cograd##c.age. The ## operator includes both the main effects and interactions of the variables specified. reg realrinc i.cograd##c.age female,vce(robust) Linear regression Number of obs = 25,718\rF(4, 25713) = 710.76\rProb \u003e F = 0.0000\rR-squared = 0.1661\rRoot MSE = 23807\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rcograd |\rCO Grad | -8648.27 1426.59 -6.06 0.000 -11444.48 -5852.07\rage | 375.15 14.68 25.56 0.000 346.39 403.92\r|\rcograd#c.age |\rCO Grad | 607.52 42.24 14.38 0.000 524.73 690.31\r|\rfemale | -12004.56 293.46 -40.91 0.000 -12579.76 -11429.37\r_cons | 10224.97 480.32 21.29 0.000 9283.52 11166.41\r------------------------------------------------------------------------------\r$$ \\widehat{realrinc}=10224.97 + - 8648.27cograd + 375.15age + 607.5224cograd*age + - 12004.56female $$ Let’s create a graph to aid in the process of interpreting the results. compute the adjusted means for ages22 and 55 separately for each level of cograd margins cograd,nopvalues at(age=(22 55)) marginsplot,noci Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 22\r2._at: age = 55\r----------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------+------------------------------------------------\r_at#cograd |\r1#Not CO Grad | 12533.97 185.57 12170.25 12897.69\r1#CO Grad | 17251.19 549.53 16174.07 18328.31\r2#Not CO Grad | 24914.08 349.75 24228.55 25599.61\r2#CO Grad | 49679.54 950.38 47816.74 51542.34\r----------------------------------------------------------------\rFitted values for linear by two-level categorical predictor model\rThe figure indicate the slope between cograd \u0026 notcograd are significant different. 2.2.1 Estimates of slopes Let’s use the margins command to compute the age slope for college graduates and noncollege graduates. The dydx(age) option is used with the over(cograd) option to compute the age slope at each level of cograd. margins,dydx(age) over(cograd) Average marginal effects Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\rOver: cograd\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage |\rcograd |\rNot CO Grad | 375.15 14.68 25.56 0.000 346.39 403.92\rCO Grad | 982.68 39.55 24.84 0.000 905.15 1060.20\r------------------------------------------------------------------------------\r2.2.2 Estimates and contrasts on means Let’s begin the investigation of the effect of cograd by computing the adjusted mean of income for each level of cograd, holding age constant at 30. margins cograd, nopvalues at(age=30) Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rAt: age = 30\r--------------------------------------","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:2:2","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Linear by three-level categorical interactions Let’s now explore a model in which a three-level categorical variable is interacted with a continuous variable. Let’s extend the previous example by considering three educational groups: 1) non–high school graduates, 2) high school graduates, and 3) college graduates. Although not shown in the graph, the intercept is 3,000 for group 1, 3,700 for group 2, and for group 3. Linear by three-level categorical predictor with labels for slopes\r$$ \\widehat{realrinc}=3000 + 700hsgrad + -800cograd + 300age + 100hsgradage + 700cogradage $$ The value of 3,000 is the intercept for those who did not graduate college. The coefficient for hsgrad is the difference in the intercepts between high school graduates and non–high school graduates (that is,$3700 - 3000 = 700$ ). The coefficient for cograd is the difference in the intercepts between college graduates and non–high school graduates (that is,$- 5000 - 3000 = -8000$). $$ Non-hsgrad:\\widehat{realrinc}=3000 + 300age $$ $$ Hsgrad:\\widehat{realrinc}=3700 + 400age $$ $$ College-grad:\\widehat{realrinc}=-5000 + 1000age $$ If we do not reject this null hypothesis, then the education by interaction terms may no longer be needed and could be omitted from the model. If we do reject this null hypothesis, we might be further interested in forming specific contrasts among the slopes. We might be further interested in forming specific contrasts among the slopes, for example, We might be interested in comparing the different educational groups given different levels of age. As an illustration, the predicted mean of income for those aged 30, 40, and 50 for eacheducational group have been computed and are plotted in figure below. ","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:3:0","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Examples using the GSS Let’s continue to use age as the continuous predictor and realrinc as the outcome, but now we will use a three-category education variable, educ3. use gss_ivrm.dta keep if age\u003e=22 \u0026 age\u003c=55 reg realrinc i.educ3##c.age female,vce(robust) Linear regression Number of obs = 25,718\rF(6, 25711) = 563.58\rProb \u003e F = 0.0000\rR-squared = 0.1728\rRoot MSE = 23712\r------------------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\reduc3 |\rHS | 1906.98 1098.01 1.74 0.082 -245.18 4059.14\rColl | -6287.54 1643.87 -3.82 0.000 -9509.63 -3065.46\r|\rage | 299.15 28.35 10.55 0.000 243.58 354.72\r|\reduc3#c.age |\rHS | 120.00 32.96 3.64 0.000 55.40 184.60\rColl | 682.88 48.71 14.02 0.000 587.42 778.35\r|\rfemale | -12258.80 293.44 -41.78 0.000 -12833.96 -11683.63\r_cons | 8012.50 944.86 8.48 0.000 6160.51 9864.49\r------------------------------------------------------------------------------\rBefore interpreting these results, let’s make a graph showing the adjusted means by age and educ3. compute the adjusted means at ages22 and 55 for each level of educ3 margins educ3,nopvalues at(age=(22 55)) marginsplot,noci Predictive margins Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: age = 22\r2._at: age = 55\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\r_at#educ3 |\r1#not hs | 8523.52 361.18 7815.59 9231.45\r1#HS | 13070.41 208.67 12661.40 13479.43\r1#Coll | 17259.39 549.76 16181.83 18336.94\r2#not hs | 18395.49 655.31 17111.04 19679.94\r2#HS | 26902.25 405.94 26106.58 27697.93\r2#Coll | 49666.47 950.09 47804.25 51528.69\r--------------------------------------------------------------\rFitted values for linear by three-level categorical predictor model\rThe dydx(age) is combined with the over(educ3) option to compute the age slope separately for each level of educ3. 3.1.1 Estimates and contrasts on slopes margins,dydx(age) over(educ3) Average marginal effects Number of obs = 25,718\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\rOver: educ3\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage |\reduc3 |\rnot hs | 299.15 28.35 10.55 0.000 243.58 354.72\rHS | 419.15 16.85 24.87 0.000 386.12 452.18\rColl | 982.03 39.55 24.83 0.000 904.51 1059.55\r------------------------------------------------------------------------------\rThe output not only shows the age slope at each level of educ3 but also includes the standard error, confidence interval, and a test of whether the slope is significantly different from 0. Let’s test whether these slopes are equal to each other. In other words,let’s test the null hypothesis： $$ H_{0} = \\beta{1} = \\beta{2} = \\beta{3} $$ contrast educ3#c.age Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\reduc3#c.age | 2 105.89 0.0000\r|\rDenominator | 25711\r------------------------------------------------\rThis interaction is significant, so we can reject the null hypothesis that these slopes are all equal. $$ H_{0} = \\beta{1} = \\beta{3} $$ $$ H_{0} = \\beta{2} = \\beta{3} $$ The following contrast command tests these two null hypotheses.Specifying rb3.educ3 uses reference group comparisons with group 3 as the baseline (comparison) group. We can reject both null hypotheses. contrast rb3.educ3#c.age,nowald pveffect Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------","date":"2024-01-09","objectID":"/10.chapter10linear-by-categorical-interactions/:3:1","tags":["Interaction","stata"],"title":"Chapter10 ：Linear by categorical interactions","uri":"/10.chapter10linear-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models involving interactions of three categorical variables, with an emphasis on how to interpret the interaction of the three categorical variables.","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models involving interactions of three categorical variables, with an emphasis on how to interpret the interaction of the three categorical variables. This chapter focuses on three types of interactions: two by two by two model two by two by three model three by three by four model ","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:0:0","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Two by two by two models a new study using a two by two by two model in which treatment has two levels (control group versus happiness therapy), depression status has two levels (nondepressed versus mildly depressed), and season has two levels (winter and summer). opt-2by2by2.dta anova opt depstat##treat##season Number of obs = 240 R-squared = 0.5677\rRoot MSE = 8.01794 Adj R-squared = 0.5546\rSource | Partial SS df MS F Prob\u003eF\r---------------------+----------------------------------------------------\rModel | 19584.517 7 2797.7881 43.52 0.0000\r|\rdepstat | 1601.6667 1 1601.6667 24.91 0.0000\rtreat | 13470.017 1 13470.017 209.53 0.0000\rdepstat#treat | 35.266667 1 35.266667 0.55 0.4596\rseason | 3713.0667 1 3713.0667 57.76 0.0000\rdepstat#season | 220.41667 1 220.41667 3.43 0.0653\rtreat#season | 112.06667 1 112.06667 1.74 0.1880\rdepstat#treat#season | 432.01667 1 432.01667 6.72 0.0101\r|\rResidual | 14914.667 232 64.287356 ---------------------+----------------------------------------------------\rTotal | 34499.183 239 144.34805 Note! Three-way interaction shortcut Specifying depstat##treat##season is a shortcut for specifying all main effects, two-way interactions, and the three-way interaction of depstat, treat, and season. This both saves time and helps ensure that you include all lower order effects. Even if not significant, these lower order effects should be included in the model. The depstat#treat#season interaction is significant ($F = 6.72$,$p = 0.0101$). Let’s use the margins command to show the mean of optimism broken down by these three factors. margins depstat#treat#season,nopvalues Adjusted predictions Number of obs = 240\rExpression: Linear prediction, predict()\r----------------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r---------------------+------------------------------------------------\rdepstat#treat#season |\rNon#Con#Winter | 44.40 1.46 41.52 47.28\rNon#Con#Summer | 51.67 1.46 48.78 54.55\rNon#HT#Winter | 59.93 1.46 57.05 62.82\rNon#HT#Summer | 64.57 1.46 61.68 67.45\rMild#Con#Winter | 39.23 1.46 36.35 42.12\rMild#Con#Summer | 44.97 1.46 42.08 47.85\rMild#HT#Winter | 50.93 1.46 48.05 53.82\rMild#HT#Summer | 64.77 1.46 61.88 67.65\r----------------------------------------------------------------------\rLet’s then use the marginsplot command to make a graph of the means, showing treat on the $x$ axis and the different seasons in separate panels. marginsplot,xdimension(treat) bydimension(season)noci Optimism by treatment, depression status, and season\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:1:0","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Simple interactions by season One way that we can dissect the three-way interaction is by looking at the simple interactions of treatment by depression status at each season. Looking at figure，it appears that the interaction is not significant during the winter and is significant during the summer. We test this using the contrast command, which tests the treat#depstat interaction at each level of season. contrast treat#depstat@season Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rtreat#depstat@season |\rWinter | 1 1.71 0.1917\rSummer | 1 5.55 0.0193\rJoint | 2 3.63 0.0279\r|\rDenominator | 232\r--------------------------------------------------------\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:1:1","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Simple interactions by depression status Another way to dissect this three-way interaction is by looking at the simple interaction of treatment by season at each level of depression status. To visualize this, let’s rerun the margins command and then use the marginsplot command to graph the means showing treat on the $x$ axis and separate panels for those who are nondepressed and mildly depressed. margins depstat#treat#season marginsplot,xdimension(treat)bydimension(depstat) noci Adjusted predictions Number of obs = 240\rExpression: Linear prediction, predict()\r--------------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r---------------------+----------------------------------------------------------------\rdepstat#treat#season |\rNon#Con#Winter | 44.40 1.46 30.33 0.000 41.52 47.28\rNon#Con#Summer | 51.67 1.46 35.29 0.000 48.78 54.55\rNon#HT#Winter | 59.93 1.46 40.94 0.000 57.05 62.82\rNon#HT#Summer | 64.57 1.46 44.11 0.000 61.68 67.45\rMild#Con#Winter | 39.23 1.46 26.80 0.000 36.35 42.12\rMild#Con#Summer | 44.97 1.46 30.72 0.000 42.08 47.85\rMild#HT#Winter | 50.93 1.46 34.79 0.000 48.05 53.82\rMild#HT#Summer | 64.77 1.46 44.24 0.000 61.88 67.65\r--------------------------------------------------------------------------------------\rOptimism by treatment, season, and depression status\rThere is an interaction of treatment by season for those who are mildly depressed, but no such interaction for those who are not depressed. We can test the interaction of treatment by season at each level of depression status using the following contrast command: contrast treat#season@depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rtreat#season@depstat |\rNon | 1 0.81 0.3693\rMild | 1 7.65 0.0061\rJoint | 2 4.23 0.0157\r|\rDenominator | 232\r--------------------------------------------------------\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:1:2","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 Simple effects We might want to know whether the effect of happiness therapy is significant for each combination of season and depression status. contrast treat@season#depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r--------------------------+---------------------------------------\rtreat@season#depstat |\r(HT vs base) Winter#Non | 15.53 2.07 7.50 0.000\r(HT vs base) Winter#Mild | 11.70 2.07 5.65 0.000\r(HT vs base) Summer#Non | 12.90 2.07 6.23 0.000\r(HT vs base) Summer#Mild | 19.80 2.07 9.56 0.000\r------------------------------------------------------------------\rThe mean optimism for those in the happiness therapy group is always greater than the control group at each level of season and at each level of depression status. ","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:1:3","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Two by two by three models Let’s now consider an example with three factors, two of which have two levels and one of which has three levels. In this example, the treatment variable now has three levels: 1.control group, 2. traditional therapy, and 3. happiness therapy. use opt-3by2by2.dta Let’s now use the anova command to predict opt from depstat, treat, season, all two-way interactions of these variables, and the three-way interaction. anova opt depstat##treat##season Number of obs = 360 R-squared = 0.4912\rRoot MSE = 7.9879 Adj R-squared = 0.4751\rSource | Partial SS df MS F Prob\u003eF\r---------------------+----------------------------------------------------\rModel | 21435.233 11 1948.6576 30.54 0.0000\r|\rdepstat | 2423.2111 1 2423.2111 37.98 0.0000\rtreat | 13811.217 2 6905.6083 108.23 0.0000\rdepstat#treat | 3.9055556 2 1.9527778 0.03 0.9699\rseason | 3960.1 1 3960.1 62.06 0.0000\rdepstat#season | 253.34444 1 253.34444 3.97 0.0471\rtreat#season | 469.11667 2 234.55833 3.68 0.0263\rdepstat#treat#season | 514.33889 2 257.16944 4.03 0.0186\r|\rResidual | 22204.667 348 63.806513 ---------------------+----------------------------------------------------\rTotal | 43639.9 359 121.55961 The three-way interaction is significant ( $F = 4.03$ , $p = 0.0186$ ). Let’s use the margins and marginsplot commands to display and graph the means by each of these categorical variables. margins depstat#treat#season,nopvalues marginsplot,bydimension(depstat) noci Adjusted predictions Number of obs = 360\rExpression: Linear prediction, predict()\r-----------------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r----------------------+------------------------------------------------\rdepstat#treat#season |\rNon#Con#Winter (S1) | 44.70 1.46 41.83 47.57\rNon#Con#Summer (S2) | 49.70 1.46 46.83 52.57\rNon#TT#Winter (S1) | 54.33 1.46 51.46 57.20\rNon#TT#Summer (S2) | 59.40 1.46 56.53 62.27\rNon#HT#Winter (S1) | 59.77 1.46 56.90 62.64\rNon#HT#Summer (S2) | 64.57 1.46 61.70 67.44\rMild#Con#Winter (S1) | 39.63 1.46 36.76 42.50\rMild#Con#Summer (S2) | 44.20 1.46 41.33 47.07\rMild#TT#Winter (S1) | 49.23 1.46 46.36 52.10\rMild#TT#Summer (S2) | 54.70 1.46 51.83 57.57\rMild#HT#Winter (S1) | 49.33 1.46 46.46 52.20\rMild#HT#Summer (S2) | 64.23 1.46 61.36 67.10\r-----------------------------------------------------------------------\rOptimism by treatment, season, and depression status\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:2:0","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Simple interactions by depression status It appears that the treat#season interaction might not be significant for those who are not depressed (see the left panel of figure) but might be significant for those who are mildly depressed (see the right panel of figure ). We can explore this by assessing the treat#season interaction at each level of depstat using the contrastcommand below. contrast treat#season@depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rtreat#season@depstat |\rNon | 2 0.00 0.9955\rMild | 2 7.70 0.0005\rJoint | 4 3.85 0.0044\r|\rDenominator | 348\r--------------------------------------------------------\rLet’s further dissect this simple interaction by applying contrasts to the treatment factor through the use of simple partial interactions. ","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:2:1","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.2 Simple partial interaction by depression status Say that we want to form two comparisons with respect to treat, comparing group 2 versus 1 (traditional therapy versus control group) and comparing group 3 versus 2 (happiness therapy versus traditional therapy). The interaction of treatment (traditional therapy versus control group) by season for those who are mildly depressed is visualized in the left panel of figure below, and the interaction of treatment (happiness therapy versus traditional therapy) by season for those who are mildly depressed is visualized in the right panel of figure below. Simple partial interactions\rTo understand this, let’s break it into two parts. The first part, ar.treat#season, creates the interactions of treatment (traditional therapy versus control group) by season, and treatment (happiness therapy versus traditional therapy) by season. The second part, @2.depstat indicates the contrasts will be performed only for level 2 of depstat (the mildly depressed group) contrast ar.treat#season@2.depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------\r| df F P\u003eF\r--------------------------+----------------------------------\rtreat#season@depstat |\r(TT vs Con) (joint) Mild | 1 0.10 0.7578\r(HT vs TT) (joint) Mild | 1 10.46 0.0013\rJoint | 2 7.70 0.0005\r|\rDenominator | 348\r-------------------------------------------------------------\rLet’s now further understand this simple partial interaction through the use of simple contrasts. ","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:2:2","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.3 Simple contrasts In particular, let’s ask whether there is a difference between happiness therapy and traditional therapy separately for each season focusing only on those who are mildly depressed. We can perform this test by specifying ar3.treat@season#2.depstat on the contrast command. Let’s break this into two parts. The first part, ar3.treat, requests the comparison of treatment group 3 versus 2 (happiness therapy versus traditional therapy). The second part, @season#2.depstat, requests that the contrasts be performed at each level of season and at level 2 of depression status (mildly depressed) contrast ar3.treat@season#2.depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------------------+---------------------------------------\rtreat@season#depstat |\r(HT vs TT) Winter (S1)#Mild | 0.10 2.06 0.05 0.961\r(HT vs TT) Summer (S2)#Mild | 9.53 2.06 4.62 0.000\r---------------------------------------------------------------------\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:2:3","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.4 Partial interactions Say that we wanted to further understand this interaction by applying adjacent group contrasts to the treatment factor. These contrasts compare group 2 versus 1 (traditional therapy versus control group) and group 3 versus 2 (happiness therapy versus traditional therapy). We could interact these contrasts with season and depression status. Simple partial interaction: T2 vs. T1 by season by depstat\rSimple partial interaction: T3 vs. T2 by season by depstat\rWe can test each of these partial interactions using the contrast command below. contrast ar.treat#season#depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------\r| df F P\u003eF\r-----------------------------+----------------------------------\rtreat#season#depstat |\r(TT vs Con) (joint) (joint) | 1 0.04 0.8400\r(HT vs TT) (joint) (joint) | 1 5.53 0.0193\rJoint | 2 4.03 0.0186\r|\rDenominator | 348\r----------------------------------------------------------------\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:2:4","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Three by three by three models and beyond Let’s consider an extension of the example involving the factors treat, depstat, and season, except that these factors have three, three and four levels, respectively. The three levels of treat are 1) control group, 2) traditional therapy, and 3) happiness therapy. The three levels of depstat are 1) nondepressed, 2) mildly depressed, and 3) severely depressed. The four levels of season are 1) winter, 2) spring, 3) summer, and 4)fall. use opt-3by3by4.dta anova opt depstat##treat##season Number of obs = 1,080 R-squared = 0.6172\rRoot MSE = 6.00663 Adj R-squared = 0.6043\rSource | Partial SS df MS F Prob\u003eF\r---------------------+----------------------------------------------------\rModel | 60718.9 35 1734.8257 48.08 0.0000\r|\rdepstat | 18782.039 2 9391.0194 260.29 0.0000\rtreat | 34636.039 2 17318.019 480.00 0.0000\rdepstat#treat | 1702.0056 4 425.50139 11.79 0.0000\rseason | 3522.8333 3 1174.2778 32.55 0.0000\rdepstat#season | 1004.2722 6 167.3787 4.64 0.0001\rtreat#season | 185.11667 6 30.852778 0.86 0.5275\rdepstat#treat#season | 886.59444 12 73.88287 2.05 0.0179\r|\rResidual | 37667.067 1,044 36.079566 ---------------------+----------------------------------------------------\rTotal | 98385.967 1,079 91.182546 The three-way interaction of depstat#treat#season is significant ( $F = 2.05$ , $p=0.0179$ ). To begin to understand the nature of this interaction, let’s first graph the interaction using the margins and marginsplot commands. margins depstat#treat#season marginsplot,xdimension(treat)bydimension(season) noci legend(rows(1)) Adjusted predictions Number of obs = 1,080\rExpression: Linear prediction, predict()\r--------------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r---------------------+----------------------------------------------------------------\rdepstat#treat#season |\rNon#Con#Winter | 44.63 1.10 40.70 0.000 42.48 46.79\rNon#Con#Spring | 47.53 1.10 43.34 0.000 45.38 49.69\rNon#Con#Summer | 49.70 1.10 45.32 0.000 47.55 51.85\rNon#Con#Fall | 47.83 1.10 43.62 0.000 45.68 49.99\rNon#TT#Winter | 54.30 1.10 49.51 0.000 52.15 56.45\rNon#TT#Spring | 57.33 1.10 52.28 0.000 55.18 59.49\rNon#TT#Summer | 60.37 1.10 55.05 0.000 58.21 62.52\rNon#TT#Fall | 57.03 1.10 52.01 0.000 54.88 59.19\rNon#HT#Winter | 61.30 1.10 55.90 0.000 59.15 63.45\rNon#HT#Spring | 62.70 1.10 57.17 0.000 60.55 64.85\rNon#HT#Summer | 64.70 1.10 59.00 0.000 62.55 66.85\rNon#HT#Fall | 62.87 1.10 57.33 0.000 60.71 65.02\rMild#Con#Winter | 39.60 1.10 36.11 0.000 37.45 41.75\rMild#Con#Spring | 42.73 1.10 38.97 0.000 40.58 44.89\rMild#Con#Summer | 44.50 1.10 40.58 0.000 42.35 46.65\rMild#Con#Fall | 42.73 1.10 38.97 0.000 40.58 44.89\rMild#TT#Winter | 49.17 1.10 44.83 0.000 47.01 51.32\rMild#TT#Spring | 52.20 1.10 47.60 0.000 50.05 54.35\rMild#TT#Summer | 54.10 1.10 49.33 0.000 51.95 56.25\rMild#TT#Fall | 52.03 1.10 47.45 0.000 49.88 54.19\rMild#HT#Winter | 51.20 1.10 46.69 0.000 49.05 53.35\rMild#HT#Spring | 56.37 1.10 51.40 0.000 54.21 58.52\rMild#HT#Summer | 65.33 1.10 59.58 0.000 63.18 67.49\rMild#HT#Fall | 56.17 1.10 51.22 0.000 54.01 58.32\rSevere#Con#Winter | 36.67 1.10 33.44 0.000 34.51 38.82\rSevere#Con#Spring | 39.67 1.10 36.17 0.000 37.51 41.82\rSevere#Con#Summer | 39.60 1.10 36.11 0.000 37.45 41.75\rSevere#Con#Fall | 39.97 1.10 36.44 0.000 37.81 42.12\rSevere#TT#Winter | 47.20 1.10 43.04 0.000 45.05 49.35\rSevere#TT#Spring | 50.23 1.10 45.81 0.000 48.08 52.39\rSevere#TT#Summer | 49.23 1.10 44.89 0.000 47.08 51.39\rSevere#TT#Fall | 50.00 1.10 45.59 0.000 47.85 52.15\rSevere#HT#Winter | 46.67 1.10 42.55 0.000 44.51 48.82\rSevere#HT#Spring | 49.77 1.10 45.38 0.000 47.61 51.92\rSevere#HT#Summer | 48.57 1.10 44.29 0.000 46.41 50.72\rSevere#HT#Fall | 50.20 1.10 45.78 0.000 48.05 52.35\r--------------------------------------------------------------------------------------\rOptimism by treatment, season, and depression status\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:3:0","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Partial interactions and interaction contrasts Let’s explore ways to dissect the three-way interaction of depstat#treat#season by applying contrasts to one or more of the factors. Let’s begin by testing whether the interaction of treat#depstat is the same for each season compared with winter (season 1). This is performed by applying the r. contrast operator to season and interacting that with treat and depstat. contrast r.season#treat#depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------------\r| df F P\u003eF\r------------------------------------+----------------------------------\rseason#treat#depstat |\r(Spring vs Winter) (joint) (joint) | 4 0.46 0.7619\r(Summer vs Winter) (joint) (joint) | 4 5.36 0.0003\r(Fall vs Winter) (joint) (joint) | 4 0.40 0.8115\rJoint | 12 2.05 0.0179\r|\rDenominator | 1044\r-----------------------------------------------------------------------\rNote! Fall versus spring A custom contrast is applied to season to obtain the comparison of fall versus spring (season 4 versus 2).[ contrast {season 0 -1 0 1}#treat#depstat ] The contrast command below performs this comparison by applying the r3. contrast to season to compare summer with winter (season 3 versus 1) and the r2. contrast on depstat to compare those who are mildly depressed with those who are nondepressed (levels 2 versus 1). These terms are all interacted (that is, r3.season#r2.depstat#treat) yielding a test of summer versus winter (season 3 versus 1) by mildly depressed versus nondepressed (levels 2 versus 1) by treatment. *Season(winter vs. summer) by depstat(nondepressed vs. mildly depressed)by treat contrast r3.season#r2.depstat#treat Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rseason#depstat#treat | 2 9.03 0.0001\r|\rDenominator | 1044\r--------------------------------------------------------\rInteraction contrast of season (winter versus summer) by depression status (mildly depressed versus nondepressed) by treatment\rThis significant test indicates that the two-way interaction formed by interacting depression status (nondepressed versus mildly depressed) by treatment differs by season (winter versus summer) Say that we wanted to take this test and focus on the contrast of happiness therapy versus traditional therapy (group 3 versus 2).1 This yields an interaction of season (winter versus summer) by depression status (nondepressed versus mildly depressed) by treatment (happiness therapy versus traditional therapy). *season(winter vs. summer) by depstat (nondepressed vs mildly depressed) by treat(HT vs. TT) contrast r3.season#r2.depstat#r3b2.treat,noeffects Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rseason#depstat#treat | 1 14.64 0.0001\r|\rDenominator | 1044\r--------------------------------------------------------\rInteraction contrast of season (winter versus summer) by depression status (mildly depressed versus nondepressed) by treatment (HT versus TT)\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:3:1","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.2 Simple interactions Let’s now explore a different way to dissect the three-way interaction through the use of simple interaction tests. contrast depstat#treat@season Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rdepstat#treat@season |\rWinter | 4 3.75 0.0049\rSpring | 4 2.29 0.0575\rSummer | 4 9.88 0.0000\rFall | 4 2.01 0.0904\rJoint | 16 4.48 0.0000\r|\rDenominator | 1044\r--------------------------------------------------------\rThe treat#depstat interaction is significant for winter (season 1) and summer (season 3). The treat#depstat interaction is not significant in the spring (season 2) or fall (season 4) Let’s perform this same contrast command, but apply the r2. contrast to depstat that compares those who are nondepressed versus mildly depressed. This yields four partial interactions of depression status (nondepressed versus mildly depressed) by treatment at each level of season. contrast r2.depstat#treat@season Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------------\r| df F P\u003eF\r------------------------------+----------------------------------\rdepstat#treat@season |\r(Mild vs Non) (joint) Winter | 2 3.49 0.0309\r(Mild vs Non) (joint) Spring | 2 0.27 0.7631\r(Mild vs Non) (joint) Summer | 2 5.74 0.0033\r(Mild vs Non) (joint) Fall | 2 0.38 0.6851\rJoint | 8 2.47 0.0119\r|\rDenominator | 1044\r-----------------------------------------------------------------\rOptimism by treatment and season focusing on mildly depressed versus nondepressed\rLet’s also apply the r3b2. contrast to treat, comparing group 3 with group 2 (happiness therapy to traditional therapy). This yields an interaction contrast of depression status (mildly depressed versus nondepressed) by treatment (happiness therapy versus traditional therapy) performed at each of the four seasons. contrast r2.depstat#r3b2.treat@season,noeffects //r2 means non-dep vs mild-dep Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------------------\r| df F P\u003eF\r---------------------------------+----------------------------------\rdepstat#treat@season |\r(Mild vs Non) (HT vs TT) Winter | 1 5.13 0.0238\r(Mild vs Non) (HT vs TT) Spring | 1 0.30 0.5844\r(Mild vs Non) (HT vs TT) Summer | 1 9.90 0.0017\r(Mild vs Non) (HT vs TT) Fall | 1 0.60 0.4385\rJoint | 4 3.98 0.0033\r|\rDenominator | 1044\r--------------------------------------------------------------------\rSimple interaction contrast of depression status by treatment at each season\r","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:3:2","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.3 Simple effects and simple comparisons We might be interested in focusing on the simple effects of treatment across the levels of season and depression status. contrast treat@season#depstat We could further refine this test by focusing on the comparison of happiness therapy versus traditional therapy (group 3 versus 2) by applying the r3b2. contrast operator to treat, as shown below. contrast r3b2.treat@season#depstat,nowald pveffects this contrast is specified as r3b2.treat,which indicates to compare group 3 with group2. This could have also been specified as a custom contrast,{treat 0 -1 1} Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r--------------------------+---------------------------------------\rtreat@season#depstat |\r(HT vs TT) Winter#Non | 7.00 1.55 4.51 0.000\r(HT vs TT) Winter#Mild | 2.03 1.55 1.31 0.190\r(HT vs TT) Winter#Severe | -0.53 1.55 -0.34 0.731\r(HT vs TT) Spring#Non | 5.37 1.55 3.46 0.001\r(HT vs TT) Spring#Mild | 4.17 1.55 2.69 0.007\r(HT vs TT) Spring#Severe | -0.47 1.55 -0.30 0.764\r(HT vs TT) Summer#Non | 4.33 1.55 2.79 0.005\r(HT vs TT) Summer#Mild | 11.23 1.55 7.24 0.000\r(HT vs TT) Summer#Severe | -0.67 1.55 -0.43 0.667\r(HT vs TT) Fall#Non | 5.83 1.55 3.76 0.000\r(HT vs TT) Fall#Mild | 4.13 1.55 2.67 0.008\r(HT vs TT) Fall#Severe | 0.20 1.55 0.13 0.897\r------------------------------------------------------------------\rThis shows that for some combinations of season and depstat, the difference between happiness and traditional therapy is significant. For example, in season 1 (winter) and depression status 1 (nondepressed), the difference between happiness and traditional therapy is significant, with happiness therapy yielding optimism scores that are 7 points greater than traditional therapy ","date":"2024-01-07","objectID":"/9.chapter9categorical-by-categorical-by-categorical-interactions/:3:3","tags":["Categorical","Interaction","stata"],"title":"Chapter9 ：Categorical by categorical by categorical interactions","uri":"/9.chapter9categorical-by-categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve the interaction of two categorical variables. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates models that involve the interaction of two categorical variables.The emphasis of this chapter is not only how to test for interactions between factor variables but also how to understand and dissect those interactions. This chapter focuses on three types of interactions: two by two interactions. two by three interactions. three by three interactions. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:0:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Two by two models: Example 1 In this first hypothetical study, she seeks to determine the effectiveness of happiness therapy by comparing the optimism of people who have completed happiness therapy treatment with the optimism of people in a control group who received no treatment. The researcher is interested in not only assessing the effectiveness of happiness therapy but also assessing whether its effectiveness depends on whether the person has been diagnosed as clinically depressed. This yields a two by two research design, crossing treatment group assignment (control group versus happiness therapy) with depression status (nondepressed versus depressed). The variable treat indicates the treatment assignment, coded: 1 = control group (Con) and 2 = happiness therapy (HT). The variable depstat reflects the person’s depression status at the beginning of the study and is coded: 1 = nondepressed and 2 = depressed. The variable opt is the optimism score at the end of the study. In this dataset, opt has a mean of 44.5, a minimum of 16, and a maximum of 80. Let’s now run an analysis that predicts opt based on treat, depstat, and the interaction of these two variables. This analysis uses the anova command (instead of the regress command) because the anova command directly shows the significance tests for each of the main effects as well as the interaction. use opt-2by2.dta anova opt depstat##treat Number of obs = 120 R-squared = 0.4889\rRoot MSE = 10.0136 Adj R-squared = 0.4757\rSource | Partial SS df MS F Prob\u003eF\r--------------+----------------------------------------------------\rModel | 11126 3 3708.6667 36.99 0.0000\r|\rdepstat | 7426.1333 1 7426.1333 74.06 0.0000\rtreat | 2803.3333 1 2803.3333 27.96 0.0000\rdepstat#treat | 896.53333 1 896.53333 8.94 0.0034\r|\rResidual | 11631.467 116 100.27126 --------------+----------------------------------------------------\rTotal | 22757.467 119 191.23922 Note! The anova and regress commands if you want use regress command in stead of the anova command to fit the previous model, there are two caveats: the regress command will require an extra step using the contrast command to test the overall interaction (for example, contrast depstat#treat). the tests of the main effects differ when using the regress command compared with the anova command. The significant interaction indicates that the effect of happiness therapy for those who are nondepressed is significantly different from the effect of happiness therapy for those who are depressed. margins treat#depstat,nopvalues marginsplot Adjusted predictions Number of obs = 120\rExpression: Linear prediction, predict()\r---------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r--------------+------------------------------------------------\rtreat#depstat |\rCon#Non | 44.87 1.83 41.25 48.49\rCon#Dep | 34.60 1.83 30.98 38.22\rHT#Non | 60.00 1.83 56.38 63.62\rHT#Dep | 38.80 1.83 35.18 42.42\r---------------------------------------------------------------\rGraph of means\r","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:1:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Simple effects The significant interaction indicates that the effect of happiness therapy is different for those who are depressed versus nondepressed. Each of these effects is called a simple effect, because they reflect the effect of one variable while holding another variable constant. We can estimate and test these simple effects using the contrast command, as shown below. Note the use of the @ symbol. This requests the simple effect of treat at each level of depstat. contrast treat@depstat contrast treat@depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rtreat@depstat |\r(HT vs base) Non | 15.13 2.59 5.85 0.000\r(HT vs base) Dep | 4.20 2.59 1.62 0.107\r----------------------------------------------------------\rBy adding the nowald and pveffects options, the contrast command displays a table with the estimate of the simple effect, the standard error, and a significance test of the simple effect. This shows the effect of treatment among those who are nondepressed equals 15.1, and this effect is significant ( $t = 5.85,p=0.000$ ). Among those who are depressed, the treatment effect is 4.2, and this difference is not significant ( $t = 1.62,p=0.107$ ). Note! Contrast options Combining the nowald and pveffects options provides a concise output that includes an estimate of the size of the contrast and a test of its significance. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:1:1","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Estimating the size of the interaction As we saw in the analysis of the simple effects, the simple effect of treatment is 4.2 for those who are depressed and is 15.1 for those who are nondepressed. Taking the difference in these simple effects ($4.2 - 15.1$) gives us an estimate of the size of the interaction, which is $-10.9$. This is the same value that we obtain if we estimate the interaction using the contrast command below. Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r----------------------------+---------------------------------------\rtreat#depstat |\r(HT vs base) (Dep vs base) | -10.93 3.66 -2.99 0.003\r--------------------------------------------------------------------\rthe $p$-value for this test matches the $p$-value of the treat#depstat interaction from the original anova command. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:1:2","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 More about interaction let’s further explore what we mean by an interaction by considering the hypothetical pattern of results shown in below. Two by two with no interaction\rThis is an example pattern in which there is no interaction between treatment and depression status. One way we can see the absence of an interaction is by seeing that the line for D1 is parallel to the line for D2. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:1:3","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Two by three models his section considers models where one of the categorical variables has two levels and the other categorical variable has three levels. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:2:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Example 2 Referring to the example from the previous section, depression status had two levels, nondepressed and depressed. Suppose that we instead use three categories for depression status: nondepressed, mildly depressed, and severely depressed. Let’s now perform an analysis predicting optimism from treatment group, depression status, and the interaction of these two variables. use opt-2by3-ex1.dta anova opt depstat##treat Number of obs = 180 R-squared = 0.5402\rRoot MSE = 10.0154 Adj R-squared = 0.5270\rSource | Partial SS df MS F Prob\u003eF\r--------------+----------------------------------------------------\rModel | 20505.828 5 4101.1656 40.89 0.0000\r|\rdepstat | 15432.844 2 7716.4222 76.93 0.0000\rtreat | 3183.6056 1 3183.6056 31.74 0.0000\rdepstat#treat | 1889.3778 2 944.68889 9.42 0.0001\r|\rResidual | 17453.567 174 100.30785 --------------+----------------------------------------------------\rTotal | 37959.394 179 212.06366 As expected, the depstat#treat interaction is significant. We can compute the mean optimism as a function of depression status and treatment group by using the margins command below. Had there been additional predictors in the model, the margins command would have produced adjusted means, adjusting for the other predictors in the model. margins treat#depstat,nopvalues marginsplot Adjusted predictions Number of obs = 180\rExpression: Linear prediction, predict()\r---------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r--------------+------------------------------------------------\rtreat#depstat |\rCon#Non | 44.23 1.83 40.62 47.84\rCon#Mild | 39.63 1.83 36.02 43.24\rCon#Sev | 29.80 1.83 26.19 33.41\rHT#Non | 59.60 1.83 55.99 63.21\rHT#Mild | 49.73 1.83 46.12 53.34\rHT#Sev | 29.57 1.83 25.96 33.18\r---------------------------------------------------------------\rGraph of means\r2.1.1 Simple effects We can ask whether the effect of happiness therapy is significant at each level of depression status. contrast treat@depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------------+---------------------------------------\rtreat@depstat |\r(HT vs base) Non | 15.37 2.59 5.94 0.000\r(HT vs base) Mild | 10.10 2.59 3.91 0.000\r(HT vs base) Sev | -0.23 2.59 -0.09 0.928\r-----------------------------------------------------------\rThis test of simple effects tells us that happiness therapy is significantly better than the control group for those who are nondepressed and for those who are mildly depressed. For those who are severely depressed, happiness therapy is not significantly different from being in the control group 2.1.2 Partial interactions Another way to dissect a two by three interaction is through the use of partial interactions. In this example, a partial interaction is constructed by applying a contrast operator to depstat and interacting that with treat. For example, applying the a.contrast operator to depstat yields two contrasts: group 1 versus 2 (Non vs Mild depression); and group 2 versus 3 (Mild vs Sev depression). Interacting a.depstat with treat forms two partial interactions. contrast a.depstat#treat Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| df F P\u003eF\r-----------------------+----------------------------------\rdepstat#treat |\r(Non vs Mild) (joint) | 1 2.07 0.1516\r(Mild vs Sev) (joint) | 1 7.98 0.0053\rJoint | 2 9.42 0.0001\r|\rDenominator | 174\r----------------------------------------------------------\rThe first partial interaction is not significant ( $F = 2.07 , p = 0.1516$ ).The effect of happiness therapy (compared with the control group) is not significantly different for those who are nondepressed versus mildly depressed. The second partial interaction is significant ( $F = 7.98 , p = 0.0053$ ). The effect of happiness therapy (compared with the con","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:2:1","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Three by three models: Example 4 Let’s now consider an example that illustrates a three by three design. there are three levels of treatment (control group, traditional therapy, and happiness therapy), and three depression groups (nondepressed, mildly depressed, and severely depressed) use opt-3by3.dta.dta anova opt depstat##treat Number of obs = 270 R-squared = 0.4898\rRoot MSE = 10.023 Adj R-squared = 0.4742\rSource | Partial SS df MS F Prob\u003eF\r--------------+----------------------------------------------------\rModel | 25175.519 8 3146.9398 31.32 0.0000\r|\rdepstat | 17664.096 2 8832.0481 87.92 0.0000\rtreat | 5250.363 2 2625.1815 26.13 0.0000\rdepstat#treat | 2261.0593 4 565.26481 5.63 0.0002\r|\rResidual | 26220.367 261 100.46117 --------------+----------------------------------------------------\rTotal | 51395.885 269 191.06277 margins treat#depstat,nopvalues marginsplot Adjusted predictions Number of obs = 270\rExpression: Linear prediction, predict()\r---------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r--------------+------------------------------------------------\rtreat#depstat |\rCon#Non | 44.20 1.83 40.60 47.80\rCon#Mild | 39.70 1.83 36.10 43.30\rCon#Sev | 29.90 1.83 26.30 33.50\rTT#Non | 54.53 1.83 50.93 58.14\rTT#Mild | 49.53 1.83 45.93 53.14\rTT#Sev | 39.80 1.83 36.20 43.40\rHT#Non | 59.33 1.83 55.73 62.94\rHT#Mild | 49.87 1.83 46.26 53.47\rHT#Sev | 30.10 1.83 26.50 33.70\r---------------------------------------------------------------\rMean optimism by treatment group and depression status\rWe can statistically dissect this interaction in four different ways: using simple effects , simple contrasts , partial interactions , or interaction contrasts . Each of these techniques is illustrated below ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:3:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Simple effects One way to dissect the interaction is by looking at the effect of treatment at each level of depression status. contrast treat@depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------\r| df F P\u003eF\r--------------+----------------------------------\rtreat@depstat |\rNon | 2 17.86 0.0000\rMild | 2 9.96 0.0001\rSev | 2 9.56 0.0001\rJoint | 6 12.46 0.0000\r|\rDenominator | 261\r-------------------------------------------------\rThese results show that the effect of treat is significant at each level of depstat. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:3:1","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.2 Simple contrast contrast r.treat@1.depstat,nowald pveffects This yields a comparison of each treatment group with the reference group (that is, group 1, the control group) at each level of depression status. Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------+---------------------------------------\rtreat@depstat |\r(TT vs Con) Non | 10.33 2.59 3.99 0.000\r(HT vs Con) Non | 15.13 2.59 5.85 0.000\r---------------------------------------------------------\rLet’s now perform these simple contrasts for those who are mildly depressed. contrast r.treat@2.depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rtreat@depstat |\r(TT vs Con) Mild | 9.83 2.59 3.80 0.000\r(HT vs Con) Mild | 10.17 2.59 3.93 0.000\r----------------------------------------------------------\rFinally, let’s perform these simple contrasts for those who are severely depressed. contrast r.treat@3.depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------+---------------------------------------\rtreat@depstat |\r(TT vs Con) Sev | 9.90 2.59 3.83 0.000\r(HT vs Con) Sev | 0.20 2.59 0.08 0.938\r---------------------------------------------------------\rIf you prefer, you can obtain all six of these simple contrasts at once using the contrast command below contrast r.treat@depstat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rtreat@depstat |\r(TT vs Con) Non | 10.33 2.59 3.99 0.000\r(TT vs Con) Mild | 9.83 2.59 3.80 0.000\r(TT vs Con) Sev | 9.90 2.59 3.83 0.000\r(HT vs Con) Non | 15.13 2.59 5.85 0.000\r(HT vs Con) Mild | 10.17 2.59 3.93 0.000\r(HT vs Con) Sev | 0.20 2.59 0.08 0.938\r----------------------------------------------------------\r","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:3:2","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.3 Partial interaction I used the means from the margins command to create a visual depiction of these two partial interactions, shown in figure below. The left panel of figure illustrates the comparison of treatment group 2 versus 1 (traditional therapy versus control) interacted with depression status. The right panel illustrates the comparison of treatment group 3 versus 1 (happiness therapy versus control) interacted with depression status Partial interactions\rcontrast r.treat#depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r--------------------------------------------------------\r| df F P\u003eF\r---------------------+----------------------------------\rtreat#depstat |\r(TT vs Con) (joint) | 2 0.01 0.9891\r(HT vs Con) (joint) | 2 8.64 0.0002\rJoint | 4 5.63 0.0002\r|\rDenominator | 261\r--------------------------------------------------------\rThe first partial interaction is not significant.The difference in optimism between traditional therapy and the control group does not differ among the levels of depression status. This result represent the left panel:The effect of traditional therapy (versus the control group) is similar for all three lines (representing the three levels of depression). The first partial interaction is not significant.The difference in optimism between happiness therapy and the control group depends on the level of depression. This result represent the right panel:the effect of happiness therapy (compared with the control group) may be similar for those who are nondepressed and mildly depressed but different for those who are severely depressed. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:3:3","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.4 Interaction contrasts Suppose we applied the r. contrast operator to treatment group and the a. contrast operator to depression status. This would create contrasts of each treatment group against the control group (that is, group 2 versus 1 and group 3 versus 1) interacted with contrasts of adjacent levels of depression groups (that is, group 1 versus 2 and group 2 versus 3). contrast a.depstat#r.treat,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------------------+---------------------------------------\rdepstat#treat |\r(Non vs Mild) (TT vs Con) | 0.50 3.66 0.14 0.891\r(Non vs Mild) (HT vs Con) | 4.97 3.66 1.36 0.176\r(Mild vs Sev) (TT vs Con) | -0.07 3.66 -0.02 0.985\r(Mild vs Sev) (HT vs Con) | 9.97 3.66 2.72 0.007\r-------------------------------------------------------------------\rInteraction contrasts\rLet’s begin by interpreting the fourth interaction contrast, the only one that was significant. The significance of this interaction contrast indicates that the effect of happiness therapy (compared with the control group) is different for those who are mildly depressed compared with those who are severely depressed. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:3:4","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Unbalanced designs Even in the context of a randomized experiment, it is unusual to have the same number of observations in each cell. This section presents an example of an unbalanced design. This will allow us to consider two different strategies that can be used for estimating adjusted means, the asobserved strategy and the as-balanced strategy. As we will see, the asbalanced option can be used with the margins command to estimate margins as though the design were balanced, even if the actual design is not balanced. use gss_ivrm.dta tab married cograd if !missing(happy7),row +----------------+\r| Key |\r|----------------|\r| frequency |\r| row percentage |\r+----------------+\rmarital: |\rmarried=1, |\runmarried= | College graduate\r0 | (1=yes, 0=no)\r(recoded) | Not CO Gr CO Grad | Total\r-----------+----------------------+----------\rUnmarried | 454 147 | 601 | 75.54 24.46 | 100.00 -----------+----------------------+----------\rMarried | 403 153 | 556 | 72.48 27.52 | 100.00 -----------+----------------------+----------\rTotal | 857 300 | 1,157 | 74.07 25.93 | 100.00 Before performing the analysis, let’s compute the mean of happy7 by married and cograd using the tabulate command below tab married cograd,sum(happy7) marital: |\rmarried=1, |\runmarried= | College graduate\r0 | (1=yes, 0=no)\r(recoded) | Not CO Gr CO Grad | Total\r-----------+----------------------+----------\rUnmarried | 5.3039648 5.5170068 | 5.3560732\r| 1.0590229 .99556373 | 1.0470596\r| 454 147 | 601\r-----------+----------------------+----------\rMarried | 5.7121588 5.6862745 | 5.705036\r| .8986037 .79032462 | .86953016\r| 403 153 | 556\r-----------+----------------------+----------\rTotal | 5.495916 5.6033333 | 5.5237684\r| 1.0071217 .89926887 | .9810472\r| 857 300 | 1157\rLet’s now perform an analysis that predicts happy7 from married, cograd, and the interaction of these two variables. anova happy7 married##cograd Number of obs = 1,157 R-squared = 0.0362\rRoot MSE = .964375 Adj R-squared = 0.0337\rSource | Partial SS df MS F Prob\u003eF\r---------------+----------------------------------------------------\rModel | 40.284425 3 13.428142 14.44 0.0000\r|\rmarried | 18.502336 1 18.502336 19.89 0.0000\rcograd | 1.94355 1 1.94355 2.09 0.1486\rmarried#cograd | 3.1674385 1 3.1674385 3.41 0.0652\r|\rResidual | 1072.3119 1,153 .93001903 ---------------+----------------------------------------------------\rTotal | 1112.5964 1,156 .96245361 We can see that the married#cograd interaction is not significant ($p = 0.0652$). Let’s assume that we want to retain this interaction. (We may want to retain it based on theoretical considerations or because its -value is close to 0.05.) Let’s now turn our attention to married, which is significant ($p\u003c0.001$). To understand this significant result, let’s use the margins command to compute the adjusted means by the levels of married. margins married,nopvalues Predictive margins Number of obs = 1,157\rExpression: Linear prediction, predict()\r--------------------------------------------------------------\r| Delta-method\r| Margin std. err. [95% conf. interval]\r-------------+------------------------------------------------\rmarried |\rUnmarried | 5.36 0.04 5.28 5.44\rMarried | 5.71 0.04 5.63 5.79\r--------------------------------------------------------------\rWe can think of this adjusted mean as being computed by taking each cell mean of happy7 among those who are not married and weighing it by the corresponding proportion of those are college graduates or noncollege graduates, as illustrated below. $ 454 num ÷ 601 = 0.74$ $ 147 num ÷ 601 = 0.26$ $ 5.3039648 * 0.7407 + 5.5170068 * 0.2593 = 5.3592066 $ We can likewise compute the adjusted mean for those who are married using the same strategy, as shown below. $ 5.7121588 * 0.7407 + 5.6862745 * 0.2593 = 5.05447$ The key point is that the adjusted means are computed by creating a weighted average of cell means that is weighted by the observed proportions of observations in the data (in this case, the observed proportions of cograd)","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:4:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Main effects with interactions: anova versus regress This section considers the meaning of main effects in the presence of an interaction when using the regress command compared with the anova command. In the presence of interactions, this can lead to conflicting estimates of so-called main effects for the regress command versus the anova command. Let’s use the dataset for this example and show the mean optimism by treatment group and depression status. use opt-2by2.dta anova opt treat##depstat Number of obs = 120 R-squared = 0.4889\rRoot MSE = 10.0136 Adj R-squared = 0.4757\rSource | Partial SS df MS F Prob\u003eF\r--------------+----------------------------------------------------\rModel | 11126 3 3708.6667 36.99 0.0000\r|\rtreat | 2803.3333 1 2803.3333 27.96 0.0000\rdepstat | 7426.1333 1 7426.1333 74.06 0.0000\rtreat#depstat | 896.53333 1 896.53333 8.94 0.0034\r|\rResidual | 11631.467 116 100.27126 --------------+----------------------------------------------------\rTotal | 22757.467 119 191.23922 Let’s now perform this analysis but instead use the regress command. reg opt treat##depstat,vsquish Source | SS df MS Number of obs = 120\r-------------+---------------------------------- F(3, 116) = 36.99\rModel | 11126 3 3708.66667 Prob \u003e F = 0.0000\rResidual | 11631.4667 116 100.271264 R-squared = 0.4889\r-------------+---------------------------------- Adj R-squared = 0.4757\rTotal | 22757.4667 119 191.239216 Root MSE = 10.014\r-------------------------------------------------------------------------------\ropt | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r--------------+----------------------------------------------------------------\rtreat |\rHT | 15.13 2.59 5.85 0.000 10.01 20.25\rdepstat |\rDep | -10.27 2.59 -3.97 0.000 -15.39 -5.15\rtreat#depstat |\rHT#Dep | -10.93 3.66 -2.99 0.003 -18.18 -3.69\r_cons | 44.87 1.83 24.54 0.000 41.25 48.49\r-------------------------------------------------------------------------------\rLet’s now compare the results of the anova command with the results of the regress command, focusing on the significance tests. These comparisons are a bit tricky, because the anova command reports $F$ statistics, whereas the regress command reports $t$ statistics. But we can square the value from the regress command to convert it into an equivalent of an statistic. If we square $t$ the value of $-2.99$ from the regress command, we obtain the 8.94, the same value as $F$ the statistic from the anova command. Using the contrast treat#depstat command following the regress command also yields the same results as the anova command. The value from the contrast command is the same as the $F$ value from the anova command, 8.94. contrast treat#depstat Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------\r| df F P\u003eF\r--------------+----------------------------------\rtreat#depstat | 1 8.94 0.0034\r|\rDenominator | 116\r-------------------------------------------------\rLet’s now compare the test of treat from the anova command with the regress command. We square of the $t$ value for the treat effect from the regress command(5.85) and obtain 34.22. This is different from the $F$ value for the treat effect from the anova command, 27.96. contrast treat Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rtreat | 1 27.96 0.0000\r|\rDenominator | 116\r------------------------------------------------\rThis might seem perplexing, but there is a perfectly logical explanation for this. The reason for these discrepancies is because of differences in the coding used by the anova and regress commands. The regress command uses dummy (0/1) coding, whereas the anova command and the contrast command use effect ($-1/1$) coding.The interpretation of the interactions is the same whether you use effect coding or dummy coding, but the meaning of the main effects differ. The interpretation of the inte","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:5:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"6 Interpreting confidence intervals use gss_ivrm.dta anova happy7 i.marital3##i.gender c.health Number of obs = 783 R-squared = 0.1246\rRoot MSE = .941504 Adj R-squared = 0.1178\rSource | Partial SS df MS F Prob\u003eF\r----------------+----------------------------------------------------\rModel | 97.864391 6 16.310732 18.40 0.0000\r|\rmarital3 | 26.17214 2 13.08607 14.76 0.0000\rgender | 3.8126465 1 3.8126465 4.30 0.0384\rmarital3#gender | 2.4708203 2 1.2354101 1.39 0.2488\rhealth | 51.985684 1 51.985684 58.65 0.0000\r|\rResidual | 687.86996 776 .88643037 ----------------+----------------------------------------------------\rTotal | 785.73436 782 1.0047754 Let’s compute the adjusted means of happiness by marital3 by gender using the margins command and graph them using the marginsplot command margins marital3#gender marginsplot Predictive margins Number of obs = 783\rExpression: Linear prediction, predict()\r---------------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r----------------------+----------------------------------------------------------------\rmarital3#gender |\rMarried#Male | 5.68 0.09 59.93 0.000 5.50 5.87\rMarried#Female | 5.69 0.06 98.87 0.000 5.57 5.80\rPrevmarried#Male | 5.13 0.11 44.95 0.000 4.90 5.35\rPrevmarried#Female | 5.29 0.08 64.16 0.000 5.13 5.46\rNever married#Male | 5.27 0.09 57.86 0.000 5.09 5.45\rNever married#Female | 5.55 0.09 60.82 0.000 5.37 5.73\r---------------------------------------------------------------------------------------\rAdjusted means of happiness by marital status and gender\rwe would need to test the effect of gender at each level of marital status using the margins command, as shown below. margins gender@marital3,contrast(nowald pveffects) Contrasts of predictive margins Number of obs = 783\rExpression: Linear prediction, predict()\r------------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r--------------------------------+---------------------------------------\rgender@marital3 |\r(Female vs base) Married | 0.01 0.11 0.05 0.961\r(Female vs base) Prevmarried | 0.17 0.14 1.20 0.231\r(Female vs base) Never married | 0.29 0.13 2.21 0.027\r------------------------------------------------------------------------\rIn summary, the marginsplot command provides a graphical display of the results calculated by the margins command. Sometimes, the appearance of the confidence intervals of individual groups might tempt you to inappropriately make statistical inferences about the comparisons between the groups. To avoid this trap, you can directly form comparisons among the groups of interest to ascertain the significance of the group differences. ","date":"2024-01-06","objectID":"/8.chapter8categorical-by-categorical-interactions/:6:0","tags":["Categorical","Interaction","stata"],"title":"Chapter8 ：Categorical by categorical interactions","uri":"/8.chapter8categorical-by-categorical-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter covers models that involve categorical predictors.","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter covers models that involve categorical predictors. The emphasis is on how to make contrasts among levels of the categorical predictor to answer interesting questions regarding the differences among the categories. ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:0:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Comparing two groups using a t test The simplest kind of categorical predictor has two levels. Examples of such twolevel predictors include gender (male versus female), treatment assignment (treatment group versus control group), or whether one is married (married versus not married). The variable happy7 indicates the happiness rating of the respondent on a 1 to 7 scale, where 7 is completely happy and 1 is completely unhappy. To compare the average happiness between those who are married and unmarried, we can perform an independent groups $t$test, as shown below. use gss_ivrm.dta ttest happy7, by(married) The variable happy7 indicates the happiness rating of the respondent on a 1 to 7 scale, where 7 is completely happy and 1 is completely unhappy. To compare the average happiness between those who are married and unmarried, we can perform an independent groups $t$ test, Two-sample t test with equal variances\r------------------------------------------------------------------------------\rGroup | Obs Mean Std. err. Std. dev. [95% conf. interval]\r---------+--------------------------------------------------------------------\rUnmarrie | 604 5.35596 .0425197 1.044982 5.272456 5.439465\rMarried | 556 5.705036 .0368763 .8695302 5.632602 5.77747\r---------+--------------------------------------------------------------------\rCombined | 1,160 5.523276 .0287773 .9801179 5.466815 5.579737\r---------+--------------------------------------------------------------------\rdiff | -.3490757 .0567084 -.4603384 -.237813\r------------------------------------------------------------------------------\rdiff = mean(Unmarrie) - mean(Married) t = -6.1556\rH0: diff = 0 Degrees of freedom = 1158\rHa: diff \u003c 0 Ha: diff != 0 Ha: diff \u003e 0\rPr(T \u003c t) = 0.0000 Pr(|T| \u003e |t|) = 0.0000 Pr(T \u003e t) = 1.0000\rThe t-test command shows that the average happiness is 5.356 for those who are unmarried and 5.705 for those who are married. The difference between these means is $-0.349$, and that difference is significantly different from 0 (with a two-tailed value of 0.0000). The difference between these means is negative. We can interpret this result to say that those who are unmarried are significantly less happy than those who are married. We could also say that those who are married are significantly happier than those who are unmarried ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:1:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 More groups and more predictors We are seldom interested in simply comparing two groups in the absence of any additional predictors (covariates). Let’s extend the previous example in two ways. First, let’s use a five-level measure of marital status, which is coded: 1 = married, 2 = widowed, 3 = divorced, 4 = separated, and 5 = never married. Second, let’s include additional predictors (covariates): gender,2 race, and age. We begin by testing the overall null hypothesis that the average happiness is equal among the five marital status groups: $$ H_{0} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}$$ I included the i. prefix before each of the categorical variables and the c. prefix in front of age to specify that it is a continuous variable. use gss_ivrm.dta anova happy7 i.marital i.gender i.race c.age Number of obs = 1,156 R-squared = 0.0488\rRoot MSE = .957826 Adj R-squared = 0.0422\rSource | Partial SS df MS F Prob\u003eF\r-----------+----------------------------------------------------\rModel | 53.979104 8 6.747388 7.35 0.0000\r|\rmarital | 47.156057 4 11.789014 12.85 0.0000\rgender | 3.8954776 1 3.8954776 4.25 0.0396\rrace | .92449374 2 .46224687 0.50 0.6043\rage | 5.3200497 1 5.3200497 5.80 0.0162\r|\rResidual | 1052.2934 1,147 .91743103 -----------+----------------------------------------------------\rTotal | 1106.2725 1,155 .95781168 Note! The anova and regress commands In this chapter (as well as chapters 8 and 9), my focus will be on starting the analysis with an assessment of the main effects (and interactions, if any) using the omnibus $F$-tests provided by the anova command. I would emphasize, however, that these same results could be obtained via the regress command. Note! Omnibus $F$-tests Omnibus F-tests are statistical tests used to assess the overall significance or goodness-of-fit of a regression model. These tests evaluate the joint significance of multiple coefficients in the model or the overall explanatory power of the regression equation. In regression analysis, the Omnibus F-test is typically used to determine whether there is a significant relationship between the predictor variables and the dependent variable. It examines the overall fit of a model by comparing the variance explained by the model to the unexplained variance (residuals) around the regression line. The steps involved in performing an Omnibus F-test include: Fit the regression model using the given predictor variables. Calculate the overall F-statistic using the explained and unexplained variance from the model. Obtain the degrees of freedom for the F-distribution based on the number of predictors and the sample size. Compare the calculated F-statistic with the critical value from the F-distribution at a specified significance level (commonly 0.05 or 0.01). If the calculated F-statistic exceeds the critical value, the null hypothesis is rejected, indicating that the overall model is statistically significant. The overall test of marital is significant ( , ). After adjusting for gender, race, and age, we can reject the null hypothesis that the average happiness is equal among the five marital status groups. Let’s probe this finding in more detail. Suppose that our research hypothesis (prior to even seeing the data) was that those who are married will be happier than each of the four other marital status groups. We can frame this as four separate null hypotheses, shown below $$H_{0}: \\mu_{2} = \\mu_{1} $$ $$H_{0}: \\mu_{3} = \\mu_{1} $$ $$H_{0}: \\mu_{4} = \\mu_{1} $$ $$H_{0}: \\mu_{5} = \\mu_{1} $$ Let’s begin the exploration of these tests by using the margins command to compute the adjusted mean of happiness by marital status. margins marital marginsplot Predictive margins Number of obs = 1,156\rExpression: Linear prediction, predict()\r--------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r---------------+----------------------------------------------------------------\rmarital |","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:2:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Overview of contrast operators the contrast operators table provides a brief description of each contrast operator and shows the section of this chapter in which each contrast operator is covered. Summary of contrast operators\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:3:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Compare each group against a reference group This section provides further examples illustrating the r. contrast operator for making reference group contrasts. Let’s continue with the example that predicting happiness from marital status, adjusting for gender, race, and age. use gss_ivrm.dta anova happy7 i.marital i.gender i.race c.age Number of obs = 1,156 R-squared = 0.0488\rRoot MSE = .957826 Adj R-squared = 0.0422\rSource | Partial SS df MS F Prob\u003eF\r-----------+----------------------------------------------------\rModel | 53.979104 8 6.747388 7.35 0.0000\r|\rmarital | 47.156057 4 11.789014 12.85 0.0000\rgender | 3.8954776 1 3.8954776 4.25 0.0396\rrace | .92449374 2 .46224687 0.50 0.6043\rage | 5.3200497 1 5.3200497 5.80 0.0162\r|\rResidual | 1052.2934 1,147 .91743103 -----------+----------------------------------------------------\rTotal | 1106.2725 1,155 .95781168 ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:4:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.1 Selecting a specific contrast Suppose you wanted to focus on the contrast of group 3 to group 1 (divorced versus married) and group 5 to group 1 (never married versus married). You can perform those two contrasts by specifying the r(3 5). contrast operator. This compares each of the groups within the parentheses with the reference group (group 1). contrast r(3 5).marital,pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------------\r| df F P\u003eF\r----------------------------+----------------------------------\rmarital |\r(divorced vs married) | 1 39.38 0.0000\r(never married vs married) | 1 4.18 0.0411\rJoint | 2 19.78 0.0000\r|\rDenominator | 1147\r---------------------------------------------------------------\r--------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r----------------------------+---------------------------------------\rmarital |\r(divorced vs married) | -0.50 0.08 -6.28 0.000\r(never married vs married) | -0.16 0.08 -2.04 0.041\r--------------------------------------------------------------------\rNote! Options on the contrast command The previous contrast command included two options: nowald and pveffects. This yields concise output that fits well on the pages of this book. When you run such analyses yourself, I recommend specifying the options nowald and effects, which will display both significance tests and confidence intervals associated with each comparison. ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:4:1","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.2 Selecting a different reference group Suppose that instead we wanted to compare each group with a different reference group. We can specify the rb5. contrast operator, which requests reference group contrasts using group 5 (never married) as the baseline (reference) group. contrast rb5.marital,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------------------+---------------------------------------\rmarital |\r(married vs never married) | 0.16 0.08 2.04 0.041\r(widowed vs never married) | -0.30 0.14 -2.06 0.040\r(divorced vs never married) | -0.34 0.09 -3.62 0.000\r(separated vs never married) | -0.39 0.18 -2.24 0.026\r----------------------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:4:2","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.3 Selecting a contrast and reference group You can both specify the reference group and specify the contrasts to be made at one time. contrast r(1 3)b5.marital,nowald pveffects //(1 versus 5)(3 versus 5) Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------------------+---------------------------------------\rmarital |\r(married vs never married) | 0.16 0.08 2.04 0.041\r(divorced vs never married) | -0.34 0.09 -3.62 0.000\r---------------------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:4:3","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Compare each group against the grand mean This section illustrates the g. contrast operator that compares each group with the grand mean of all groups. a researcher might be interested in comparing the mean happiness of each marital status group versus the grand mean of all groups. use gss_ivrm.dta anova happy7 i.marital i.gender i.race c.age margins g.marital,contrast(nowald pveffects) the prefix “g” means the mean happiness of each marital status group with the grand mean Contrasts of predictive margins Number of obs = 1,156\rExpression: Linear prediction, predict()\r-----------------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r-------------------------+---------------------------------------\rmarital |\r(married vs mean) | 0.33 0.05 6.12 0.000\r(widowed vs mean) | -0.12 0.10 -1.18 0.240\r(divorced vs mean) | -0.17 0.07 -2.44 0.015\r(separated vs mean) | -0.22 0.14 -1.61 0.107\r(never married vs mean) | 0.18 0.07 2.48 0.013\r-----------------------------------------------------------------\rmarginsplot,yline(0) When the confidence interval for a contrast excludes zero, the difference is significant at the 5% level. Contrasts comparing each group with the grand mean\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:5:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"6 Compare adjacent means This section illustrates contrasts that compare the means of adjacent groups, for example, group 1 versus 2, group 2 versus 3, group 3 versus 4. These kinds of contrasts are especially useful for studies where you expect a nonlinear relationship between an ordinal or interval predictor and outcome. For example, consider a hypothetical study about the dosage of a new pain medication where the researchers expect that at a certain dosage level the effects of the medication will kick in and lead to a statistically significant reduction in pain. The medication dosages range from 0 mg to 250 mg incrementing by 50 mg, yielding six dosage groups. use pain codebook dosegrp Type: Numeric (float)\rLabel: dosegrp\rRange: [1,6] Units: 1\rUnique values: 6 Missing .: 0/180\rTabulation: Freq. Numeric Label\r30 1 0mg\r30 2 50mg\r30 3 100mg\r30 4 150mg\r30 5 200mg\r30 6 250mg\rLet’s begin the analysis relating pain to medication dosage by testing the most general null hypothesis that could be tested—that the average pain is equal across all six dosage groups: $$ H_{0} = \\mu_{2} = \\mu_{3} = \\mu_{4} = \\mu_{5}$$ This null hypothesis is tested using the anova command shown below. anova pain i.dosegrp Number of obs = 180 R-squared = 0.4602\rRoot MSE = 10.4724 Adj R-squared = 0.4447\rSource | Partial SS df MS F Prob\u003eF\r-----------+----------------------------------------------------\rModel | 16271.694 5 3254.3389 29.67 0.0000\r|\rdosegrp | 16271.694 5 3254.3389 29.67 0.0000\r|\rResidual | 19082.633 174 109.67031 -----------+----------------------------------------------------\rTotal | 35354.328 179 197.51021 he $F$ value is 29.67 and is significant. We can reject the overall null hypothesis. Let’s use the margins command and the marginsplot command to display and graph the predicted mean of pain by dosegrp. margins dosegrp //the predicted mean of pain by dosegrp marginsplot Adjusted predictions Number of obs = 180\rExpression: Linear prediction, predict()\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rdosegrp |\r0mg | 71.83 1.91 37.57 0.000 68.06 75.61\r50mg | 70.60 1.91 36.93 0.000 66.83 74.37\r100mg | 72.13 1.91 37.73 0.000 68.36 75.91\r150mg | 70.40 1.91 36.82 0.000 66.63 74.17\r200mg | 54.70 1.91 28.61 0.000 50.93 58.47\r250mg | 48.30 1.91 25.26 0.000 44.53 52.07\r------------------------------------------------------------------------------\rMean pain rating by dosage group\rFor this study, the research question of interest focuses on the test of each dosage against the previous dosage to determine the dosage that leads to a statistically significant decrease in pain. This leads us to five specific null hypotheses. $$H_{0}: \\mu_{1} = \\mu_{2} $$ $$H_{0}: \\mu_{2} = \\mu_{3} $$ $$H_{0}: \\mu_{3} = \\mu_{4} $$ $$H_{0}: \\mu_{4} = \\mu_{5} $$ $$H_{0}: \\mu_{5} = \\mu_{6} $$ Let’s now test each of the hypotheses using the contrast command with the a. contrast operator to compare each dosage with the adjacent (subsequent) dosage. margins a.dosegrp,contrast(nowald pveffects) margins a.dosegrp,contrast(nowald cieffects) //specify cieffects in lieu of pveffects marginsplot,yline(0) Contrasts of adjusted predictions Number of obs = 180\rExpression: Linear prediction, predict()\r----------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r------------------+---------------------------------------\rdosegrp |\r(0mg vs 50mg) | 1.23 2.70 0.46 0.649\r(50mg vs 100mg) | -1.53 2.70 -0.57 0.571\r(100mg vs 150mg) | 1.73 2.70 0.64 0.522\r(150mg vs 200mg) | 15.70 2.70 5.81 0.000\r(200mg vs 250mg) | 6.40 2.70 2.37 0.019\r----------------------------------------------------------\rContrasts of each dosage to the previous dosage\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:6:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"6.1 Reverse adjacent contrasts The ar. contrast operator, shown below, provides adjacent group contrasts in reverse order. contrast ar.dosegrp,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------+---------------------------------------\rdosegrp |\r(50mg vs 0mg) | -1.23 2.70 -0.46 0.649\r(100mg vs 50mg) | 1.53 2.70 0.57 0.571\r(150mg vs 100mg) | -1.73 2.70 -0.64 0.522\r(200mg vs 150mg) | -15.70 2.70 -5.81 0.000\r(250mg vs 200mg) | -6.40 2.70 -2.37 0.019\r----------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:6:1","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"6.2 Selecting a specific contrast When making adjacent group contrasts, you can select a specific contrast. contrast a1.dosegrp,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------+---------------------------------------\rdosegrp |\r(0mg vs 50mg) | 1.23 2.70 0.46 0.649\r-------------------------------------------------------\rWe can also select contrasts using the ar. contrast operator. The ar. contrast operator forms contrasts with the previous group, so specifying ar3. (as shown below) contrasts group 3 (100 mg) with the previous group (group 2, 50 mg). contrast ar3.dosegrp,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------+---------------------------------------\rdosegrp |\r(100mg vs 50mg) | 1.53 2.70 0.57 0.571\r---------------------------------------------------------\rWe can combine selected contrasts as well. Suppose we wanted to test the equality of the mean pain ratings for the first four groups. contrast a(1 2 3).dosegrp Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------\r| df F P\u003eF\r------------------+----------------------------------\rdosegrp |\r(0mg vs 50mg) | 1 0.21 0.6489\r(50mg vs 100mg) | 1 0.32 0.5714\r(100mg vs 150mg) | 1 0.41 0.5223\rJoint | 3 0.21 0.8918\r|\rDenominator | 174\r-----------------------------------------------------\r-------------------------------------------------------------------\r| Contrast Std. err. [95% conf. interval]\r------------------+------------------------------------------------\rdosegrp |\r(0mg vs 50mg) | 1.23 2.70 -4.10 6.57\r(50mg vs 100mg) | -1.53 2.70 -6.87 3.80\r(100mg vs 150mg) | 1.73 2.70 -3.60 7.07\r-------------------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:6:2","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"7 Comparing the mean of subsequent or previous levels This section describes contrasts that compare each group mean with the mean of the subsequent groups (also known as Helmert contrasts). use pain2 tab dosage Medication |\rdosage in |\rmg | Freq. Percent Cum.\r------------+-----------------------------------\r300 | 30 16.67 16.67\r400 | 30 16.67 33.33\r500 | 30 16.67 50.00\r600 | 30 16.67 66.67\r800 | 30 16.67 83.33\r1000 | 30 16.67 100.00\r------------+-----------------------------------\rTotal | 180 100.00\rLet’s begin by testing this overall null hypothesis using the anova command below. $$ H_{0} : \\mu_{300} = \\mu_{400} = \\mu_{500} = \\mu_{600}= \\mu_{800}= \\mu_{1000}$$ anova pain i.dosage Number of obs = 180 R-squared = 0.2052\rRoot MSE = 10.5056 Adj R-squared = 0.1824\rSource | Partial SS df MS F Prob\u003eF\r-----------+----------------------------------------------------\rModel | 4958.8667 5 991.77333 8.99 0.0000\r|\rdosage | 4958.8667 5 991.77333 8.99 0.0000\r|\rResidual | 19204.133 174 110.36858 -----------+----------------------------------------------------\rTotal | 24163 179 134.98883 Let’s use the margins and marginsplot commands to show and graph the means by the six levels of dosage. margins dosage marginsplot Adjusted predictions Number of obs = 180\rExpression: Linear prediction, predict()\r------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rdosage |\r300 | 43.83 1.92 22.85 0.000 40.05 47.62\r400 | 37.60 1.92 19.60 0.000 33.81 41.39\r500 | 31.87 1.92 16.61 0.000 28.08 35.65\r600 | 29.63 1.92 15.45 0.000 25.85 33.42\r800 | 30.63 1.92 15.97 0.000 26.85 34.42\r1000 | 29.43 1.92 15.35 0.000 25.65 33.22\r------------------------------------------------------------------------------\rMean pain rating by dosage\r$$H_{0}: \\mu_{300} = \\mu \u003e _{\\text{300}}$$ $$H_{0}: \\mu_{400} = \\mu \u003e _{\\text{400}}$$ $$H_{0}: \\mu_{500} = \\mu \u003e _{\\text{500}}$$ $$H_{0}: \\mu_{600} = \\mu \u003e _{\\text{600}}$$ $$H_{0}: \\mu_{800} = \\mu \u003e _{\\text{1000}}$$ Let’s now test each of the null hypotheses below using the margins command combined with the h. contrast operator. margins h.dosage,contrast(nowald pveffects) Contrasts of adjusted predictions Number of obs = 180\rExpression: Linear prediction, predict()\r--------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r----------------+---------------------------------------\rdosage |\r(300 vs \u003e 300) | 12.00 2.10 5.71 0.000\r(400 vs \u003e 400) | 7.21 2.14 3.36 0.001\r(500 vs \u003e 500) | 1.97 2.21 0.89 0.376\r(600 vs \u003e 600) | -0.40 2.35 -0.17 0.865\r(800 vs 1000) | 1.20 2.71 0.44 0.659\r--------------------------------------------------------\rmarginsplot,yline(0) xlabel(, angle(45)) Mean pain rating by dosage\rWhen the confidence interval for the contrast excludes zero,the difference is significant at the 5% level. ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:7:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"7.1 Comparing the mean of previous levels contrast j.dosage,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r---------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-----------------+---------------------------------------\rdosage |\r(400 vs 300) | -6.23 2.71 -2.30 0.023\r(500 vs \u003c 500) | -8.85 2.35 -3.77 0.000\r(600 vs \u003c 600) | -8.13 2.21 -3.67 0.000\r(800 vs \u003c 800) | -5.10 2.14 -2.38 0.018\r(1000 vs \u003c1000) | -5.28 2.10 -2.51 0.013\r---------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:7:1","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"7.2 Selecting a specific contrast contrast h400.dosage,nowald pveffects we wanted to focus only on the contrast of those whose value of dosage was 400 to those who have higher values of dosage. Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------+---------------------------------------\rdosage |\r(400 vs \u003e400) | 7.21 2.14 3.36 0.001\r-------------------------------------------------------\rAlternatively, we might want to focus only on the contrasts of 400 mg versus the subsequent groups and 500 mg versus the subsequent groups. contrast h(400 500).dosage,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------+---------------------------------------\rdosage |\r(400 vs \u003e400) | 7.21 2.14 3.36 0.001\r(500 vs \u003e500) | 1.97 2.21 0.89 0.376\r-------------------------------------------------------\rselect the contrast of 500mg versus the mean of the previous groups contrast j500.dosage,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r---------------+---------------------------------------\rdosage |\r(500 vs \u003c500) | -8.85 2.35 -3.77 0.000\r-------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:7:2","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"Polynomial contrasts Let’s consider the use of polynomial contrasts for assessing nonlinear trends (for example, quadratic, cubic, or quartic). We can specify q.dosegrp on the contrast command to compute tests of polynomial trend with respect to dosegrp. (The noeffects option is used to save space and focus on the results of the Wald tests.) use pain contrast q.dosegrp,noeffects compute tests of polynomial trend with respect to dosegrp. Margins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rdosegrp |\r(linear) | 1 109.12 0.0000\r(quadratic) | 1 29.25 0.0000\r(cubic) | 1 0.00 0.9824\r(quartic) | 1 8.39 0.0043\r(quintic) | 1 1.62 0.2048\rJoint | 5 29.67 0.0000\r|\rDenominator | 174\r------------------------------------------------\rSuppose you wanted to fit the relationship between a predictor and outcome using a linear term and wanted to assess whether there are significant nonlinear trends in the relationship between the predictor and outcome. You can use the contrast command to test only the nonlinear terms, as shown below. contrast q(2/6).dosegrp,noeffects Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rdosegrp |\r(quadratic) | 1 29.25 0.0000\r(cubic) | 1 0.00 0.9824\r(quartic) | 1 8.39 0.0043\r(quintic) | 1 1.62 0.2048\rJoint | 4 9.81 0.0000\r|\rDenominator | 174\r------------------------------------------------\rThe joint test of all the nonlinear terms (powers 2 through 6) is significant.In such a case, it would be inadvisable to fit the relationship between the predictor and outcome using only a linear fit. The q.contrast operator assumes that the levels of dosegrp are equidistant from each other. In next example the level of dosage are not equidistant and we would have obtained different results by specifying q.dosage compared with specifying p.dosage. contrast p.dosage,noeffects the p.contrast operator to dosage.this tests the polynomial trends based on the actual dosage,accounting for the differing gaps among the levels of dosage. Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rdosage |\r(linear) | 1 28.37 0.0000\r(quadratic) | 1 13.44 0.0003\r(cubic) | 1 2.60 0.1084\r(quartic) | 1 0.47 0.4956\r(quintic) | 1 0.05 0.8202\rJoint | 5 8.99 0.0000\r|\rDenominator | 174\r------------------------------------------------\rspecific on cubic,quartic,and quintic contrast p(3/6).dosage,noeffects ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:8:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"9 Custom contrasts For those times when you want to make another kind of contrast, you can specify a custom contrast. Let’s begin by illustrating how to perform custom contrasts using simple examples that compare one group with another group. For the first example, let’s compare the mean of group 1 (married) with group 5 (not married). The custom contrast is enclosed within curly braces by specifying the variable name followed by the contrast coefficients. The contrast coefficients map to the levels (groups) of the variable. In this example, the contrast coefficient of 1 is applied to group 1, and is applied to group 5. (A contrast coefficient of 0 is applied to groups 2, 3, and 4.) The result is a contrast of group 1 minus group 5. contrast {marital 1 0 0 0 -1} the contrast coef of 1 is applied to group 1,and -1 is applied to group 5(a contrast coefficient of 0 is applied to group 2 3 and 4) Contrasts of marginal linear predictions\rMargins: asbalanced\r------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rmarital | 1 4.18 0.0411\r|\rDenominator | 1147\r------------------------------------------------\r--------------------------------------------------------------\r| Contrast Std. err. [95% conf. interval]\r-------------+------------------------------------------------\rmarital |\r(1) | 0.16 0.08 0.01 0.31\r--------------------------------------------------------------\rLet’s switch the above contrast. Let’s compare group 5 (not married) with group 1 (married), as shown below. contrast {marital -1 0 0 0 1},nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------+---------------------------------------\rmarital |\r(1) | -0.16 0.08 -2.04 0.041\r-----------------------------------------------------\rSay that we want to compare those who are married (group 1) with the average of those who are separated and divorced (groups 3 and 4). We can form that contrast as shown below. contrast{marital 1 0 -.5 -.5 0},nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------+---------------------------------------\rmarital |\r(1) | 0.52 0.10 5.34 0.000\r-----------------------------------------------------\rSuppose we want to compare those who are married (group 1) with the average of those who are widowed, divorced, and separated (groups 2, 3, and 4). contrast{marital 1 -.33333333 -.33333333 -.33333333 0},nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r-----------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------+---------------------------------------\rmarital |\r(1) | 0.50 0.08 6.10 0.000\r-----------------------------------------------------\rNote! Contrasts must sum to zero The contrast coefficients that we specify in a custom contrast must sum to zero. In the previous example, the contrast coefficients for groups 2, 3, and 4 are expressed as -.33333333, using eight digits after the decimal point. Although the sum of the coefficients for that custom contrast is not exactly zero, it is close enough to zero to satisfy the margins command. You can use inline expansions to directly specify the fraction , as shown in the contrast command below. contrast {marital 1 ‘=-1/3’ ‘=-1/3’ ‘=-1/3’ 0}, nowald pveffects Let’s form a contrast of the average of those who are married (group 1) and separated (group 4) to the average of those who are widowed (group 2) and divorced (group 3). Note how the coefficients for groups 1 and 4 are specified as 0.5 and the coefficients for groups 2 and 3 are specified as . contrast{marital .5 -.5 -.5 .5 0},nowald pveffects Margins: asbalanced\r-----------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r-------------+---------------------------------------\rmarital |\r(1) | ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:9:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"10 Weighted contrasts So far, the examples I have shown estimate the mean for groups 2 and 3 combined by obtaining the mean for group 2 and the mean for group 3, and then averaging those means. Stata calls this the as-balanced approach, because it gives equal weights to the groups even if their sample sizes are different. We could, instead, weight the means for groups 2 and 3 proportionate to their sample size. Stata calls this the as-observed approach, because the means are weighted in proportion to their observed sample size. anova happy7 i.marital3 margins h.marital3,contrast(nowald pveffects) Number of obs = 1,160 R-squared = 0.0369\rRoot MSE = .962698 Adj R-squared = 0.0352\rSource | Partial SS df MS F Prob\u003eF\r-----------+----------------------------------------------------\rModel | 41.07881 2 20.539405 22.16 0.0000\r|\rmarital3 | 41.07881 2 20.539405 22.16 0.0000\r|\rResidual | 1072.2927 1,157 .92678716 -----------+----------------------------------------------------\rTotal | 1113.3716 1,159 .96063119 Let’s use the h. contrast operator to compare each group with the mean of the subsequent groups, using the as-balanced approach. Let’s focus our attention on the first contrast, Married vs \u003eMarried, which compares those who are married (group 1) versus those who are previously married and never married (groups 2 and 3). Compare each group with the mean of the subsequent groups,using the as-balanced approach Contrasts of adjusted predictions Number of obs = 1,160\rExpression: Linear prediction, predict()\r-------------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r---------------------------------+---------------------------------------\rmarital3 |\r(Married vs \u003eMarried) | 0.34 0.06 6.07 0.000\r(Prevmarried vs Never married) | -0.20 0.08 -2.50 0.012\r-------------------------------------------------------------------------\rWe can manually compute this estimate: $5.705036 - (5.263323 + 5.459649)/2 = 0.34355$ Let’s compare this estimate with the as-observed approach, which weights the mean of groups 2 and 3 (previously married and never married) by their sample size. The hw. contrast operator is used to obtain the as-observed estimate. margins h.marital3,contrast(nowald pveffects) Contrasts of adjusted predictions Number of obs = 1,160\rExpression: Linear prediction, predict()\r-------------------------------------------------------------------------\r| Delta-method\r| Contrast std. err. t P\u003e|t|\r---------------------------------+---------------------------------------\rmarital3 |\r(Married vs \u003eMarried) | 0.34 0.06 6.07 0.000\r(Prevmarried vs Never married) | -0.20 0.08 -2.50 0.012\r-------------------------------------------------------------------------\rInstead of weighting groups 2 and 3 equally—by (1/2)—groups 2 and 3 are weighted by their individual sample size divided by the combined sample size. The $N$ for group 2 (previously married) is 319, and the $N$ for group 3 (never married) is 285, and the combined for the two groups is 604. We can manually compute this estimate: $5.705036 - (5.263323*(319/604)+ 5.459649*(285/604)) = 0.34907573$ Thus, if you want estimates that are weighted as a function of the proportion of observations in each group, then the as-observed estimates will provide you the kind of estimates that you desire. ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:10:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"11 Pairwise comparisons Sometimes, you want to test all pairwise comparisons that can be formed for a factor variable. The pwcompare command can be used to form such comparisons. use gss_ivrm,clear anova happy7 i.marital i.gender i.race c.age We can use the pwcompare command to form all pairwise comparisons among the marital status groups. Because of the many comparisons, we might want to make adjustments to the values to account for the multiple comparisons. For example, let’s use Šidák’s method for adjusting for multiple comparisons by adding the mcompare(sidak) option. pwcompare marital,pveffects mcompare(sidak) Pairwise comparisons of marginal linear predictions\rMargins: asbalanced\r---------------------------\r| Number of\r| comparisons\r-------------+-------------\rmarital3 | 3\r---------------------------\r----------------------------------------------------------------------\r| Sidak\r| Contrast Std. err. t P\u003e|t|\r------------------------------+---------------------------------------\rmarital3 |\rPrevmarried vs Married | -0.44 0.07 -6.53 0.000\rNever married vs Married | -0.25 0.07 -3.50 0.001\rNever married vs Prevmarried | 0.20 0.08 2.50 0.037\r----------------------------------------------------------------------\rThe bonferroni or scheffe method could have alternatively been specified within the mcompare() option. When you have balanced data, the tukey, snk, duncan, or dunnett method can be specified within mcompare() (see [R] pwcompare for more details) ","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:11:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"12 Interpreting confidence intervals The marginsplot command displays margins and confidence intervals that were computed from the most recent margins command. Sometimes, these confidence intervals might tempt you into falsely believing that they tell us about differences among groups. use gss_ivrm,clear anova happy7 i.marital i.gender i.race c.age The margins command is used to estimate the adjusted means of happiness by marital. The output also includes the 95% confidence interval for each adjusted mean. margins marital marginsplot Predictive margins Number of obs = 1,156\rExpression: Linear prediction, predict()\r--------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r---------------+----------------------------------------------------------------\rmarital |\rmarried | 5.70 0.04 139.63 0.000 5.62 5.78\rwidowed | 5.25 0.12 44.51 0.000 5.01 5.48\rdivorced | 5.20 0.07 75.92 0.000 5.06 5.33\rseparated | 5.15 0.16 31.25 0.000 4.83 5.47\rnever married | 5.54 0.06 87.86 0.000 5.42 5.67\r--------------------------------------------------------------------------------\rAdjusted means of happiness by marital status\rOur eye might be tempted to use the overlap (or lack of overlap) of confidence intervals between groups to draw conclusions about the significance of the differences between groups. However, such conclusions would not be appropriate. For example, although the confidence intervals for those who are separated and never married overlap, the output from the contrast command below shows that the difference in these means is statistically significant ($P = 0.026$) contrast ar.marital,nowald pveffects Contrasts of marginal linear predictions\rMargins: asbalanced\r----------------------------------------------------------------------\r| Contrast Std. err. t P\u003e|t|\r------------------------------+---------------------------------------\rmarital |\r(widowed vs married) | -0.45 0.12 -3.67 0.000\r(divorced vs widowed) | -0.05 0.13 -0.34 0.732\r(separated vs divorced) | -0.05 0.18 -0.28 0.777\r(never married vs separated) | 0.39 0.18 2.24 0.026\r----------------------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:12:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"13 Testing categorical variables using regression The analyses in this chapter have been conducted using the anova command because it produces concise printed output. However, this is not to imply that we cannot perform such tests using the regress command. use gss_ivrm,clear anova happy7 i.marital i.gender i.race c.age reg happy7 i.marital i.gender i.race c.age Source | SS df MS Number of obs = 1,156\r-------------+---------------------------------- F(8, 1147) = 7.35\rModel | 53.9791041 8 6.74738801 Prob \u003e F = 0.0000\rResidual | 1052.29339 1,147 .917431026 R-squared = 0.0488\r-------------+---------------------------------- Adj R-squared = 0.0422\rTotal | 1106.27249 1,155 .957811681 Root MSE = .95783\r--------------------------------------------------------------------------------\rhappy7 | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r---------------+----------------------------------------------------------------\rmarital |\rwidowed | -0.45 0.12 -3.67 0.000 -0.70 -0.21\rdivorced | -0.50 0.08 -6.28 0.000 -0.66 -0.34\rseparated | -0.55 0.17 -3.23 0.001 -0.88 -0.22\rnever married | -0.16 0.08 -2.04 0.041 -0.31 -0.01\r|\rgender |\rFemale | 0.12 0.06 2.06 0.040 0.01 0.23\r|\rrace |\rblack | -0.04 0.09 -0.42 0.676 -0.20 0.13\rother | -0.11 0.12 -0.95 0.341 -0.34 0.12\r|\rage | 0.01 0.00 2.41 0.016 0.00 0.01\r_cons | 5.42 0.11 47.90 0.000 5.19 5.64\r--------------------------------------------------------------------------------\rThe output of the regress command is lengthier because it uses dummy coding for each of the categorical variables and shows the effect for each of the dummy variables. To obtain the test of the overall effect of marital and the test of the overall effect of race, we can use the contrast command, as shown below. contrast marital race Contrasts of marginal linear predictions Margins: asbalanced ------------------------------------------------\r| df F P\u003eF\r-------------+----------------------------------\rmarital | 4 12.85 0.0000\r|\rrace | 2 0.50 0.6043\r|\rDenominator | 1147\r------------------------------------------------\r**The contrast, margins, marginsplot, and pwcompare commands work the same way after the regress command as they do after the anova command.**For example, wecan use the margins command to obtain the adjusted means broken down by marital. contrast r.marital,nowald pveffects Predictive margins Number of obs = 1,156\rModel VCE: OLS\rExpression: Linear prediction, predict()\r--------------------------------------------------------------------------------\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r---------------+----------------------------------------------------------------\rmarital |\rmarried | 5.70 0.04 139.63 0.000 5.62 5.78\rwidowed | 5.25 0.12 44.51 0.000 5.01 5.48\rdivorced | 5.20 0.07 75.92 0.000 5.06 5.33\rseparated | 5.15 0.16 31.25 0.000 4.83 5.47\rnever married | 5.54 0.06 87.86 0.000 5.42 5.67\r--------------------------------------------------------------------------------\r","date":"2024-01-05","objectID":"/7.chapter7categorical-predictors/:13:0","tags":["Categorical","stata"],"title":"Chapter7 ：Categorical predictors","uri":"/7.chapter7categorical-predictors/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter explores models that involve the interaction of three continuous linear predictors.","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter explores models that involve the interaction of three continuous linear predictors. ","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/:0:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Overview Let’s first consider a hypothetical example looking at income (adjusted for inflation) as a function of age, education, and year born. To illustrate the meaning of an interaction of these three continuous predictor, let’s first consider a model that does not include a three-way interaction. $$ \\widehat{realrin}=3365394 + — 55747age + -66053educ + -1712yrborn + 109age * educ + 28age * yrborn + 33.2educ*yrborn$$ The variable age is plotted on the $x$(horizontal) axis, educ is on the $z$axis (representing depth), and the predicted value of realrinc is on the $y$(vertical) axis. Separate graphs are used to represent yrborn.The lines with respect to age are drawn thicker to help accentuate changes in the slope of the relationship between age and the outcome as a function of educ and yrborn. Three-dimensional graph of predicted values from model without the three-way interaction\rlet’s now consider a model that includes a three-way interaction.This regression model predicts realrinc from age, educ, yrborn, the two-way interactions of these predictors (ageeduc, ageyrborn, and educyrborn), and the three-way interaction (ageeduc*yrborn). \\begin{align} \\widehat{realrin} \u0026= -2004225 + 66407age + 313720educ + 1042yrborn +- 8524age\\ \\cdot educ \\notag\\ \\end{align} \\begin{align} +- 34.7age \\cdot yrborn +- 161.62educ \\cdot yrborn + 4.43age \\ \\cdot educ \\cdot yrborn \\notag \\end{align} Three-dimensional graph of predicted values from model with the three-way interaction\rage on the $x$axis, educ on the $z$axis, the predicted value of realrinc on the $y$axis. Separate graphs represent yrborn for the years of birth 1930, 1940, 1950, and 1960 shown from left to right and then top to bottom For those born in 1930 (the top left panel), the age slope is mildly negative for those with 12 years of education and remains mildly negative across the different levels of education. Skipping forward to those born in 1960 (the bottom right panel), the age slope is mildly positive for those with 12 years of education and is sharply positive for those with 20 years of education. Looking across the panels from those born in 1930 (top left) to those born in 1960 (bottom right), we can see how the increase in the age slope due to higher levels of education grows as the year of birthincreases from 1930 to 1960. For those born in 1930, the age slope remains largely the same for all education levels. By contrast, for those born in 1960, the age slope increases considerably with increasing levels of educ. In other words, the size of the ageeduc interaction changes as a function of yrborn. This is a result of, and a way to describe, the interaction of ageeduc*yrborn. Let’s see how these models can be visualized using two-dimensional graphs. Two-dimensional graph of adjusted means for model with the threeway interaction\rIn 1960, the age slope increases considerably with increasing education. We can compare how the age slope changes as a function of education for those born in 1930 with those born in 1960. For those born in 1930, the age slope remains mildly negative for all levels of education. By contrast, for those born in 1960, the age slope grows increasingly positive with increasing levels of education. As we saw in the three-dimensional graph, this two-dimensional graph illustrates how the age×educ interaction changes as a function of yrborn, which is another way of saying that there is an age × educ × yrborn interaction. ","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/:1:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Example using GSS data Let’s now illustrate a model with an interaction of three continuous variables using the GSS dataset. This example predicts realrinc from age, educ, and yrborn. use gss_ivrm.dta keep if (age\u003e=30 \u0026 age\u003c=55) \u0026 (educ\u003e=12) \u0026 (yrborn\u003e=1930 \u0026 yrborn\u003c=1960) ","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/:2:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1.1 A model without a three-way interaction Linear regression Number of obs = 11,765\rF(8, 11756) = 138.87\rProb \u003e F = 0.0000\rR-squared = 0.1142\rRoot MSE = 24595\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\rage | -48960.89 8316.82 -5.89 0.000\reduc | -61659.03 34481.49 -1.79 0.074\ryrborn | -1529.75 290.82 -5.26 0.000\r|\rc.age#c.educ | 109.44 18.74 5.84 0.000\r|\rc.age#c.yrborn | 24.53 4.28 5.73 0.000\r|\rc.educ#c.yrborn | 30.92 17.50 1.77 0.077\r|\rrace |\rblack | -5274.18 464.22 -11.36 0.000\rother | -4616.74 1145.59 -4.03 0.000\r|\r_cons | 3.01e+06 570438.47 5.28 0.000\rWe can visualize these results using the margins and the marginsplot commands. The margins command is used to obtain the fitted value for ages 30 and 55, for educations of 12 to 20 years (in two-year increments), and for the years of birth 1930, 1940, 1950, and 1960. The marginsplot command is then used to graph these values, placing age on the $x$axis, using separate panels for yrborn, and using separate lines for educ margins, at(age=(30 55) educ=(12(2)20) yrborn=(1930(10)1960)) marginsplot,xdimension(age) bydimension(yrborn) /// plotdimension(educ,allsimple) legend(row(2)subtitle(Education)) /// recast(line) scheme(s1mono) noci ylabel(,angle(0)) Adjusted means from model without the three-way interaction, showing age on the $x$ axis, separate panels for year of birth, and separate lines for education\rAlthough the people born in different years might show a different age slope at 12 years of education, the increase in the age slope as a function of education is the same across the years of birth. In fact, the coefficient for c.age#c.educ describes the exact degree of this increase. For every unit increase in educ, the age slope increases by 109.44. This is true for all years of birth. Let’s see this for ourselves using the margins command. The margins command below estimates the age slope for those with 14 and 15 years of education who were born in 1930. result compute: -88.59 + 109.44 = 20.85 margins,dydx(age) at(educ=(14 15) yrborn=1930) vsquish Average marginal effects Number of obs = 11,765\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: educ = 14\ryrborn = 1930\r2._at: educ = 15\ryrborn = 1930\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\rage |\r_at |\r1 | -88.59 81.21 -1.09 0.275 -247.78 70.59\r2 | 20.85 86.72 0.24 0.810 -149.14 190.84\r------------------------------------------------------------------------------\rLet’s make the same comparison, except for those born in 1940. margins,dydx(age)at(educ=(14 15) yrborn=1940) vsquish result compute: 266.1371 - 156.6922 = 109.44 Average marginal effects Number of obs = 11,765\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: educ = 14\ryrborn = 1940\r2._at: educ = 15\ryrborn = 1940\r------------------------------------------------------------------------------\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\r-------------+----------------------------------------------------------------\rage |\r_at |\r1 | 156.69 46.04 3.40 0.001 66.45 246.93\r2 | 266.14 53.97 4.93 0.000 160.35 371.92\r------------------------------------------------------------------------------\r","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/:2:1","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1.2 A three-way interaction model Let’s now consider a model that includes a three-way interaction of age, educ, and yrborn when predicting realrinc. Such models can have a high degree of multicollinearity that can lead to numerical instability of the estimates and inflated standard errors. To avoid these problems, Aiken and West (1991) recommend centering the predictors prior to the analysis. Let’s adopt this advice and center age, educ, and yrborn before attempting an analysis that includes the interaction of these three variables. The following generate commands create centered versions of these variables, centering them around values that I chose to ease the interpretation of the centered values. generate yrborn30 = yrborn - 1930 generate age40 = age - 40 generate educ16 = educ - 16 The variable yrborn is centered by subtracting 1930, creating a new variable called yrborn30. This centered variable will range from 0 to 30, corresponding to the years of birth ranging from 1930 to 1960. The centered version of age is called age40 and contains the value of age minus 40. An age of 30 would be represented as using the centered version of age (age40). Finally, the centered version of educ is called educ16, which contains educ minus 16. We could refer to 20 years of education via the centered variable by specifying that educ16 equals 4. The rest of this section will use these centered variables for the analysis. Let’s now form a model that predicts realrinc from age40, educ16, and yrborn30, the two-way interactions among these variables, and the three-way interaction of these variables. reg realrinc c.age40##c.educ16##c.yrborn30 i.race,vce(robust) noci Linear regression Number of obs = 11,765\rF(9, 11755) = 126.24\rProb \u003e F = 0.0000\rR-squared = 0.1145\rRoot MSE = 24591\r--------------------------------------------------------------------\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\r----------------------------+---------------------------------------\rage40 | -27.89 135.31 -0.21 0.837\reduc16 | 2800.94 366.46 7.64 0.000\r|\rc.age40#c.educ16 | 26.63 42.54 0.63 0.531\r|\ryrborn30 | -88.92 55.93 -1.59 0.112\r|\rc.age40#c.yrborn30 | 32.56 6.69 4.87 0.000\r|\rc.educ16#c.yrborn30 | 12.89 17.90 0.72 0.471\r|\rc.age40#c.educ16#c.yrborn30 | 4.32 2.19 1.97 0.049\r|\rrace |\rblack | -5279.07 463.47 -11.39 0.000\rother | -4648.00 1142.81 -4.07 0.000\r|\r_cons | 33441.15 1161.80 28.78 0.000\r--------------------------------------------------------------------\rWe can visualize the c.age40#c.educ16#c.yrborn30 interaction in a variety of ways. We can focus on the age40 slope, the educ16 slope, or the yrborn30 slope. As we have done throughout this chapter, let’s focus our attention on the age slope (via the centered variable age40). Note! Retaining main effects and two-way interactions Looking at the estimates from the regress command, you might notice that some of the main effects and two-way interaction terms are not significant. Even though they are not significant, it is important to retain these effects to preserve the interpretation of the three-way interaction term. 1.1.2.1 Visualizing the three-way interaction The margins command is used to compute the adjusted means at different values of the centered variable using the at() option. In terms of the uncentered variables, the at() option specifies ages 30 and 55, educations from 12 to 20 in 2-unit increments, and years of birth from 1930 to 1960 in 10-unit increments. Then, the marginsplot command is used to graph the fitted values, placing age40 on the $x$ axis, with separate lines for educ16 and with separate panels for yrborn30. margins, at(age40=(-10 15) educ16=(-4(2)4) yrborn30=(0(10)30)) marginsplot,xdimension(age40) bydimension(yrborn30) /// plotdimension(educ16,allsimple) legend(row(2) subtitle(Education)) /// recast(line) scheme(s1mono) noci ylabel(, angle(0)) Adjusted means from model with the three-way interaction as a function of age ( $x$ axis), year of birth (separate panels), and education (","date":"2024-01-04","objectID":"/6.continuous-by-continuous-by-continuous-interactions/:2:2","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter6 ：Continuous by continuous by continuous interactions","uri":"/6.continuous-by-continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates how to interpret interactions of two continuous predictors. ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates how to interpret interactions of two continuous predictors. ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:0:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Linear by linear interactions A linear by linear interaction implies that the slope of the relationship between one of the predictors and the outcome changes as a linear function of the other predictor. Let’s begin with a hypothetical example in which we predict income (realrinc) from age (age) and education (educ) without an interaction. $$ \\widehat{realrin}=-41300 + 600age + 3000educ $$ Three-dimensional graph of fitted values from model without aninteraction\rLet’s now consider a second hypothetical regression model that contains an interaction of age (age) and education (educ). $$ \\widehat{realrin}=2400 + -1100age - 1600educ + 120age*educ $$ Three-dimensional graph of fitted values from model with an interaction\rLet’s transition to the use of two-dimensional graphs for illustrating the precise role of linear by linear interactions. Two-dimensional graph of fitted values from model without an interaction (left panel) and with an interaction (right panel)\rThe left panel shows a two-dimensional representation of the model without an interaction, and the right panel shows a two-dimensional representation of the model with an interaction. ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Example using GSS data use gss_ivrm.dta keep if (age\u003e=22 \u0026 age \u003c=55) \u0026 (educ\u003e=12) Let’s fit a model where we predict realrinc from educ, age, and the interaction of these two variables. reg realrinc c.educ##c.age female, vce(robust) Linear regression Number of obs = 22,367\rF(4, 22362) = 664.04\rProb \u003e F = 0.0000\rR-squared = 0.1712\rRoot MSE = 24677\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\reduc | -1487.58 339.60 -4.38 0.000 -2153.21 -821.94\rage | -1036.79 126.23 -8.21 0.000 -1284.21 -789.38\r|\rc.educ#c.age | 114.91 9.38 12.25 0.000 96.52 133.30\r|\rfemale | -12553.79 328.28 -38.24 0.000 -13197.25 -11910.33\r_cons | 28738.43 4550.48 6.32 0.000 19819.18 37657.69\r","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:1","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Interpreting the interaction in terms of age We can use the margins and marginsplot commands to visualize this interaction. Let’s visualize this interaction by graphing the adjusted means with age on the X axis and with separate lines for each level of educ. The margins command is used with the at() option to compute the adjusted means for ages 22 and 55 and educations ranging from 12 to 20 in two-year increments. margins, at(age=(22 55) educ=(12(2)20)) Then, the marginsplot command is used to graph the adjusted means with age on the axis and with separate lines for each level of educ.The legend() option is included to customize the display of the graph legend. marginsplot,noci legend(rows(3) title(Education)) Adjusted means for a linear by linear interaction with age on the X axis\rwe can use the margins command combined with the dydx(age) option to estimate the slope for each of the lines displayed in figure margins, at(educ=(12(2)20)) dydx(age) vsquish Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: educ = 12\r2._at: educ = 14\r3._at: educ = 16\r4._at: educ = 18\r5._at: educ = 20\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\rage |\r_at |\r1 | 342.16 19.78 17.30 0.000 303.39 380.93\r2 | 571.99 16.30 35.09 0.000 540.03 603.94\r3 | 801.81 29.06 27.59 0.000 744.85 858.77\r4 | 1031.64 46.12 22.37 0.000 941.23 1122.04\r5 | 1261.46 64.14 19.67 0.000 1135.73 1387.19\rThe estimates of the age slope increase as a function of educ. For example, at 12 years of education, the age slope is 342.16, and at 14 years of education, the age slope is 571.99. For a two-unit increase in education, the age slope increases by 229.83 ($571.99-342.16$). We can relate this to the coefficient for the c.educ#c.age interaction, which is the amount by which the age slope changes for every one-year increase in educ. For every one-year increase in educ, the age slope increases by 114.91($229.83÷2=114.91$). ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:2","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.3 Interpreting the interaction in terms of education Now, let’s explore the meaning of the interaction by focusing on the educ slope. Let’s visualize this by creating a graph of the adjusted means showing educ on the $x$ axis and separate lines for age. First, the margins command is used to create adjusted means for 12 and 20 years of education and ages ranging from 25 to 55 in 10-year increments. margins, at(educ=(12(2)20)) dydx(age) vsquish Predictive margins Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: educ = 12\rage = 25\r2._at: educ = 12\rage = 35\r3._at: educ = 12\rage = 45\r4._at: educ = 12\rage = 55\r5._at: educ = 20\rage = 25\r6._at: educ = 20\rage = 35\r7._at: educ = 20\rage = 45\r8._at: educ = 20\rage = 55\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 13091.92 236.14 55.44 0.000 12629.07 13554.76\r2 | 16513.52 172.78 95.57 0.000 16174.85 16852.19\r3 | 19935.12 286.72 69.53 0.000 19373.12 20497.11\r4 | 23356.72 461.33 50.63 0.000 22452.47 24260.96\r5 | 24173.82 876.85 27.57 0.000 22455.13 25892.50\r6 | 36788.43 619.20 59.41 0.000 35574.75 38002.11\r7 | 49403.04 906.00 54.53 0.000 47627.21 51178.86\r8 | 62017.65 1442.62 42.99 0.000 59190.01 64845.28\rmarginsplot,noci legend(title(Age)) Adjusted means for a linear by linear interaction with education on the axis\rwe can estimate the slope of each line (that is, the educ slope) using the margins command, as shown below. margins,at(age=(25(10)55)) dydx(educ)vsquish Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: educ\r1._at: age = 25\r2._at: age = 35\r3._at: age = 45\r4._at: age = 55\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\reduc |\r_at |\r1 | 1385.24 129.78 10.67 0.000 1130.87 1639.61\r2 | 2534.36 90.87 27.89 0.000 2356.24 2712.48\r3 | 3683.49 131.45 28.02 0.000 3425.83 3941.15\r4 | 4832.62 209.54 23.06 0.000 4421.90 5243.33\rAs age increases, so does the educ slope. For every one-unitincrease in age, the educ slope increases by 114.91, the estimate of the age#educ interaction. For a 10-unit increase in age, the educ slope would be expected to increase by 1,149.12. ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:3","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.4 Interpreting the interaction in terms of age slope We can visualize the age by educ interaction by illustrating the way that the age slope changes as a function of education. The margins command below includes the dydx(age) option to estimate the age slope at each level of educ. margins,dydx(age) at(educ=(12(1)20))vsquish Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: educ = 12\r2._at: educ = 13\r3._at: educ = 14\r4._at: educ = 15\r5._at: educ = 16\r6._at: educ = 17\r7._at: educ = 18\r8._at: educ = 19\r9._at: educ = 20\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\rage |\r_at |\r1 | 342.16 19.78 17.30 0.000 303.39 380.93\r2 | 457.07 15.51 29.47 0.000 426.68 487.47\r3 | 571.99 16.30 35.09 0.000 540.03 603.94\r4 | 686.90 21.61 31.78 0.000 644.54 729.26\r5 | 801.81 29.06 27.59 0.000 744.85 858.77\r6 | 916.72 37.39 24.52 0.000 843.44 990.01\r7 | 1031.64 46.12 22.37 0.000 941.23 1122.04\r8 | 1146.55 55.07 20.82 0.000 1038.61 1254.49\r9 | 1261.46 64.14 19.67 0.000 1135.73 1387.19\rThis shows that the age slope increases as a function of education. In fact, the age slope increases by 114.91 units for every one-unit increase in educ. We can visualize these age slopes as a function of education using the marginsplot command (shown below). marginsplot ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:4","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.5 Interpreting the interaction in terms of the educ slope We can visualize the age by educ interaction by focusing on the way that the educ slope changes as a function of age. The margins command below estimates the educ slope for ages ranging from 25 to 55 in five-year increments. margins,dydx(educ)at(age=(25(5)55))vsquish Average marginal effects Number of obs = 22,367\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: educ\r1._at: age = 25\r2._at: age = 30\r3._at: age = 35\r4._at: age = 40\r5._at: age = 45\r6._at: age = 50\r7._at: age = 55\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\reduc |\r_at |\r1 | 1385.24 129.78 10.67 0.000 1130.87 1639.61\r2 | 1959.80 101.73 19.26 0.000 1760.40 2159.20\r3 | 2534.36 90.87 27.89 0.000 2356.24 2712.48\r4 | 3108.93 102.80 30.24 0.000 2907.43 3310.43\r5 | 3683.49 131.45 28.02 0.000 3425.83 3941.15\r6 | 4258.05 168.50 25.27 0.000 3927.78 4588.33\r7 | 4832.62 209.54 23.06 0.000 4421.90 5243.33\rThis shows that the educ slope increases as a function of age. For each five-year increase in age, the educ slope increases by 574.56 (that is, the age#educ coefficient multiplied by five, $114.91 × 5$). marginsplot,noci ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:1:5","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Linear by quadratic interactions This section considers models with an interaction of two continuous variables, where one of the variables is fit linearly and the other is fit using a quadratic term. A quadratic term introduces curvature in the fitted relationship between the predictor and outcome. Let’s first illustrate a model that contains a quadratic predictor and a linear predictor but no interaction between these predictors. This hypothetical example uses realrinc as the outcome variable, age as the quadratic predictor, and educ as the linear predictor. $$ \\widehat{realrin}=-7000 + 2100age + - age^2 + 3000educ $$ Three-dimensional graph of fitted values for linear and quadratic models without an interaction\rLet’s now consider a model that includes an interaction between age (as a quadratic term) and educ. This regression equation is shown below $$ \\widehat{realrin}=165000 + -8600age + 95age^2 +-14000educ + 780age*educ + - 8age^2 * educ $$ The key term is the age squared by education interaction. This governs the degree of the curvature in age as a function of education. Three-dimensional graph of fitted values for linear and quadratic models with an interaction\rAs education increases from 12 to 20years, the degree of the inverted U-shape grows as a function of education. This is due to the interaction of education with age squared. When quadratic terms become more negative, the inverted U-shape becomes more pronounced. Thus for every one-unit increase in education, the relationship between income and age shows more of an inverted U-shape. We can clearly see how the degree of the curvature in relationship between income and age is the same across the levels of education. The right panel of figure shows a two-dimensional representation of figure above, where there was an interaction of education with the quadratic term for age. Two-dimensional graph of fitted values for linear and quadratic models without an interaction (left panel) and with linear by quadratic interaction (right panel)\r","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:2:0","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Example using GSS data Let’s use the GSS dataset to fit a model that predicts realrinc from educ (treated as a continuous linear variable) interacted with age (treated as a continuous variable fit using a quadratic term). use gss_ivrm.dta keep if (age\u003e=22 \u0026 age\u003c=80) \u0026 (educ\u003e=12) reg realrinc c.educ c.age##c.age female,vce(robust) Let’s begin by fitting a model that predicts realrinc using educ as a linear term and age as a quadratic term but no interaction between education and age. Linear regression Number of obs = 25,964\rF(4, 25959) = 785.49\rProb \u003e F = 0.0000\rR-squared = 0.1658\rRoot MSE = 26078\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\reduc | 3071.27 93.46 32.86 0.000 2888.08 3254.45\rage | 2245.62 79.05 28.41 0.000 2090.67 2400.57\r|\rc.age#c.age | -21.77 0.94 -23.09 0.000 -23.62 -19.92\r|\rfemale | -13344.78 319.66 -41.75 0.000 -13971.33 -12718.23\r_cons | -64839.08 2060.09 -31.47 0.000 -68876.96 -60801.20\rThe quadratic term is significant and is negative. This negative coefficient indicates that the relationship between age and income has an inverted U-shape. Let’s use the margins and marginsplot commands to visualize the adjusted means of income as a function of age while holding education constant at 12 to 20 years of education (in two-year increments). We first compute the adjusted means as a function of age and education using the margins command. Then, the marginsplot command graphs the adjusted means on the $y$ axis and age on the $x$ axis, with separate lines for each level of education. margins,at(age=(22(1)80) educ=(12(2)20)) marginsplot,noci legend(rows(2))recast(line) scheme(s1mono) Adjusted means at 12, 14, 16, 18, and 20 years of education\rLet’s now fit a model that includes an interaction of educ with the quadratic term for age. reg realrinc c.educ##c.age##c.age female,vce(robust) noci Linear regression Number of obs = 25,964\rF(6, 25957) = 558.27\rProb \u003e F = 0.0000\rR-squared = 0.1757\rRoot MSE = 25924\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t|\reduc | -9317.78 817.82 -11.39 0.000\rage | -5009.26 551.97 -9.08 0.000\r|\rc.educ#c.age | 517.95 41.56 12.46 0.000\r|\rc.age#c.age | 46.88 6.39 7.34 0.000\r|\rc.educ#c.age#c.age | -4.91 0.48 -10.18 0.000\r|\rfemale | -13160.33 317.92 -41.40 0.000\r_cons | 108559.85 10897.04 9.96 0.000\rLet’s interpret this as a function of age by graphing the adjusted means on the axis and age on the axis, with separate lines to indicate the levels of education. margins,at(age=(22 25(5)80) educ=(12(2)20)) marginsplot,plotdimension(,allsimple)legend(subtitle(Education)rows(2))noci recast(line) scheme(s1mono) Adjusted means from linear by quadratic model\rthe c.educ#c.age#c.age coefficient describes the degree to which the inverted U-shape changes as a function of education. This coefficient, which is $-4.9$, represents the change in the quadratic term for age for a one-unit increase in educ. As education increases by one unit, the quadratic term for age decreases by 4.9, creating a more inverted U-shape. For those with lower educations, the relationship between age and income tends to be more linear, and for those with higher levels of education, the relationship between age and income is more curved, showing a greater rise and fall across ages. ","date":"2024-01-01","objectID":"/5.continuous-by-continuous-interactions/:2:1","tags":["Continuous predictors","Interaction","stata"],"title":"Chapter5 ：Continuous by continuous interactions","uri":"/5.continuous-by-continuous-interactions/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.  ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:0:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Introduction to piecewise regression models A piecewise regression goes by several names, including spline regression,broken line regression, broken stick regression, and even hockey stick models. Consider the example, predicting annual income from education, shown in the figure below A knot can signify a change of slope and a change of intercept, yielding an increase (or decrease) in the outcome upon attaining a particular milestone. Note! Instantaneous jumps? As a thought experiment, imagine someone being one day short of graduating high school and the wages they would obtain as they seek a job. Compare this person with an identical job seeker who has one more day of education (that is, they graduated high school). These two people are identical except that one crossed the threshold of getting a diploma. It is indeed plausible that the second person would be offered an annual income $2,200 more than the first person$. Suppose you have a predictor that shows a nonlinear relationship with the outcome, and you believe that a piecewise model with one knot signifying a change in slope would fit your data well. However, unlike the previous examples, you do not have a theoretical or practical basis for selecting the placement of the knot. You could haphazardly try a variety of placements for the knot, trying to find a placement that results in the best fitting model. Alternatively, you can let Stata do the work for you by using a least-squares procedure for selecting a location for the knot that produces the lowest residual sum of squares. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:1:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Piecewise with one known knot This section illustrates piecewise regression with one knot. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:2:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Examples using the GSS Let’s use the GSS dataset to illustrate a piecewise model with one knot, focusing on the relationship between income and education. use gss_ivrm.dta reg realrinc i.educ,vce(robust) margins educ marginsplot,noci It looks like the relationship between education and income could be fit well with a piecewise model with a knot at 12 (corresponding to graduating high school). The following subsections illustrate two different ways to fit this kind of piecewise model: using individual slope coding and using change in slope coding. 2.1.1 Individual slope coding The individual slope coding scheme estimates the slope of each line segment of the piecewise model. The first step is to create two new variables that are coded to represent the educ slope before and after graduating high school. The mkspline command creates the variables ed1 and ed2 based on the original variable educ. The value of 12 is inserted between ed1 and ed2, indicating that this is the knot. mkspline ed1 12 ed2 = educ showcoding educ ed1 ed2 The next step is to use the regress command to predict realrinc from ed1 and ed2. This will yield a piecewise model with 12 years of education as the knot. reg realrinc ed1 ed2 female,vce(robust) Linear regression Number of obs = 32,183\rF(3, 32179) = 1030.24\rProb \u003e F = 0.0000\rR-squared = 0.1420\rRoot MSE = 25045\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\red1 | 832.27 72.38 11.50 0.000 690.40 974.14\red2 | 3441.33 93.42 36.84 0.000 3258.21 3624.44\rfemale | -12372.38 276.35 -44.77 0.000 -12914.05 -11830.72\r_cons | 12052.18 793.42 15.19 0.000 10497.04 13607.31\rAmong non–high school graduates(ed1), each additional year of education is predicted to increase income by $832.27$.The coefficient for ed2 is the slope for those with 12 or more years of education (high school graduates). Income increases by $3,441.33$ for each additional year of education beyond 12 years of education(ed2). Each of these slopes is significantly different from 0. Say that we want to compute the adjusted mean given that a person has eight years of education. We can compute this adjusted mean using the margins command; To graph the adjusted means as a function of education, we need to compute the adjusted means when education is 0, 12, and 20. The margins command below computes these three adjusted means by using the at() option three times. margins,at(ed1=0 ed2=0) at(ed1=12 ed2=0) at(ed1=12 ed2=8) vsquish Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: ed1 = 0\red2 = 0\r2._at: ed1 = 12\red2 = 0\r3._at: ed1 = 12\red2 = 8\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 5964.98 794.24 7.51 0.000 4408.23 7521.72\r2 | 15952.22 161.46 98.80 0.000 15635.75 16268.69\r3 | 43482.83 657.66 66.12 0.000 42193.79 44771.86\rpreserve clear input educ yhat 0 5964.977 12 15952.22 20 43482.83 end graph twoway line yhat educ,xlabel(0(4)20) xline(12) restore 2.1.2 Change in slope coding This coding scheme estimates the slope for the line segment before the first knot (for example, for non–high school graduates) and then estimates the difference in the slopes of adjacent line segments (for example, for high school graduates versus non–high school graduates). This strategy emphasizes the change in slope that occurs at each knot. The key difference is that we add the marginal option to the mkspline command, as shown below. I name the variables ed1m and ed2m, adding the m to emphasize that these variables were created using the marginal option. mkspline ed1m 12 ed2m = educ,marginal The next step is to enter ed1m and ed2m as predictors of income, as shown below. reg realrinc ed1m ed2m female,vce(robust) Linear regression Number of obs = 32,183\rF(3, 32179) = 1030.24\rProb \u003e F = 0.0000\rR-squared = 0.1420\rRoot MSE = 25045\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\red1m | 832.27 72.38 11.50 0.000 690.40 974.14\red2m | 2609.06 134.40 19.41","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:2:1","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Piecewise with two known knots ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:3:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Examples using the GSS use gss_ivrm.dta mkspline ed1m 12 ed2m 16 ed3m = educ,marginal showcoding educ ed1m ed2m ed3m The coefficient for ed2m will represent the change in slope for high school graduates versus non–high school graduates. The coefficient for ed3m will represent the change in slope comparing college graduates with high school graduates. reg realrinc ed1m ed2m ed3m female,vce(robust) Linear regression Number of obs = 32,183\rF(4, 32178) = 784.42\rProb \u003e F = 0.0000\rR-squared = 0.1432\rRoot MSE = 25029\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\red1m | 939.67 70.55 13.32 0.000 801.40 1077.95\red2m | 2022.42 144.24 14.02 0.000 1739.71 2305.13\red3m | 1657.45 412.15 4.02 0.000 849.62 2465.28\rfemale | -12336.74 277.09 -44.52 0.000 -12879.84 -11793.64\r_cons | 11215.32 787.53 14.24 0.000 9671.73 12758.92\rWe can use the margins command to compute adjusted means for any given value of education by expressing education in terms of the variables ed1m, ed2m, and ed3m. To graph the entire range of education values, we need to compute the adjusted means for the minimum of education (0), for each of the knots (12 and 16), and for the maximum of education (20). The margins command below computes these adjusted means using the at() option once for each of these four levels of education. margins,at(ed1m=0 ed2m=0 ed3m=0) /// at(ed1m=12 ed2m=0 ed3m=0) /// at(ed1m=16 ed2m=4 ed3m=0) /// at(ed1m=20 ed2m=8 ed3m=4) vsquish Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: ed1m = 0\red2m = 0\red3m = 0\r2._at: ed1m = 12\red2m = 0\red3m = 0\r3._at: ed1m = 16\red2m = 4\red3m = 0\r4._at: ed1m = 20\red2m = 8\red3m = 4\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 5145.66 785.16 6.55 0.000 3606.72 6684.60\r2 | 16421.73 145.60 112.79 0.000 16136.36 16707.11\r3 | 28270.11 383.13 73.79 0.000 27519.16 29021.06\r4 | 46748.30 1242.79 37.62 0.000 44312.38 49184.22\rWe can then manually input the adjusted means from the margins command into a dataset as shown below. The graph command is then used to graph the relationship between education and income. preserve clear input educ yhat 0 5154.66 12 16421.73 16 28270.11 20 46748.3 end graph twoway line yhat educ,xlabel(0(4)20) xline(12 16) xtitle(Education) ytitle(Adjusted mean) restore ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:3:1","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Piecewise with one knot and one jump ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:4:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.1 Examples using the GSS use gss_ivrm.dta mkspline ed1m 12 ed2m = educ,marginal reg realrinc ed1m ed2m hsgrad female,vce(robust) The variable hsgrad is coded 1 if someone has 12 or more years of education, and 0 otherwise. Linear regression Number of obs = 32,183\rF(4, 32178) = 803.67\rProb \u003e F = 0.0000\rR-squared = 0.1425\rRoot MSE = 25039\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\red1m | 273.10 105.88 2.58 0.010 65.56 480.64\red2m | 3102.95 141.83 21.88 0.000 2824.97 3380.94\rhsgrad | 2721.54 412.82 6.59 0.000 1912.40 3530.67\rfemale | -12391.31 276.30 -44.85 0.000 -12932.87 -11849.74\r_cons | 16345.24 988.38 16.54 0.000 14407.98 18282.49\rAt 12 years of education, the adjusted mean is computed twice, once assuming the absence of a high school degree and once assuming a high school degree, illustrating the jump in income due to graduating high school. How tow interpret the regression coefficient? For each additional year of education (up to 12), income increases by $273.10.$figure shows the adjusted means given zero and one year of education. This difference in these adjusted means equals 273.10 $(10521.83-10248.73)$ The coefficient of ed2m is 3,102.95, which is the change (increase) in slope for high school graduates compared with non–high school graduates. Finally, the hsgrad coefficient (2,721.54) represents the predicted jump (increase in income) due to graduating high school. showcoding educ hsgrad ed1m ed2m margins,at(ed1m=0 ed2m=0 hsgrad=0) /// at(ed1m=12 ed2m=0 hsgrad=0) /// at(ed1m=12 ed2m=0 hsgrad=1) /// at(ed1m=20 ed2m=8 hsgrad=1) vsquish Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r1._at: ed1m = 0\red2m = 0\rhsgrad = 0\r2._at: ed1m = 12\red2m = 0\rhsgrad = 0\r3._at: ed1m = 12\red2m = 0\rhsgrad = 1\r4._at: ed1m = 20\red2m = 8\rhsgrad = 1\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r1 | 10248.73 987.42 10.38 0.000 8313.35 12184.10\r2 | 13525.93 374.97 36.07 0.000 12790.97 14260.89\r3 | 16247.46 174.79 92.95 0.000 15904.86 16590.07\r4 | 43255.90 664.00 65.14 0.000 41954.43 44557.37\rpreserve clear input educ yhat 0 10248.73 12 13525.93 12 16247.46 20 43255.9 end graph twoway line yhat educ,xlabel(0(4)20) xline(12) restore Note! Individual slope coding This model was fit using the change in slope coding method (that is, with the marginal option on the mkspline command). If you wished, you could fit this model using individual slope coding by omitting the marginal option on the mkspline command. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:4:1","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5 Piecewise with two knots and two jumps This section will illustrate a model with two knots signifying a change of slope and intercept. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:5:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"5.1 Examples using the GSS use gss_ivrm.dta mkspline ed1m 12 ed2m 16 ed3m = educ,marginal reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust) Linear regression Number of obs = 32,183\rF(6, 32176) = 544.02\rProb \u003e F = 0.0000\rR-squared = 0.1458\rRoot MSE = 24991\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\red1m | 272.27 105.87 2.57 0.010 64.76 479.79\red2m | 1329.81 189.31 7.02 0.000 958.75 1700.88\red3m | 2540.17 398.71 6.37 0.000 1758.69 3321.65\rhsgrad | 3925.58 405.81 9.67 0.000 3130.18 4720.98\rcograd | 5740.76 733.17 7.83 0.000 4303.73 7177.80\rfemale | -12358.72 276.69 -44.67 0.000 -12901.04 -11816.40\r_cons | 16339.10 988.28 16.53 0.000 14402.04 18276.16\rshowcoding educ ed1m ed2m ed3m hsgrad cograd margins,at (ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) /// at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1) vsquish noatlegend Predictive margins Number of obs = 32,183\rModel VCE: Robust\rExpression: Linear prediction, predict()\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 10258.62 987.32 10.39 0.000 8323.44 12193.81\r2 | 13525.88 374.93 36.08 0.000 12791.01 14260.75\r3 | 17451.46 157.37 110.90 0.000 17143.02 17759.91\r4 | 23859.81 558.53 42.72 0.000 22765.07 24954.55\r5 | 29600.57 475.61 62.24 0.000 28668.35 30532.79\r6 | 46169.58 1255.73 36.77 0.000 43708.30 48630.87\rpreserve clear input educ yhat 0 10258.62 12 13525.88 12 17451.46 16 23858.81 16 29600.57 20 46169.58 end graph twoway line yhat educ,xlabel(0(4)20) xline(12 16) xtitle(Education) ytitle(Adjusted means) restore ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:5:1","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"6 Piecewise with an unknown knot This section illustrates a method for fitting a piecewise model with one knot where the location of the knot is uncertain. Consider the relationship between year of birth and level of education. In this dataset, the year of birth is recorded in the variable yrborn and education level is recorded in the variable educ. To visualize the relationship between year of birth and education, let’s make a graph showing the mean of educ at each level of yrborn. use gss_ivrm.dta keep if (yrborn\u003e=1905 \u0026 yrborn\u003c=1985) \u0026 !missing(educ) reg educ i.yrborn margins yrborn marginsplot,noci We could haphazardly select different years for the placement of the knot and select the knot that yields the best fitting model. Rather than manually doing this selection process, we can use the nl command to automate the process of selecting the optimal knot, by selecting a knot location that yields the lowest residual sum of squares. The code for fitting such a model is shown below. nl (educ = ({cons} + {b1}*yrborn)*(yrborn\u003c{knot}) + /// ({cons} + {b1}*{knot} + {b2}*(yrborn-{knot}))*(yrborn\u003e={knot})), /// initial(knot 1945 b1 .1 b2 -.0125 cons -181) Iteration 0: Residual SS = 464140\rIteration 1: Residual SS = 464092.3\rIteration 2: Residual SS = 464092.3\rSource | SS df MS\rNumber of obs = 52,873\rModel | 48574.186 3 16191.3952 R-squared = 0.0947\rResidual | 464092.28 52869 8.77815515 Adj R-squared = 0.0947\rRoot MSE = 2.962795\rTotal | 512666.47 52872 9.69636992 Res. dev. = 264897.3\reduc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\r/cons | -152.07 3.24 -46.88 0.000 -158.43 -145.71\r/b1 | 0.09 0.00 50.59 0.000 0.08 0.09\r/knot | 1946.97 0.51 3800.38 0.000 1945.96 1947.97\r/b2 | -0.01 0.00 -2.98 0.003 -0.01 -0.00\rNote: Parameter cons is used as a constant term during estimation. The coefficient labeled cons is the constant for the model (the predicted value of educ when yrborn is 0). This value is generally uninteresting. The coefficient labeled knot is the location of the knot, selected as 1946.97 (which we can round to 1947). The coefficient labeled b1 is the slope of the relationship between education and year of birth for those born before the knot (before 1947). The coefficient labeled b2 is the slope for those born in or after 1947. The key is that 1947 was selected as the optimal location for the knot. How to compute the coef respectively and interpret the graph ? In place of educ, you would insert your outcome variable, and in place of yrborn, you would place your predictor variable. Then for the initial() option, you would insert plausible values for knot, b1, b2, and cons. These correspond to the placement of the knot, the slope before the knot, the slope after the knot, and the constant, respectively. In this example, I used 1945 as the knot. To estimate b1, I looked at the graph and saw that the mean education rose about 4 units from 1905 to 1945. Taking a change of 4 units divided by 40 gave me an estimate of 0.1 for b1. Likewise, I estimated that education declined by about 0.5 units from 1945 to 1985 and divided $-0.5$ units by 40 to yield $-0.0125$ as an estimate of b2. Finally, to estimate cons I estimated the average education to be 9.5 units at 1905 and then used the estimated slope of 0.1 to estimate the education at year 0 would be $9.5-1905×0.1=-181.$ ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:6:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"7 Piecewise model with multiple unknown knots This section illustrates the use of piecewise regression models where there could be multiple knots in the relationship between the predictor and outcome, and you have no basis for the placement of the knots. Consider the relationship between age and income. I would suspect that income would initially rise rapidly with increasing age, hit a peak, and then decline with increasing age. In such a case, we can intentionally fit a model with too many knots and then progressively remove the superfluous knots. use gss_ivrm.dta keep if age\u003c=80 * Model 0 reg realrinc i.age,vce(robust) The test of these indicators is significant, and they have an $R^2$ value of 0.0581. This $R^2$ value is the highest amount of variance we could hope to explain using age as a predictor. This is because this set of indicators accounts for every tiny bump and drop in the relationship between age and income. Any simpler model (for example, linear, quadratic, or piecewise) will not account for all the bumps and drops and thus will have a lower $R^2$ . However, a good model will account for the major bumps and drops and have an $R^2$ that is not too much smaller than the $R^2$ from the indicator model. This is our goal in fitting the piecewise model with multiple knots. Let’s visualize the relationship between age and income. We can do this by using the predict command to create predicted values based on the indicator model, in this case named yhatind. predict yhatind graph twoway line yhatind age,sort xlabel(18 20(5)80) graph twoway line yhatind age,xlabel(25 30 35 45 55 65) xline(25 30 35 45 55 65)sort Let’s first fit a model specified by the knots at ages 25, 30, 35, 45, 55, and 65, which we will call model 1. we will use the mkspline command to create knots at each of the ages, and this creates the variables age18to24m to age65to80m. model1 : full model* mkspline age18to24m 25 age25to29m 30 /// age30to34m 35 age35to44m 45 /// age45to54m 55 age55to64m 65 /// age65to80m=age,marginal reg realrinc age18to24m-age65to80m,vce(robust) Linear regression Number of obs = 32,100\rF(7, 32092) = 712.84\rProb \u003e F = 0.0000\rR-squared = 0.0559\rRoot MSE = 26153\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\rage18to24m | 1559.14 66.34 23.50 0.000 1429.10 1689.18\rage25to29m | -582.00 131.65 -4.42 0.000 -840.04 -323.96\rage30to34m | -45.67 188.34 -0.24 0.808 -414.82 323.48\rage35to44m | -494.46 184.93 -2.67 0.008 -856.93 -131.99\rage45to54m | -310.18 154.30 -2.01 0.044 -612.61 -7.76\rage55to64m | -827.83 190.35 -4.35 0.000 -1200.93 -454.73\rage65to80m | -4.33 214.92 -0.02 0.984 -425.59 416.93\r_cons | -25134.60 1502.49 -16.73 0.000 -28079.54 -22189.66\rWhen a coefficient regarding the change in the slope in the line segments is not significant, it indicates a knot that can be removed because the slopes before and after the knot are not significantly different. We can use this as a guide for removing superfluous knots. we can see that the slope for those who are 55 to 64 years old is similar to the slope for those who are 65 years old and older. Thus, the knot at age 65 is not really needed and we can assume one slope from ages 55 to 80. *model 2 :drop knot at age 65 drop age18to24m-age65to80m mkspline age18to24m 25 age25to29m 30 /// age30to34m 35 age35to44m 45 /// age45to54m 55 age55to80m=age,marginal reg realrinc age18to24m-age55to80m,vce(robust) Linear regression Number of obs = 32,100\rF(6, 32093) = 830.57\rProb \u003e F = 0.0000\rR-squared = 0.0559\rRoot MSE = 26152\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\rage18to24m | 1559.15 66.34 23.50 0.000 1429.11 1689.18\rage25to29m | -582.03 131.64 -4.42 0.000 -840.05 -324.01\rage30to34m | -45.57 188.23 -0.24 0.809 -414.50 323.36\rage35to44m | -494.68 184.31 -2.68 0.007 -855.94 -133.42\rage45to54m | -309.49 146.24 -2.12 0.034 -596.12 -22.87\rage55to80m | -829.99 133.15 -6.23 0.000 -1090.96 -569.01\r_cons | -25134.71 1502.46 -16.73 0.000 -28079.59 -22189.83\rI","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:7:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"8 Automating graphs of piecewise models If you change your data (for example, fix incorrect values), the adjusted means will not be automatically updated to reflect the new data.This section illustrates a more efficient, but trickier, way of creating such graphs that does not require retyping the data. use gss_ivrm.dta mkspline ed1m 12 ed2m 16 ed3m = educ,marginal reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust) margins,at(ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=1 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=13 ed2m=1 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) /// at(ed1m=17 ed2m=5 ed3m=1 hsgrad=1 cograd=1) /// at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1) The following steps save the adjusted means from the margins command, as well as the corresponding values of education into the active dataset. The graph command is then used to graph the adjusted means by education, creating the graph shown below matrix yhat = r(b)' svmat yhat matrix educ = ( 0 \\ 1 \\ 12 \\ 12 \\ 13 \\ 16 \\ 16 \\ 17 \\ 20 ) svmat educ graph twoway line yhat1 educ1, xline(12 16) xtitle(Education) ytitle(Adjusted mean) Let’s walk through this process again, but do so more slowly. First, repeat the use gss_ivrm command, as well as the mkspline, regress, and margins commands from above. Now, the adjusted means computed by the margins command are stored in a matrix named r(b) with one row and nine columns, corresponding to the nine values specified with the at() option. use gss_ivrm.dta mkspline ed1m 12 ed2m 16 ed3m = educ,marginal reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust) margins,at(ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=1 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) /// at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=13 ed2m=1 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) /// at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) /// at(ed1m=17 ed2m=5 ed3m=1 hsgrad=1 cograd=1) /// at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1) matrix list r(b) r(b)[1,9]\r1. 2. 3. 4. 5. 6. 7. 8. 9.\r_at _at _at _at _at _at _at _at _at\rr1 10258.623 10530.894 13525.881 17451.464 19053.55 23859.81 29600.571 33742.824 46169.582\rLet’s store these adjusted means as a matrix called yhat and in the process transpose the matrix (converting the columns to rows). matrix yhat = r(b)' matrix list yhat yhat[9,1]\rr1\r1._at 10258.623\r2._at 10530.894\r3._at 13525.881\r4._at 17451.464\r5._at 19053.55\r6._at 23859.81\r7._at 29600.571\r8._at 33742.824\r9._at 46169.582\rWe can then save yhat into the current dataset with the svmat command. svmat yhat list yhat1 in 1/10 +----------+\r| yhat1 |\r|----------|\r1. | 10258.62 |\r2. | 10530.89 |\r3. | 13525.88 |\r4. | 17451.46 |\r5. | 19053.55 |\r6. | 23859.81 |\r7. | 29600.57 |\r8. | 33742.82 |\r9. | 46169.58 |\r10. | . |\r+----------+\rNow, let’s make a matrix containing the values of education. This is stored in the matrix named educ. We then save this matrix into the dataset, as shown below. matrix educ = (0 \\ 1 \\ 12 \\ 12 \\ 13 \\ 16 \\ 16 \\ 17 \\ 20) svmat educ list yhat1 educ1 in 1/10 +------------------+\r| yhat1 educ1 |\r|------------------|\r1. | 10258.62 0 |\r2. | 10530.89 1 |\r3. | 13525.88 12 |\r4. | 17451.46 12 |\r5. | 19053.55 13 |\r6. | 23859.81 16 |\r7. | 29600.57 16 |\r8. | 33742.82 17 |\r9. | 46169.58 20 |\r10. | . . |\r+------------------+\rNow, we can graph the adjusted means, called yhat1, by the levels of education, called educ1, as shown below. graph twoway line yhat1 educ1, xline(12 16)xtitle(Education) ytitle(Adjusted mean) Although the process of creating this graph is more complicated, the benefit is that it will automatically be updated if the dataset changes. This can be a little more work in the short run but saves us time in the long run. ","date":"2023-12-29","objectID":"/3.continuous-predictors_piecewise-models/:8:0","tags":["Continuous predictors","stata"],"title":"Chapter4 ：Continuous predictors: Piecewise models","uri":"/3.continuous-predictors_piecewise-models/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This chapter focuses on the use of polynomial terms to account for nonlinearity in the relationship between a continuous predictor and a continuous outcome.  ","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This Chapter focuses on how to interpret the coefficient of a continuous predictor in a linear regression model. ","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:0:0","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Quadratic (squared) terms A quadratic (squared) term can be used to model curved relationships, accounting for one bend in the relationship between the predictor and outcome. Let’s relate the nature of the curve to the regression equation predicting income (realrinc) from age (age), shown below. $$ \\widehat{realrinc}=-30000 + 2500age + (-25age^{2}) $$ For an inverted U-shaped curve, we can compute the value of x that corresponds to the maximum value of y. If we call the linear coefficient of age and the quadratic coefficient of age b2 , then the value of age that yields the maximum income is given by -b1/(2×b2). Substituting 2,500 for b1 and -25 for b2 yields a value of 50;therefore,the maximum income occurs when someone is 50 years old. The degree of curvature (U-shape) would increase as the quadratic coefficient increases. The linear coefficient would still determine the slope when the predictor is at zero. Because the curve is U-shaped, the minimum of that curve would be represented by -b1/(2×b2), where is the linear coefficient and is the quadratic coefficient. ","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:1:0","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Examples use gss_ivrm.dta keep if (age\u003c=80) Before fitting a quadratic model relating income to age, let’s assess the shape of the relationship between these variables using a locally weighted smoother. The lowess command is used to create the variable yhatlowess, which is the predicted value based on the locally weighted regression predicting income from age. Checking for nonlinearity lowess realrinc age,nograph gen(yhatlowess) line yhatlowess age,sort Let’s fit a model with a quadratic (squared) term to account for the bend in the relationship between age and income. We do this using the interaction operator ## (as shown below), which creates a term that multiplies age by age. Specifying c.age indicates to Stata that age should be treated as a continuous variable (instead of treating it as factor variable). 1.1.1 Interpreting the relationship between age and income reg realrinc c.age##c.age female,vce(robust) Note! Why not square age? You might be wondering why we do not instead use the generate command to create a new variable, say, age2, that contains the age squared. If we do this, the results of the regress command would be the same, but this would confuse the margins command. The margins command would think that age and age2 are two completely different variables. Linear regression Number of obs = 32,100\rF(3, 32096) = 1252.67\rProb \u003e F = 0.0000\rR-squared = 0.1089\rRoot MSE = 25407\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\rage | 2412.339 58.058 41.55 0.000 2298.544 2526.135\r|\rc.age#c.age | -24.202 0.696 -34.78 0.000 -25.566 -22.838\r|\rfemale | -1.24e+04 280.475 -44.28 0.000 -1.30e+04 -1.19e+04\r_cons | -2.57e+04 1038.412 -24.73 0.000 -2.77e+04 -2.36e+04\rWe can use the formula -b1/(2×b2) to compute the age at which income is at its maximum. This yields -2412.34/(2×-24.20) , which equals 49.84. The adjusted mean of income is highest for those who are 49.84 years old. Suppose we wanted to estimate the age slope for any given value of age. We can do so using the margins command combined with the dydx(age) option.Below,we obtain the age slope for ages ranging from 30 to 70 in 10-year increments. margins,at(age=(30(10)70))dydx(age)vsquish Average marginal effects Number of obs = 32,100\rModel VCE: Robust\rExpression: Linear prediction, predict()\rdy/dx wrt: age\r1._at: age = 30\r2._at: age = 40\r3._at: age = 50\r4._at: age = 60\r5._at: age = 70\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\rage |\r_at |\r1 | 960.222 18.274 52.55 0.000 924.404 996.039\r2 | 476.183 9.823 48.47 0.000 456.928 495.437\r3 | -7.856 15.700 -0.50 0.617 -38.628 22.915\r4 | -491.896 27.998 -17.57 0.000 -546.772 -437.019\r5 | -975.935 41.336 -23.61 0.000 -1056.955 -894.915\r1.1.2 Graphing adjusted means with confidence intervals The marginsplot command can be used to create a graph of the adjusted means with a shaded region showing the confidence interval for the adjusted means. We can then run the marginsplot command, adding the recast(line) and recastci(rarea) options to display the adjusted means as a line and the confidence interval as a shaded region. The resulting graph is shown in below. margins,at(age=(18(1)80)) marginsplot,recast(line) recastci(rarea) ","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:1:1","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Cubic (third power)terms Let’s examine the relationship between the year of birth and number of children a woman has using the gss_ivrm.dta dataset, focusing on women aged 45 to 55 born between 1920 and 1960. use gss_ivrm.dta keep if (age\u003e=45 \u0026 age\u003c=55) \u0026 (yrborn\u003e=1920 \u0026 yrborn\u003c=1960) \u0026 female==1 lowess children yrborn,gen(yhatlowess) nograph graph twoway line yhatlowess yrborn,sort Below,we fit a model predicting children from yrborn fit using a cubic term.The model specifies c.yrborn##c.yrborn##c.yrborn, which includes the cubic term for yrborn, the quadratic term for yrborn, and the linear term for yrborn. reg children c.yrborn##c.yrborn##c.yrborn,noci note: c.yrborn#c.yrborn#c.yrborn omitted because of collinearity. Source | SS df MS Number of obs = 5,049\rF(2, 5046) = 193.19\rModel | 1163.13728 2 581.56864 Prob \u003e F = 0.0000\rResidual | 15189.893 5,046 3.01028399 R-squared = 0.0711\rAdj R-squared = 0.0708\rTotal | 16353.0303 5,048 3.2395068 Root MSE = 1.735\rchildren | Coefficient Std. err. t P\u003e|t|\ryrborn | 1.431 0.816 1.75 0.079\r|\rc.yrborn#c.yrborn | -0.000 0.000 -1.81 0.071\r|\rc.yrborn#c.yrborn#c.yrborn | 0.000 (omitted)\r|\r_cons | -1344.881 791.474 -1.70 0.089\rThere was a problem running this model. There is a note saying that the cubic term was omitted because of collinearity. This is a common problem when entering cubic terms, which can be solved by centering yrborn. The dataset includes a variable called yrborn40, which is the variable yrborn centered around the year 1940 (that is, 1940 is subtracted from each value of yrborn). Let’s try fitting the above model again but instead using the variable yrborn40. reg children c.yrborn40##c.yrborn40##c.yrborn40,noci . reg children c.yrborn40##c.yrborn40##c.yrborn40,noci Source | SS df MS Number of obs = 5,049\rF(3, 5045) = 166.84\rModel | 1475.96126 3 491.987087 Prob \u003e F = 0.0000\rResidual | 14877.069 5,045 2.94887394 R-squared = 0.0903\rAdj R-squared = 0.0897\rTotal | 16353.0303 5,048 3.2395068 Root MSE = 1.7172\rchildren | Coefficient Std. err. t P\u003e|t|\ryrborn40 | -0.091 0.005 -17.34 0.000\r|\rc.yrborn40#c.yrborn40 | -0.001 0.000 -3.66 0.000\r|\rc.yrborn40#c.yrborn40#c.yrborn40 | 0.000 0.000 10.30 0.000\r|\r_cons | 2.741 0.037 73.67 0.000\rNote! Including linear, quadratic, and cubic terms When fitting this kind of a cubic model, you might find that the linear or quadratic coefficients are not significant. For the sake of parsimony, you might be tempted to omit those variables because they are not significant. However, it is essential that these terms be included in the model (even if not significant) to preserve the interpretation of the cubic term. Specifying at(yrborn40=(-20(1)20)) yields predicted means for years of birth ranging from 1920 to 1960 in one-year increments. reg children c.yrborn40##c.yrborn40##c.yrborn40,noci The marginsplot command is then used to create the graph shown in figure. The recast(line) and recastci(rarea) options display the predicted means as a solid line and the confidence interval as a shaded area. You can further explore how the yrborn40 slope varies as a function of year of birth by specifying multiple values within the at() option, as shown below. margins,at(yrborn40=(-20(5)20)) dydx(yrborn40) vsquish Conditional marginal effects Number of obs = 5,049\rModel VCE: OLS\rExpression: Linear prediction, predict()\rdy/dx wrt: yrborn40\r1._at: yrborn40 = -20\r2._at: yrborn40 = -15\r3._at: yrborn40 = -10\r4._at: yrborn40 = -5\r5._at: yrborn40 = 0\r6._at: yrborn40 = 5\r7._at: yrborn40 = 10\r8._at: yrborn40 = 15\r9._at: yrborn40 = 20\r| Delta-method\r| dy/dx std. err. t P\u003e|t| [95% conf. interval]\ryrborn40 |\r_at |\r1 | 0.191 0.023 8.34 0.000 0.146 0.236\r2 | 0.074 0.012 6.02 0.000 0.050 0.097\r3 | -0.013 0.005 -2.35 0.019 -0.023 -0.002\r4 | -0.067 0.004 -15.70 0.000 -0.076 -0.059\r5 | -0.091 0.005 -17.34 0.000 -0.101 -0.081\r6 | -0.083 0.005 -18.12 0.000 -0.092 -0.074\r7 | -0.044 0.004 -9.82 0.000 -0.052 -0.035\r8 | 0.027 0.010 2.70 0.007 0.007 0.047\r9 | 0.129 0.020 6.50 0.000 0.090 0.16","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:2:0","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Fractional polynomial regression Fractional polynomial regression is more flexible by considering other kinds of power terms as well, including negative powers and fractional powers. The fp prefix automates the process of selecting the best fitting fractional polynomial model.It fits a variety of polynomial terms (and combinations of polynomial terms) and shows you the best fitting model. The default set of power terms the fp prefix will try includes -2,-1,-0.5, 0, 0.5, 1, 2, and 3 (where 0 indicates that the natural log of the predictor is used). Let’s look at this canvas of shapes, beginning with the negative powers (-2,-1,and -0.5). These models take the form of y=b*Xpower, where could be positive or negative, and could be -2,-1, or -0.5. Figure shows some possible shapes of these models, showing the powers -2,-1,-0.5 and in columns 1, 2, and 3. The graphs in the first row (with the positive coefficients) are all typified by a steep descent and then reaching a floor. The more strongly negative the power term, the stronger the descent. The second row is a vertical mirror image of the first. When the coefficient is negative, there is a sharp ascent and then a ceiling is reached. The more negative power terms are associated with a sharper ascent. The shapes of the relationship between and for the powers 1, 2, and 3 are shown in figure The first column shows a linear relationship between and . The second and third columns show the second and third power, with the top row showing a U-shaped bend and the bottom row showing an inverted U-shaped bend. The higher power terms are associated with a more rapid change in the outcome for a unit change in the predictor. the fp prefix (by default) will not only fit each of these eight powers alone, but also includes all two-way combinations of these powers. The right panel shows the formula combining these two curves, Note how this curve combines the rapid rise of the left panel with the gradual inverted U-shape of the middle panel. As you can imagine, being able to combine two different fractional polynomials can yield a flexible set of possible curve shapes for modeling your data. 2.1.1 Example using fractional polynomial regression First, we will run a regression predicting educ fromage, treating age as a categorical variable use gss_ivrm.dta keep if (age\u003c=80) reg educ i.age predict yhatmean graph twoway line yhatmean age,sort xlabel(20(5)80) Note how there is a curvilinear aspect to the relationship between age and education, suggesting that we might try including a quadratic term for educ. reg educ c.age##c.age Source | SS df MS Number of obs = 53,070\rF(2, 53067) = 1616.60\rModel | 29981.1031 2 14990.5515 Prob \u003e F = 0.0000\rResidual | 492083.501 53,067 9.27287205 R-squared = 0.0574\rAdj R-squared = 0.0574\rTotal | 522064.604 53,069 9.83746828 Root MSE = 3.0451\reduc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\rage | 0.138 0.005 28.22 0.000 0.129 0.148\r|\rc.age#c.age | -0.002 0.000 -36.02 0.000 -0.002 -0.002\r|\r_cons | 10.763 0.107 100.14 0.000 10.553 10.974\rLet’s use the predict command to compute the fitted values from the quadratic model, naming the variable yhatq. Then, let’s graph the fitted values from the quadratic model and the mean of education by age, as shown below. predict yhatq graph twoway line yhatmean yhatq age,sort xlabel(20(5)80) Note how the quadratic fit line yields predicted values that are too high in the younger years and too low in the older years. Another way of putting this is that the quadratic line does not account for the rapid rise in education in the late teens and early 20s, nor does it account for the slow decline of education in later years. A fractional polynomial model, with its increased flexibility, could provide a more appropriate fit. We fit such a model by adding the fp prefix to the regress command, as shown below. fp \u003cage\u003e:reg educ \u003cage\u003e Fractional polynomial comparisons:\r| Test Residual Deviance\rage | df Deviance std. dev. diff. P Powers","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:2:1","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.2 Main effects with polynomial terms The meaning of main effects changes when polynomial terms are included in the model. In fact, the inclusion of polynomial terms can substantially change the coefficient for the main effect when compared with the main effect–only model. use gss_ivrm.dta keep if (age\u003c=80) reg realrinc age female,vce(robust) Linear regression Number of obs = 32,100\rF(2, 32097) = 1170.51\rProb \u003e F = 0.0000\rR-squared = 0.0787\rRoot MSE = 25833\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\rage | 320.07 10.70 29.93 0.000 299.10 341.03\rfemale | -12373.25 285.03 -43.41 0.000 -12931.91 -11814.59\r_cons | 15106.17 403.04 37.48 0.000 14316.19 15896.16\rHowever, there is a problem. As we saw in section 1.1, the relationship between income and age is not linear. As we did in that section, let’s add a quadratic term for age, as shown below. reg realrinc c.age##c.age female,vce(robust) Linear regression Number of obs = 32,100\rF(3, 32096) = 1252.67\rProb \u003e F = 0.0000\rR-squared = 0.1089\rRoot MSE = 25407\r| Robust\rrealrinc | Coefficient std. err. t P\u003e|t| [95% conf. interval]\rage | 2412.34 58.06 41.55 0.000 2298.54 2526.13\r|\rc.age#c.age | -24.20 0.70 -34.78 0.000 -25.57 -22.84\r|\rfemale | -12419.24 280.47 -44.28 0.000 -12968.98 -11869.49\r_cons | -25679.77 1038.41 -24.73 0.000 -27715.10 -23644.44\rThe quadratic term is significant, but we might suddenly become concerned that the main effect of age has skyrocketed from 320.07 in the linear model to 2,412.34 in the quadratic model. Why did the main effect change so much? Did we do something wrong? The key is that the term “main effect” is really a misnomer, because we expect this term to describe the general trend of the relationship between income and age. This value is meaningless for two reasons. First, nobody has income when they are zero years old. Second, this term no longer reflects the general trend. As we saw in section 1.1, the age slope changes for every level of age, so there is no such thing as a measure of general trend in this kind of model. ","date":"2023-12-28","objectID":"/2.continuous-predictors_polynomials/:2:2","tags":["Continuous predictors","stata"],"title":"Chapter3 ：Continuous predictors: Polynomials","uri":"/2.continuous-predictors_polynomials/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This Chapter focuses on how interpret the coefficient of a continuous predictor in a linear regression models. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"This Chapter focuses on how to interpret the coefficient of a continuous predictor in a linear regression model. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:0:0","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1 Simple linear regression This section illustrates the use of a continuous predictor for predicting a continuous outcome using ordinary least-squares regression. Terminology: Continuous and categorical variables When I use the termcontinuous variable, I am referring to a variable that is measured on an interval or ratio scale. By contrast, when I speak of a categorical variable,I am referring to either a nominal variable or an ordinal/interval/ratio variable that we wish to treat as though it were a nominal variable. Let’s run a simple regression model in which we predict the education of the respondent from the education of the respondent’s father. regress educ paeduc The result as shown below Source | SS df MS Number of obs = 696\rF(1, 694) = 228.14\rModel | 1649.70181 1 1649.70181 Prob \u003e F = 0.0000\rResidual | 5018.43038 694 7.23116769 R-squared = 0.2474\rAdj R-squared = 0.2463\rTotal | 6668.13218 695 9.5944348 Root MSE = 2.6891\reduc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\rpaeduc | 0.359 0.024 15.10 0.000 0.313 0.406\r_cons | 9.740 0.286 34.08 0.000 9.179 10.301\rThe regression equation can be written as shown below $$ \\widehat{educ}=9.74 + 0.36paeduc $$ The intercept is the predicted mean of the respondent’s education when the father’s education is 0. For every one-year increase in the education of the father, we would predict that the education of the respondent increases by 0.36 years. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:1:0","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.1 Computing predicted means using the margins command Suppose we wanted to compute the predicted mean of education for the respondent, assuming separately that the father had 8, 12, or 16 years of education. margins,at (paeduc=(8 12 16)) vsquish Note: The vsquish option The vsquish option vertically squishes the output by omitting extra blank lines. Adjusted predictions Number of obs = 696\rModel VCE: OLS\rExpression: Linear prediction, predict()\r1._at: paeduc = 8\r2._at: paeduc = 12\r3._at: paeduc = 16\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 12.616 0.128 98.93 0.000 12.365 12.866\r2 | 14.053 0.104 135.64 0.000 13.850 14.257\r3 | 15.491 0.153 101.42 0.000 15.191 15.791\rSometimes, we might want to compute the predicted means given a range of values for a predictor. For example, we might want to compute the predicted means when father’s education is 0, 4, 8, 12, 16, and 20. margins,at(paeduc=(0(4)20)) vsquish Rather than typing all of these values, we can specify 0(4)20, which tells Stata that we mean 0 to 20 in 4-unit increments. Adjusted predictions Number of obs = 696\rModel VCE: OLS\rExpression: Linear prediction, predict()\r1._at: paeduc = 0\r2._at: paeduc = 4\r3._at: paeduc = 8\r4._at: paeduc = 12\r5._at: paeduc = 16\r6._at: paeduc = 20\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 9.740 0.286 34.08 0.000 9.179 10.301\r2 | 11.178 0.200 55.95 0.000 10.786 11.570\r3 | 12.616 0.128 98.93 0.000 12.365 12.866\r4 | 14.053 0.104 135.64 0.000 13.850 14.257\r5 | 15.491 0.153 101.42 0.000 15.191 15.791\r6 | 16.929 0.232 72.82 0.000 16.472 17.385\r","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:1:1","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"1.2 Graphing predicted means using the marginsplot command We can use the marginsplot command to create a graph showing the predicted means and confidence intervals based on the most recent margins command. marginsplot Note：The margins and marginsplot commands work together as a team. Let’s now create a graph that shows the fitted line with a shaded confidence interval. margins,at(paeduc=(0(1)20)) marginsplot,recast(line) recastci(rarea) The recast() option specifies that the fitted line should be displayed as a line graph (suppressing the markers). The recastci() option specifies that the confidence interval should be displayed as an rarea graph, displaying a shaded area for the confidence region. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:1:2","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2 Multiple regression Let’s now turn to a multiple regression model that predicts the respondent’s education from the father’s education (paeduc), the mother’s education (maeduc), and the age of the respondent (age). reg educ paeduc maeduc age Source | SS df MS Number of obs = 650\rF(3, 646) = 92.93\rModel | 1822.26082 3 607.420272 Prob \u003e F = 0.0000\rResidual | 4222.37918 646 6.53619069 R-squared = 0.3015\rAdj R-squared = 0.2982\rTotal | 6044.64 649 9.31377504 Root MSE = 2.5566\reduc | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\rpaeduc | 0.258 0.033 7.82 0.000 0.193 0.323\rmaeduc | 0.208 0.038 5.48 0.000 0.133 0.282\rage | 0.034 0.007 5.28 0.000 0.022 0.047\r_cons | 6.962 0.511 13.63 0.000 5.959 7.965\rThe equation as shown below $$ \\widehat{educ}=6.86 + 0.26paeduc + 0.21maeduc + 0.03age $$ The coefficients from this multiple regression model reflect the association between each predictor and the outcome after adjusting for all the other predictors. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:2:0","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"2.1 Computing adjusted means using the margins command The margins command allows us to hold more than one variable constant at a time. In the example below, we compute the adjusted means when the father’s education equals 8, 12, and 16, while holding the mother’s education constant at 14. reg educ paeduc maeduc age Predictive margins Number of obs = 650\rModel VCE: OLS\rExpression: Linear prediction, predict()\r1._at: paeduc = 8\rmaeduc = 14\r2._at: paeduc = 12\rmaeduc = 14\r3._at: paeduc = 16\rmaeduc = 14\r| Delta-method\r| Margin std. err. t P\u003e|t| [95% conf. interval]\r_at |\r1 | 13.544 0.211 64.18 0.000 13.130 13.958\r2 | 14.576 0.128 113.76 0.000 14.325 14.828\r3 | 15.609 0.152 102.52 0.000 15.310 15.908\rTerminology: Adjusted means For example, we can say that the predicted mean, given the father has 8 years of education, is 13.544 after adjusting for all other predictors. We could also call this an adjusted mean. The term adjusted mean implies after adjusting for all other predictors in the model. When using nonlinear models (such as a logistic regression model), we will use a more general term, such as predictive margin. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:2:1","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3 Checking for nonlinearity graphically This section illustrates graphical approaches for checking for nonlinearity in the relationship between a predictor and outcome variable. These approaches include examining scatterplots of the predictor and outcome. examining residual-versusfitted plots. creating plots based on locally weighted smoothers. plotting the mean of the outcome for each level of the predictor. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:3:0","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.1 Using scatterplots to check for nonlinearity Let’s look at a scatterplot of the size of the engine (displacement) by length of the car (length) with a line showing the linear fit, as shown in figure use autosubset graph twoway (scatter displacement length) (lfit displacement length),ytitle(\"Engine displacement(cu in.) \") legend (off) The relationship between these two variables looks fairly linear, but the addition of the linear fit line helps us to see the nonlinearity. Note how for short cars (whenlength is below 160) the fit line underpredicts and for longer cars (when length is above 210) the fit line also underpredicts. Using a scatterplot like this can be a simple means of looking at the linearity of the simple relationship between a predictor and outcome variable. However, this does not account for other predictors that you might want to include in a model. To this end, let’s next look at how we can use the residuals for checking linearity ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:3:1","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.2 Checking for nonlinearity using residuals For example, let’s run a regression predicting displacement from length, trunk, and weight, as shown below reg displacement length trunk weight We can then look at the residuals versus the fitted values, as shown in figure rvfplot Note the U-shaped pattern of the residuals. This pattern suggests that the relationship between the predictors and outcome is not linear. There are many excellent resources that illustrate Stata’s regression diagnostic tools, including the manual entry for [R] regress postestimation. You can also see the help entries for avplot, rvfplot, and rvpplot. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:3:2","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.3 Checking for nonlinearity using locally weighted smoother With larger datasets, it can be harder to visualize nonlinearity using scatterplots or residual-versus-fitted plots. Suppose we want to determine the nature of the relationship between the year that the respondent was born (yrborn) and education level (educ). use gss_ivrm.dta scatter educ yrborn,msymbol(oh) It is hard to discern the nature of the relationship between year of birth and education using this scatterplot. With so many observations, the scatterplot is saturated with data points creating one big blotch that tells us little about the shape of the relationship between the predictor and outcome The lowess command below creates a graph showing the locally weighted regression of education on year of birth, as shown in figure lowess educ yrborn,msymbol(p) The lowess graph suggests that there is nonlinearity in the relationship between year of birth and education. Education increases with year of birth until the 1950s, at which point the smoothed education values level out and then start to decline. The graph produced by the lowess command is much more informative than the scatterplot alone. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:3:3","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"3.4 Graphing outcome mean at each level of predictor Another way to visualize the relationship between the predictor and outcome is to create a graph showing the mean of the outcome at each level of the predictor. Using the example predicting education from year of birth means creating a graph of the average of education at each level of year of birth. Although the variable yrborn can assume many values (from 1883 to 1990), the variable is composed of discrete integers with reasonably many observations (usually more than 100) for each value. In such a case, we can explore the nature of the relationship between the predictor and outcome by creating a graph of the mean of the outcome variable (education level) for each level of the predictor (year of birth). This kind of graph imposes no structure on the shape of the relationship between year of birth and education and allows us to observe the nature of the relationship between the predictor and the outcome. One simple way to create such a graph is to fit a regression model predicting the outcome treating the predictor variable as a factor variable. Following that, the margins command is used to obtain the predicted mean of the outcome for each level of the predictor. In the regress command below, specifying i.yrborn indicates that the variable yrborn should be treated as a factor variable. The following margins command computes the predicted mean of the outcome (education) at each year of birth reg educ i.yrborn margins yrborn marginsplot The predicted means vary erratically for the years before 1900 because of the few observations per year during those years. For these years, the confidence intervals are much wider compared with later years, reflecting greater uncertainty of the estimates because of fewer observations. If all the years had such few observations, then the entire graph might be dominated by wild swings in the means and show little about the nature of the relationship between the predictor and outcome. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:3:4","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4 Checking for nonlinearity analytically This section shows how to check for nonlinearity using analytic approaches, including adding power terms and using factor variables. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:4:0","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.1 Adding power terms Another way to check for nonlinearity of a continuous variable is to add power terms (for example, quadratic or cubic). Using the example with education as a function of year of birth. Let’s introduce a quadratic term (in addition to the linear term) by adding c.yrborn#c.yrborn to the model. This introduces a quadratic effect that would account for one bend in the line relating year of birth to education. We would expect the quadratic term to be significant based on the graphs we saw in figures use gss_ivrm.dta Source | SS df MS Number of obs = 54,745\rF(2, 54742) = 3567.49\rModel | 63778.2779 2 31889.1389 Prob \u003e F = 0.0000\rResidual | 489328.985 54,742 8.93882184 R-squared = 0.1153\rAdj R-squared = 0.1153\rTotal | 553107.263 54,744 10.103523 Root MSE = 2.9898\reduc | Coefficient Std. err. t P\u003e|t|\ryrborn | 4.218 0.102 41.46 0.000\r|\rc.yrborn#c.yrborn | -0.001 0.000 -41.00 0.000\r|\r_cons | -4129.000 98.816 -41.78 0.000\rNote! Using the noci option for clearer output When models include interactions,those labels can get rather wide, and Stata is forced to display those labels across multiple lines, which can make the output confusing and hard to read. This omits the display of the confidence intervals, which makes enough room to display the label for every term in the model in a single line. but!,the confidence interval are also important for our research. The quadratic term is significant in this model.Furthermore, the R2 for this model increased to 0.1153 compared with 0.0881 for the linear model. This provides analytic support for including a quadratic term for year of birth when predicting education. A cubic term would imply that the line fitting year of birth and education has a tendency to have two bends in it.c.yrborn##c.yrborn##c.yrborn as a predictor is a shorthand for including the linear, quadratic, and cubic terms for year of birth (yrborn). reg educ c.yrborn##c.yrborn##c.yrborn,noci note: c.yrborn#c.yrborn#c.yrborn omitted because of collinearity. Source | SS df MS Number of obs = 926\rF(2, 923) = 11.47\rModel | 219.843988 2 109.921994 Prob \u003e F = 0.0000\rResidual | 8846.14737 923 9.584125 R-squared = 0.0242\rAdj R-squared = 0.0221\rTotal | 9065.99136 925 9.80107174 Root MSE = 3.0958\reduc | Coefficient Std. err. t P\u003e|t|\ryrborn | 6.159 1.287 4.79 0.000\r|\rc.yrborn#c.yrborn | -0.002 0.000 -4.79 0.000\r|\rc.yrborn#c.yrborn#c.yrborn | 0.000 (omitted)\r|\r_cons | -6015.618 1259.800 -4.78 0.000\rThere was a problem running this model. There is a note saying that the cubic term was omitted because of collinearity. This is a common problem when entering cubic terms, which can be solved by centering yrborn. The dataset includes a variable called yrborn40, which is the variable yrborn centered around the year 1940 (that is, 1940 is subtracted from each value of yrborn). reg educ c.yrborn40##c.yrborn40##c.yrborn40,noci Source | SS df MS Number of obs = 926\rF(3, 922) = 7.72\rModel | 222.175819 3 74.0586064 Prob \u003e F = 0.0000\rResidual | 8843.81554 922 9.59199083 R-squared = 0.0245\rAdj R-squared = 0.0213\rTotal | 9065.99136 925 9.80107174 Root MSE = 3.0971\reduc | Coefficient Std. err. t P\u003e|t|\ryrborn40 | 0.058 0.014 4.20 0.000\r|\rc.yrborn40#c.yrborn40 | -0.002 0.001 -2.14 0.033\r|\rc.yrborn40#c.yrborn40#c.yrborn40 | 0.000 0.000 0.49 0.622\r|\r_cons | 13.427 0.201 66.87 0.000\rThe results show, as expected, that the cubic term is significant. However, this dataset has many observations, so the model has the statistical power to detect very small effects. Note how the is 0.1162 for the cubic model compared with 0.1153 for the quadratic model. This is a trivial increase, suggesting that the cubic trend is not really an important term to include in this model. ","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:4:1","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["Interpreting and Visualizing Regression Models Using Stata"],"content":"4.2 Using factor variables The strategy of using factor variables to check for nonlinearity makes sense only when you have a relatively limited number of levels of the predictor that are coded as whole numbers. let’s perform an analysis to detect any kind of nonlinearity in the relationship between decade of age and health status. use gss_ivrm.dta reg health c.agedec i.agedec note: 8.agedec omitted because of collinearity. Source | SS df MS Number of obs = 40,984\rF(7, 40976) = 451.59\rModel | 2111.10121 7 301.585887 Prob \u003e F = 0.0000\rResidual | 27364.9308 40,976 .667828261 R-squared = 0.0716\rAdj R-squared = 0.0715\rTotal | 29476.032 40,983 .719225826 Root MSE = .81721\rhealth | Coefficient Std. err. t P\u003e|t| [95% conf. interval]\ragedec | -0.098 0.005 -18.46 0.000 -0.108 -0.087\r|\ragedec |\r20s | 0.110 0.028 3.97 0.000 0.055 0.164\r30s | 0.165 0.024 6.85 0.000 0.118 0.212\r40s | 0.135 0.022 6.24 0.000 0.093 0.178\r50s | 0.065 0.021 3.15 0.002 0.025 0.106\r60s | -0.006 0.021 -0.28 0.783 -0.047 0.036\r70s | -0.038 0.024 -1.60 0.110 -0.084 0.009\r80s | 0.000 (omitted)\r|\r_cons | 3.320 0.035 95.81 0.000 3.253 3.388\rThis unconventional-looking model divides the relationship between the age decade and the outcome into two pieces: the linear relationship, which is accounted for by c.agedec any remaining nonlinear components, which are explained by the indicator variables specified by i.agedec. Let’s now use the testparm command to perform a test of the indicator variables, giving us an overall test of the nonlinearity in the relationship between age decade and health status. testparm i.agedec (1) 2.agedec = 0\r(2) 3.agedec = 0\r(3) 4.agedec = 0\r(4) 5.agedec = 0\r(5) 6.agedec = 0\r(6) 7.agedec = 0\rF( 6, 40976) = 20.61\rProb \u003e F = 0.0000\rThis general strategy tells us that there is nonlinearity between the age decade and health status but does not pinpoint the exact nature of the nonlinearity. Let’s try another strategy that will pinpoint the nature of the nonlinearity. And use the contrast command with the p. contrast operator to obtain a detailed breakdown of possible nonlinear trends in the relationship between the age decade and health status reg health i.agedec contrast p.agedec Contrasts of marginal linear predictions Margins: asbalanced | df F P\u003eF\ragedec |\r(linear) | 1 1187.58 0.0000\r(quadratic) | 1 26.65 0.0000\r(cubic) | 1 52.99 0.0000\r(quartic) | 1 1.18 0.2778\r(quintic) | 1 1.00 0.3179\r(sextic) | 1 0.15 0.6959\r(septic) | 1 0.02 0.8748\rJoint | 7 451.59 0.0000\r|\rDenominator | 40976\r| Contrast Std. err. [95% conf. interval]\ragedec |\r(linear) | -0.260 0.008 -0.275 -0.245\r(quadratic) | -0.038 0.007 -0.053 -0.024\r(cubic) | 0.047 0.006 0.034 0.059\r(quartic) | 0.006 0.005 -0.005 0.016\r(quintic) | -0.004 0.004 -0.013 0.004\r(sextic) | 0.001 0.004 -0.006 0.009\r(septic) | -0.001 0.004 -0.008 0.006\r","date":"2023-12-09","objectID":"/1.continuous-predictors_linear/:4:2","tags":["Continuous predictors","stata"],"title":"Chapter2 ：Continuous predictors:Linear","uri":"/1.continuous-predictors_linear/"},{"categories":["documentation"],"content":"探索 Hugo - LoveIt 主题的全部内容和背后的核心概念.","date":"2020-03-06","objectID":"/theme-documentation-basics/","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"探索 Hugo - LoveIt 主题的全部内容和背后的核心概念. ","date":"2020-03-06","objectID":"/theme-documentation-basics/:0:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"1 准备 由于 Hugo 提供的便利性, Hugo 本身是这个主题唯一的依赖. 直接安装满足你操作系统 (Windows, Linux, macOS) 的最新版本  Hugo (\u003e 0.62.0). 为什么不支持早期版本的 Hugo?\r由于 Markdown 渲染钩子函数 在 Hugo 圣诞节版本 中被引入, 本主题只支持高于 0.62.0 的 Hugo 版本.\r推荐使用 Hugo extended 版本\r由于这个主题的一些特性需要将  SCSS 转换为  CSS, 推荐使用 Hugo extended 版本来获得更好的使用体验.\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:1:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2 安装 以下步骤可帮助你初始化新网站. 如果你根本不了解 Hugo, 我们强烈建议你按照此 快速入门文档 进一步了解它. ","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.1 创建你的项目 Hugo 提供了一个 new 命令来创建一个新的网站: hugo new site my_website cd my_website ","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:1","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.2 安装主题 LoveIt 主题的仓库是: https://github.com/dillonzq/LoveIt. 你可以下载主题的 最新版本  .zip 文件 并且解压放到 themes 目录. 另外, 也可以直接把这个主题克隆到 themes 目录: git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 或者, 初始化你的项目目录为 git 仓库, 并且把主题仓库作为你的网站目录的子模块: git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt ","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:2","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.3 基础配置 以下是 LoveIt 主题的基本配置: baseURL = \"http://example.org/\" # 更改使用 Hugo 构建网站时使用的默认主题 theme = \"LoveIt\" # 网站标题 title = \"我的全新 Hugo 网站\" # 网站语言, 仅在这里 CN 大写 [\"en\", \"zh-CN\", \"fr\", \"pl\", ...] languageCode = \"zh-CN\" # 语言名称 [\"English\", \"简体中文\", \"Français\", \"Polski\", ...] languageName = \"简体中文\" # 是否包括中日韩文字 hasCJKLanguage = true # 作者配置 [author] name = \"xxxx\" email = \"\" link = \"\" # 菜单配置 [menu] [[menu.main]] weight = 1 identifier = \"posts\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" name = \"文章\" url = \"/posts/\" # 当你将鼠标悬停在此菜单链接上时, 将显示的标题 title = \"\" [[menu.main]] weight = 2 identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" [[menu.main]] weight = 3 identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" # Hugo 解析文档的配置 [markup] # 语法高亮设置 (https://gohugo.io/content-management/syntax-highlighting) [markup.highlight] # false 是必要的设置 (https://github.com/dillonzq/LoveIt/issues/158) noClasses = false 注意\r在构建网站时, 你可以使用 --theme 选项设置主题. 但是, 我建议你修改配置文件 (config.toml) 将本主题设置为默认主题.\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:3","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.4 创建你的第一篇文章 以下是创建第一篇文章的方法: hugo new posts/first_post.md 通过添加一些示例内容并替换文件开头的标题, 你可以随意编辑文章. 注意\r默认情况下, 所有文章和页面均作为草稿创建. 如果想要渲染这些页面, 请从元数据中删除属性 draft: true, 设置属性 draft: false 或者为 hugo 命令添加 -D/--buildDrafts 参数.\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:4","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.5 在本地启动网站 使用以下命令启动网站: hugo serve 去查看 http://localhost:1313. 基本配置下的预览\r技巧\r当你运行 hugo serve 时, 当文件内容更改时, 页面会随着更改自动刷新.\r注意\r由于本主题使用了 Hugo 中的 .Scratch 来实现一些特性, 非常建议你为 hugo server 命令添加 --disableFastRender 参数来实时预览你正在编辑的文章页面. hugo serve --disableFastRender ","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:5","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"2.6 构建网站 当你准备好部署你的网站时, 运行以下命令: hugo 会生成一个 public 目录, 其中包含你网站的所有静态内容和资源. 现在可以将其部署在任何 Web 服务器上. 技巧\r网站内容可以通过 Netlify 自动发布和托管 (了解有关通过 Netlify 进行 HUGO 自动化部署 的更多信息). 或者, 您可以使用 AWS Amplify, Github pages, Render 以及更多…\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:2:6","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"3 配置 ","date":"2020-03-06","objectID":"/theme-documentation-basics/:3:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"3.1 网站配置 除了 Hugo 全局配置 和 菜单配置 之外, LoveIt 主题还允许您在网站配置中定义以下参数 (这是一个示例 config.toml, 其内容为默认值). 请打开下面的代码块查看完整的示例配置 : baseURL = \"http://example.org/\" # 更改使用 Hugo 构建网站时使用的默认主题 theme = \"LoveIt\" # 网站标题 title = \"我的全新 Hugo 网站\" # 网站语言, 仅在这里 CN 大写 [\"en\", \"zh-CN\", \"fr\", \"pl\", ...] languageCode = \"zh-CN\" # 语言名称 [\"English\", \"简体中文\", \"Français\", \"Polski\", ...] languageName = \"简体中文\" # 是否包括中日韩文字 hasCJKLanguage = true # 默认每页列表显示的文章数目 paginate = 12 # 谷歌分析代号 [UA-XXXXXXXX-X] googleAnalytics = \"\" # 版权描述，仅仅用于 SEO copyright = \"\" # 是否使用 robots.txt enableRobotsTXT = true # 是否使用 git 信息 enableGitInfo = true # 是否使用 emoji 代码 enableEmoji = true # 忽略一些构建错误 ignoreErrors = [\"error-remote-getjson\", \"error-missing-instagram-accesstoken\"] # 作者配置 [author] name = \"xxxx\" email = \"\" link = \"\" # 菜单配置 [menu] [[menu.main]] weight = 1 identifier = \"posts\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" name = \"文章\" url = \"/posts/\" # 当你将鼠标悬停在此菜单链接上时, 将显示的标题 title = \"\" [[menu.main]] weight = 2 identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" [[menu.main]] weight = 3 identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" [params] # 网站默认主题样式 [\"auto\", \"light\", \"dark\"] defaultTheme = \"auto\" # 公共 git 仓库路径，仅在 enableGitInfo 设为 true 时有效 gitRepo = \"\" # 哪种哈希函数用来 SRI, 为空时表示不使用 SRI # [\"sha256\", \"sha384\", \"sha512\", \"md5\"] fingerprint = \"\" # 日期格式 dateFormat = \"2006-01-02\" # 网站标题, 用于 Open Graph 和 Twitter Cards title = \"我的网站\" # 网站描述, 用于 RSS, SEO, Open Graph 和 Twitter Cards description = \"这是我的全新 Hugo 网站\" # 网站图片, 用于 Open Graph 和 Twitter Cards images = [\"/logo.png\"] # 页面头部导航栏配置 [params.header] # 桌面端导航栏模式 [\"fixed\", \"normal\", \"auto\"] desktopMode = \"fixed\" # 移动端导航栏模式 [\"fixed\", \"normal\", \"auto\"] mobileMode = \"auto\" # 页面头部导航栏标题配置 [params.header.title] # LOGO 的 URL logo = \"\" # 标题名称 name = \"\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" # 是否为标题显示打字机动画 typeit = false # 页面底部信息配置 [params.footer] enable = true # 自定义内容 (支持 HTML 格式) custom = '' # 是否显示 Hugo 和主题信息 hugo = true # 是否显示版权信息 copyright = true # 是否显示作者 author = true # 网站创立年份 since = 2019 # ICP 备案信息，仅在中国使用 (支持 HTML 格式) icp = \"\" # 许可协议信息 (支持 HTML 格式) license = '\u003ca rel=\"license external nofollow noopener noreffer\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\"\u003eCC BY-NC 4.0\u003c/a\u003e' # Section (所有文章) 页面配置 [params.section] # section 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # List (目录或标签) 页面配置 [params.list] # list 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # 应用图标配置 [params.app] # 当添加到 iOS 主屏幕或者 Android 启动器时的标题, 覆盖默认标题 title = \"我的网站\" # 是否隐藏网站图标资源链接 noFavicon = false # 更现代的 SVG 网站图标, 可替代旧的 .png 和 .ico 文件 svgFavicon = \"\" # Android 浏览器主题色 themeColor = \"#ffffff\" # Safari 图标颜色 iconColor = \"#5bbad5\" # Windows v8-10磁贴颜色 tileColor = \"#da532c\" # 搜索配置 [params.search] enable = true # 搜索引擎的类型 [\"lunr\", \"algolia\"] type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" # 主页配置 [params.home] # RSS 文章数目 rss = 10 # 主页个人信息 [params.home.profile] enable = true # Gravatar 邮箱，用于优先在主页显示的头像 gravatarEmail = \"\" # 主页显示头像的 URL avatarURL = \"/images/avatar.png\" # 主页显示的网站标题 (支持 HTML 格式) title = \"\" # 主页显示的网站副标题 (允许 HTML 格式) subtitle = \"这是我的全新 Hugo 网站\" # 是否为副标题显示打字机动画 typeit = true # 是否显示社交账号 social = true # 免责声明 (支持 HTML 格式) disclaimer = \"\" # 主页文章列表 [params.home.posts] enable = true # 主页每页显示文章数量 paginate = 6 # 被 params.page 中的 hiddenFromHomePage 替代 # 当你没有在文章前置参数中设置 \"hiddenFromHomePage\" 时的默认行为 defaultHiddenFromHomePage = false # 作者的社交信息设置 [params.social] GitHub = \"xxxx\" Linkedin = \"\" Twitter = \"xxxx\" Instagram = \"xxxx\" Facebook = \"xxxx\" Telegram = \"xxxx\" Medium = \"\" Gitlab = \"\" Youtubelegacy = \"\" Youtubecustom = \"\" Youtu","date":"2020-03-06","objectID":"/theme-documentation-basics/:3:1","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"3.2 网站图标, 浏览器配置, 网站清单 强烈建议你把: apple-touch-icon.png (180x180) favicon-32x32.png (32x32) favicon-16x16.png (16x16) mstile-150x150.png (150x150) android-chrome-192x192.png (192x192) android-chrome-512x512.png (512x512) 放在 /static 目录. 利用 https://realfavicongenerator.net/ 可以很容易地生成这些文件. 可以自定义 browserconfig.xml 和 site.webmanifest 文件来设置 theme-color 和 background-color. ","date":"2020-03-06","objectID":"/theme-documentation-basics/:3:2","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"3.3 自定义样式 注意\rHugo extended 版本对于自定义样式是必需的.\r通过定义自定义 .scss 样式文件, LoveIt 主题支持可配置的样式. 包含自定义 .scss 样式文件的目录相对于 你的项目根目录 的路径为 assets/css. 在 assets/css/_override.scss 中, 你可以覆盖 themes/LoveIt/assets/css/_variables.scss 中的变量以自定义样式. 这是一个例子: @import url('https://fonts.googleapis.com/css?family=Fira+Mono:400,700\u0026display=swap\u0026subset=latin-ext'); $code-font-family: Fira Mono, Source Code Pro, Menlo, Consolas, Monaco, monospace; 在 assets/css/_custom.scss 中, 你可以添加一些 CSS 样式代码以自定义样式. ","date":"2020-03-06","objectID":"/theme-documentation-basics/:3:3","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"4 多语言和 i18n LoveIt 主题完全兼容 Hugo 的多语言模式, 并且支持在网页上切换语言. 语言切换\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:4:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"4.1 兼容性 语言 Hugo 代码 HTML lang 属性 主题文档 Lunr.js 支持 英语 en en 简体中文 zh-cn zh-CN 繁體中文 zh-tw zh-TW 法语 fr fr 波兰语 pl pl 巴西葡萄牙语 pt-br pt-BR 意大利语 it it 西班牙语 es es 德语 de de 塞尔维亚语 pl pl 俄语 ru ru 罗马尼亚语 ro ro 越南语 vi vi 阿拉伯语 ar ar 加泰罗尼亚语 ca ca 泰语 th th 泰卢固语 te te 印尼语 id id 土耳其语 tr tr 韩语 ko ko 印地语 hi hi ","date":"2020-03-06","objectID":"/theme-documentation-basics/:4:1","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"4.2 基本配置 学习了 Hugo如何处理多语言网站 之后, 请在 站点配置 中定义你的网站语言. 例如, 一个支持英语, 中文和法语的网站配置: # 设置默认的语言 [\"en\", \"zh-cn\", \"fr\", \"pl\", ...] defaultContentLanguage = \"zh-cn\" [languages] [languages.en] weight = 1 title = \"My New Hugo Site\" languageCode = \"en\" languageName = \"English\" [[languages.en.menu.main]] weight = 1 identifier = \"posts\" pre = \"\" post = \"\" name = \"Posts\" url = \"/posts/\" title = \"\" [[languages.en.menu.main]] weight = 2 identifier = \"tags\" pre = \"\" post = \"\" name = \"Tags\" url = \"/tags/\" title = \"\" [[languages.en.menu.main]] weight = 3 identifier = \"categories\" pre = \"\" post = \"\" name = \"Categories\" url = \"/categories/\" title = \"\" [languages.zh-cn] weight = 2 title = \"我的全新 Hugo 网站\" languageCode = \"zh-CN\" languageName = \"简体中文\" hasCJKLanguage = true [[languages.zh-cn.menu.main]] weight = 1 identifier = \"posts\" pre = \"\" post = \"\" name = \"文章\" url = \"/posts/\" title = \"\" [[languages.zh-cn.menu.main]] weight = 2 identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" [[languages.zh-cn.menu.main]] weight = 3 identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" [languages.fr] weight = 3 title = \"Mon nouveau site Hugo\" languageCode = \"fr\" languageName = \"Français\" [[languages.fr.menu.main]] weight = 1 identifier = \"posts\" pre = \"\" post = \"\" name = \"Postes\" url = \"/posts/\" title = \"\" [[languages.fr.menu.main]] weight = 2 identifier = \"tags\" pre = \"\" post = \"\" name = \"Balises\" url = \"/tags/\" title = \"\" [[languages.fr.menu.main]] weight = 3 identifier = \"categories\" pre = \"\" post = \"\" name = \"Catégories\" url = \"/categories/\" title = \"\" 然后, 对于每个新页面, 将语言代码附加到文件名中. 单个文件 my-page.md 需要分为三个文件: 英语: my-page.en.md 中文: my-page.zh-cn.md 法语: my-page.fr.md 注意\r请注意, 菜单中仅显示翻译的页面. 它不会替换为默认语言内容.\r技巧\r也可以使用 文章前置参数 来翻译网址.\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:4:2","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"4.3 修改默认的翻译字符串 翻译字符串用于在主题中使用的常见默认值. 目前提供一些语言的翻译, 但你可能自定义其他语言或覆盖默认值. 要覆盖默认值, 请在你项目的 i18n 目录 i18n/\u003clanguageCode\u003e.toml 中创建一个新文件，并从 themes/LoveIt/i18n/en.toml 中获得提示. 另外, 由于你的翻译可能会帮助到其他人, 请花点时间通过  创建一个 PR 来贡献主题翻译, 谢谢! ","date":"2020-03-06","objectID":"/theme-documentation-basics/:4:3","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"5 搜索 基于 Lunr.js 或 algolia, LoveIt 主题支持搜索功能. ","date":"2020-03-06","objectID":"/theme-documentation-basics/:5:0","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"5.1 输出配置 为了生成搜索功能所需要的 index.json, 请在你的 网站配置 中添加 JSON 输出文件类型到 outputs 部分的 home 字段中. [outputs] home = [\"HTML\", \"RSS\", \"JSON\"] ","date":"2020-03-06","objectID":"/theme-documentation-basics/:5:1","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"5.2 搜索配置 基于 Hugo 生成的 index.json 文件, 你可以激活搜索功能. 这是你的 网站配置 中的搜索部分: [params.search] enable = true # 搜索引擎的类型 [\"lunr\", \"algolia\"] type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" 怎样选择搜索引擎?\r以下是两种搜索引擎的对比: lunr: 简单, 无需同步 index.json, 没有 contentLength 的限制, 但占用带宽大且性能低 (特别是中文需要一个较大的分词依赖库) algolia: 高性能并且占用带宽低, 但需要同步 index.json 且有 contentLength 的限制 文章内容被 h2 和 h3 HTML 标签切分来提高查询效果并且基本实现全文搜索. contentLength 用来限制 h2 和 h3 HTML 标签开头的内容部分的最大长度. 关于 algolia 的使用技巧\r你需要上传 index.json 到 algolia 来激活搜索功能. 你可以使用浏览器来上传 index.json 文件但是一个自动化的脚本可能效果更好. 官方提供的 Algolia CLI 是一个不错的选择. 为了兼容 Hugo 的多语言模式, 你需要上传不同语言的 index.json 文件到对应的 algolia index, 例如 zh-cn/index.json 或 fr/index.json…\r","date":"2020-03-06","objectID":"/theme-documentation-basics/:5:2","tags":["installation","configuration"],"title":"主题文档 - 基本概念","uri":"/theme-documentation-basics/"},{"categories":["documentation"],"content":"了解如何在 LoveIt 主题中快速, 直观地创建和组织内容.","date":"2020-03-05","objectID":"/theme-documentation-content/","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"了解如何在 LoveIt 主题中快速, 直观地创建和组织内容. ","date":"2020-03-05","objectID":"/theme-documentation-content/:0:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"1 内容组织 以下是一些方便你清晰管理和生成文章的目录结构建议: 保持博客文章存放在 content/posts 目录, 例如: content/posts/我的第一篇文章.md 保持简单的静态页面存放在 content 目录, 例如: content/about.md 本地资源组织 本地资源引用\r有三种方法来引用图片和音乐等本地资源: 使用页面包中的页面资源. 你可以使用适用于 Resources.GetMatch 的值或者直接使用相对于当前页面目录的文件路径来引用页面资源. 将本地资源放在 assets 目录中, 默认路径是 /assets. 引用资源的文件路径是相对于 assets 目录的. 将本地资源放在 static 目录中, 默认路径是 /static. 引用资源的文件路径是相对于 static 目录的. 引用的优先级符合以上的顺序. 在这个主题中的很多地方可以使用上面的本地资源引用, 例如 链接, 图片, image shortcode, music shortcode 和前置参数中的部分参数. 页面资源或者 assets 目录中的图片处理会在未来的版本中得到支持. 非常酷的功能! ","date":"2020-03-05","objectID":"/theme-documentation-content/:1:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"2 前置参数 Hugo 允许你在文章内容前面添加 yaml, toml 或者 json 格式的前置参数. 注意\r不是所有的以下前置参数都必须在你的每篇文章中设置. 只有在文章的参数和你的 网站设置 中的 page 部分不一致时才有必要这么做.\r这是一个前置参数例子: --- title: \"我的第一篇文章\" subtitle: \"\" date: 2020-03-04T15:58:26+08:00 lastmod: 2020-03-04T15:58:26+08:00 draft: true author: \"\" authorLink: \"\" description: \"\" license: \"\" images: [] tags: [] categories: [] featuredImage: \"\" featuredImagePreview: \"\" hiddenFromHomePage: false hiddenFromSearch: false twemoji: false lightgallery: true ruby: true fraction: true fontawesome: true linkToMarkdown: true rssFullText: false toc: enable: true auto: true code: copy: true maxShownLines: 50 math: enable: false # ... mapbox: # ... share: enable: true # ... comment: enable: true # ... library: css: # someCSS = \"some.css\" # 位于 \"assets/\" # 或者 # someCSS = \"https://cdn.example.com/some.css\" js: # someJS = \"some.js\" # 位于 \"assets/\" # 或者 # someJS = \"https://cdn.example.com/some.js\" seo: images: [] # ... --- title: 文章标题. subtitle: 文章副标题. date: 这篇文章创建的日期时间. 它通常是从文章的前置参数中的 date 字段获取的, 但是也可以在 网站配置 中设置. lastmod: 上次修改内容的日期时间. draft: 如果设为 true, 除非 hugo 命令使用了 --buildDrafts/-D 参数, 这篇文章不会被渲染. author: 文章作者. authorLink: 文章作者的链接. description: 文章内容的描述. license: 这篇文章特殊的许可. images: 页面图片, 用于 Open Graph 和 Twitter Cards. tags: 文章的标签. categories: 文章所属的类别. featuredImage: 文章的特色图片. featuredImagePreview: 用在主页预览的文章特色图片. hiddenFromHomePage: 如果设为 true, 这篇文章将不会显示在主页上. hiddenFromSearch: 如果设为 true, 这篇文章将不会显示在搜索结果中. twemoji: 如果设为 true, 这篇文章会使用 twemoji. lightgallery: 如果设为 true, 文章中的图片将可以按照画廊形式呈现. ruby: 如果设为 true, 这篇文章会使用 上标注释扩展语法. fraction: 如果设为 true, 这篇文章会使用 分数扩展语法. fontawesome: 如果设为 true, 这篇文章会使用 Font Awesome 扩展语法. linkToMarkdown: 如果设为 true, 内容的页脚将显示指向原始 Markdown 文件的链接. rssFullText: 如果设为 true, 在 RSS 中将会显示全文内容. toc: 和 网站配置 中的 params.page.toc 部分相同. code: 和 网站配置 中的 params.page.code 部分相同. math: 和 网站配置 中的 params.page.math 部分相同. mapbox: 和 网站配置 中的 params.page.mapbox 部分相同. share: 和 网站配置 中的 params.page.share 部分相同. comment: 和 网站配置 中的 params.page.comment 部分相同. library: 和 网站配置 中的 params.page.library 部分相同. seo: 和 网站配置 中的 params.page.seo 部分相同. 技巧\rfeaturedImage 和 featuredImagePreview 支持本地资源引用的完整用法. 如果带有在前置参数中设置了 name: featured-image 或 name: featured-image-preview 属性的页面资源, 没有必要在设置 featuredImage 或 featuredImagePreview: resources: - name: featured-image src: featured-image.jpg - name: featured-image-preview src: featured-image-preview.jpg ","date":"2020-03-05","objectID":"/theme-documentation-content/:2:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"3 内容摘要 LoveIt 主题使用内容摘要在主页中显示大致文章信息。Hugo 支持生成文章的摘要. 文章摘要预览\r","date":"2020-03-05","objectID":"/theme-documentation-content/:3:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"自动摘要拆分 默认情况下, Hugo 自动将内容的前 70 个单词作为摘要. 你可以通过在 网站配置 中设置 summaryLength 来自定义摘要长度. 如果您要使用 CJK中文/日语/韩语 语言创建内容, 并且想使用 Hugo 的自动摘要拆分功能，请在 网站配置 中将 hasCJKLanguage 设置为 true. ","date":"2020-03-05","objectID":"/theme-documentation-content/:3:1","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"手动摘要拆分 另外, 你也可以添加 \u003c!--more--\u003e 摘要分割符来拆分文章生成摘要. 摘要分隔符之前的内容将用作该文章的摘要. 注意\r请小心输入\u003c!--more--\u003e ; 即全部为小写且没有空格.\r","date":"2020-03-05","objectID":"/theme-documentation-content/:3:2","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"前置参数摘要 你可能希望摘要不是文章开头的文字. 在这种情况下, 你可以在文章前置参数的 summary 变量中设置单独的摘要. ","date":"2020-03-05","objectID":"/theme-documentation-content/:3:3","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"使用文章描述作为摘要 你可能希望将文章前置参数中的 description 变量的内容作为摘要. 你仍然需要在文章开头添加 \u003c!--more--\u003e 摘要分割符. 将摘要分隔符之前的内容保留为空. 然后 LoveIt 主题会将你的文章描述作为摘要. ","date":"2020-03-05","objectID":"/theme-documentation-content/:3:4","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"摘要选择的优先级顺序 由于可以通过多种方式指定摘要, 因此了解顺序很有用. 如下: 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 但分隔符之前没有内容, 则使用描述作为摘要. 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 则将按照手动摘要拆分的方法获得摘要. 如果文章前置参数中有摘要变量, 那么将以该值作为摘要. 按照自动摘要拆分方法. 注意\r不建议在摘要内容中包含富文本块元素, 这会导致渲染错误. 例如代码块, 图片, 表格等.\r","date":"2020-03-05","objectID":"/theme-documentation-content/:3:5","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"4 Markdown 基本语法 这部分内容在 Markdown 基本语法页面 中介绍. ","date":"2020-03-05","objectID":"/theme-documentation-content/:4:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"5 Markdown 扩展语法 LoveIt 主题提供了一些扩展的语法便于你撰写文章. ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:0","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"Emoji 支持 这部分内容在 Emoji 支持页面 中介绍. ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:1","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"数学公式 LoveIt 基于 $\\KaTeX$ 提供数学公式的支持. 在你的 网站配置 中的 [params.math] 下面设置属性 enable = true, 并在文章的前置参数中设置属性 math: true来启用数学公式的自动渲染. $\\KaTeX$ 根据 特定的分隔符 来自动渲染公式. 技巧\r有一份 $\\KaTeX$ 中支持的 $\\TeX$ 函数 清单.\r注意\r由于 Hugo 在渲染 Markdown 文档时会根据 _/*/\u003e\u003e 之类的语法生成 HTML 文档, 并且有些转义字符形式的文本内容 (如 \\(/\\)/\\[/\\]/\\\\) 会自动进行转义处理, 因此需要对这些地方进行额外的转义字符表达来实现自动渲染: _ -\u003e \\_ * -\u003e \\* \u003e\u003e -\u003e \\\u003e\u003e \\( -\u003e \\\\( \\) -\u003e \\\\) \\[ -\u003e \\\\[ \\] -\u003e \\\\] \\\\ -\u003e \\\\\\\\ LoveIt 主题支持 raw shortcode 以避免这些转义字符, 它可以帮助您编写原始数学公式内容. 一个 raw 示例: 行内公式: 公式块: 呈现的输出效果如下: 行内公式: 公式块: 行内公式 默认的行内公式分割符有: $ ... $ \\( ... \\) (转义的: \\\\( ... \\\\)) 例如: $c = \\pm\\sqrt{a^2 + b^2}$ 和 \\\\(f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi\\\\) 呈现的输出效果如下: $c = \\pm\\sqrt{a^2 + b^2}$ 和 \\(f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi\\) 公式块 默认的公式块分割符有: $$ ... $$ \\[ ... \\] (转义的: \\\\[ ... \\\\]) \\begin{equation} ... \\end{equation} (不编号的: \\begin{equation*} ... \\end{equation*}) \\begin{align} ... \\end{align} (不编号的: \\begin{align*} ... \\end{align*}) \\begin{alignat} ... \\end{alignat} (不编号的: \\begin{alignat*} ... \\end{alignat*}) \\begin{gather} ... \\end{gather} (不编号的: \\begin{gather*} ... \\end{gather*}) \\begin{CD} ... \\end{CD} 例如: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\\\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\\\] \\begin{equation*} \\rho \\frac{\\mathrm{D} \\mathbf{v}}{\\mathrm{D} t}=\\nabla \\cdot \\mathbb{P}+\\rho \\mathbf{f} \\end{equation*} \\begin{equation} \\mathbf{E}=\\sum_{i} \\mathbf{E}\\_{i}=\\mathbf{E}\\_{1}+\\mathbf{E}\\_{2}+\\mathbf{E}_{3}+\\cdots \\end{equation} \\begin{align} a\u0026=b+c \\\\\\\\ d+e\u0026=f \\end{align} \\begin{alignat}{2} 10\u0026x+\u00263\u0026y = 2 \\\\\\\\ 3\u0026x+\u002613\u0026y = 4 \\end{alignat} \\begin{gather} a=b \\\\\\\\ e=b+c \\end{gather} \\begin{CD} A @\u003ea\\\u003e\u003e B \\\\\\\\ @VbVV @AAcA \\\\\\\\ C @= D \\end{CD} 呈现的输出效果如下: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\] \\begin{equation*} \\rho \\frac{\\mathrm{D} \\mathbf{v}}{\\mathrm{D} t}=\\nabla \\cdot \\mathbb{P}+\\rho \\mathbf{f} \\end{equation*} \\begin{equation} \\mathbf{E}=\\sum_{i} \\mathbf{E}_{i}=\\mathbf{E}_{1}+\\mathbf{E}_{2}+\\mathbf{E}_{3}+\\cdots \\end{equation} \\begin{align} a\u0026=b+c \\\\ d+e\u0026=f \\end{align} \\begin{alignat}{2} 10\u0026x+\u00263\u0026y = 2 \\\\ 3\u0026x+\u002613\u0026y = 4 \\end{alignat} \\begin{gather} a=b \\\\ e=b+c \\end{gather} \\begin{CD} A @\u003ea\u003e\u003e B \\\\ @VbVV @AAcA \\\\ C @= D \\end{CD} 技巧\r你可以在 网站配置 中自定义行内公式和公式块的分割符.\rCopy-tex Copy-tex 是一个 $\\KaTeX$ 的插件. 通过这个扩展, 在选择并复制 $\\KaTeX$ 渲染的公式时, 会将其 $\\LaTeX$ 源代码复制到剪贴板. 在你的 网站配置 中的 [params.math] 下面设置属性 copyTex = true 来启用 Copy-tex. 选择并复制上一节中渲染的公式, 可以发现复制的内容为 $\\LaTeX$ 源代码. mhchem mhchem 是一个 $\\KaTeX$ 的插件. 通过这个扩展, 你可以在文章中轻松编写漂亮的化学方程式. 在你的 网站配置 中的 [params.math] 下面设置属性 mhchem = true 来启用 mhchem. $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ 呈现的输出效果如下: $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:2","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"字符注音或者注释 LoveIt 主题支持一种 字符注音或者注释 Markdown 扩展语法: [Hugo]^(一个开源的静态网站生成工具) 呈现的输出效果如下: Hugo一个开源的静态网站生成工具 ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:3","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"分数 LoveIt 主题支持一种 分数 Markdown 扩展语法: [浅色]/[深色] [99]/[100] 呈现的输出效果如下: 浅色/深色 90/100 ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:4","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"Font Awesome LoveIt 主题使用 Font Awesome 作为图标库. 你同样可以在文章中轻松使用这些图标. 从 Font Awesome 网站 上获取所需的图标 class. 去露营啦! :(fas fa-campground fa-fw): 很快就回来. 真开心! :(far fa-grin-tears): 呈现的输出效果如下: 去露营啦!  很快就回来. 真开心! ","date":"2020-03-05","objectID":"/theme-documentation-content/:5:5","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"转义字符 在某些特殊情况下 (编写这个主题文档时 ), 你的文章内容会与 Markdown 的基本或者扩展语法冲突, 并且无法避免. 转义字符语法可以帮助你渲染出想要的内容: 呈现的输出效果如下: :joy: 而不是 😂 技巧\r这个方法可以间接解决一个还未解决的 Hugo 的 issue.\r","date":"2020-03-05","objectID":"/theme-documentation-content/:5:6","tags":["content","Markdown"],"title":"主题文档 - 内容","uri":"/theme-documentation-content/"},{"categories":["documentation"],"content":"Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁.","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁. Hugo 使用 Markdown 为其简单的内容格式. 但是, Markdown 在很多方面都无法很好地支持. 你可以使用纯 HTML 来扩展可能性. 但这恰好是一个坏主意. 大家使用 Markdown, 正是因为它即使不经过渲染也可以轻松阅读. 应该尽可能避免使用 HTML 以保持内容简洁. 为了避免这种限制, Hugo 创建了 shortcodes. shortcode 是一个简单代码段, 可以生成合理的 HTML 代码, 并且符合 Markdown 的设计哲学. Hugo 附带了一组预定义的 shortcodes, 它们实现了一些非常常见的用法. 提供这些 shortcodes 是为了方便保持你的 Markdown 内容简洁. ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:0:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"1 figure figure 的文档 一个 figure 示例: {{\u003c figure src=\"/images/lighthouse.jpg\" title=\"Lighthouse (figure)\" \u003e}} 呈现的输出效果如下: Lighthouse (figure) 输出的 HTML 看起来像这样: \u003cfigure\u003e \u003cimg src=\"/images/lighthouse.jpg\"/\u003e \u003cfigcaption\u003e \u003ch4\u003eLighthouse (figure)\u003c/h4\u003e \u003c/figcaption\u003e \u003c/figure\u003e ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:1:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"2 gist gist 的文档 一个 gist 示例: {{\u003c gist spf13 7896402 \u003e}} 呈现的输出效果如下: 输出的 HTML 看起来像这样: \u003cscript type=\"application/javascript\" src=\"https://gist.github.com/spf13/7896402.js\"\u003e\u003c/script\u003e ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:2:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"3 highlight highlight 的文档 一个 highlight 示例: {{\u003c highlight html \u003e}} \u003csection id=\"main\"\u003e \u003cdiv\u003e \u003ch1 id=\"title\"\u003e{{ .Title }}\u003c/h1\u003e {{ range .Pages }} {{ .Render \"summary\"}} {{ end }} \u003c/div\u003e \u003c/section\u003e {{\u003c /highlight \u003e}} 呈现的输出效果如下: \u003csection id=\"main\"\u003e \u003cdiv\u003e \u003ch1 id=\"title\"\u003e{{ .Title }}\u003c/h1\u003e {{ range .Pages }} {{ .Render \"summary\"}} {{ end }} \u003c/div\u003e \u003c/section\u003e ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:3:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"4 instagram instagram 的文档 Instagram’s API was deprecated since October 24th, 2020\rThe instagram-shortcode refers an endpoint of Instagram’s API, that’s deprecated since October 24th, 2020. Thus, no images can be fetched from this API endpoint, resulting in an error when the instagram-shortcode is used. For more information please have a look at GitHub issue #7879.\r","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:4:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"5 param param 的文档 一个 param 示例: {{\u003c param description \u003e}} 呈现的输出效果如下: Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁. ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:5:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"6 ref 和 relref ref 和 relref 的文档 ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:6:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"7 tweet tweet 的文档 一个 tweet 示例: {{\u003c tweet 917359331535966209 \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:7:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"8 vimeo vimeo 的文档 一个 vimeo 示例: {{\u003c vimeo 146022717 \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:8:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"9 youtube youtube 的文档 一个 youtube 示例: {{\u003c youtube w7Ft2ymGmfc \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/theme-documentation-built-in-shortcodes/:9:0","tags":["shortcodes"],"title":"主题文档 - 内置 Shortcodes","uri":"/theme-documentation-built-in-shortcodes/"},{"categories":["documentation"],"content":"LoveIt 主题在 Hugo 内置的 shortcode 的基础上提供多个扩展的 shortcode.","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"LoveIt 主题在 Hugo 内置的 shortcode 的基础上提供多个扩展的 shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:0:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"1 style 注意\rHugo extended 版本对于 style shortcode 是必需的.\rstyle shortcode 用来在你的文章中插入自定义样式. style shortcode 有两个位置参数. 第一个参数是自定义样式的内容. 它支持  SASS 中的嵌套语法, 并且 \u0026 指代这个父元素. 第二个参数是包裹你要更改样式的内容的 HTML 标签, 默认值是 div. 一个 style 示例: ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:1:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"2 link link shortcode 是 Markdown 链接语法 的替代. link shortcode 可以提供一些其它的功能并且可以在代码块中使用. 支持本地资源引用的完整用法. link shortcode 有以下命名参数: href [必需] (第一个位置参数) 链接的目标. content [可选] (第二个位置参数) 链接的内容, 默认值是 href 参数的值. 支持 Markdown 或者 HTML 格式. title [可选] (第三个位置参数) HTML a 标签 的 title 属性, 当悬停在链接上会显示的提示. rel [可选] HTML a 标签 的 rel 补充属性. class [可选] HTML a 标签 的 class 属性. 一个 link 示例: {{\u003c link \"https://assemble.io\" \u003e}} 或者 {{\u003c link href=\"https://assemble.io\" \u003e}} {{\u003c link \"mailto:contact@revolunet.com\" \u003e}} 或者 {{\u003c link href=\"mailto:contact@revolunet.com\" \u003e}} {{\u003c link \"https://assemble.io\" Assemble \u003e}} 或者 {{\u003c link href=\"https://assemble.io\" content=Assemble \u003e}} 呈现的输出效果如下: https://assemble.io mailto:contact@revolunet.com Assemble 一个带有标题的 link 示例: {{\u003c link \"https://github.com/upstage/\" Upstage \"Visit Upstage!\" \u003e}} 或者 {{\u003c link href=\"https://github.com/upstage/\" content=Upstage title=\"Visit Upstage!\" \u003e}} 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:2:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"3 image image shortcode 是 figure shortcode 的替代. image shortcode 可以充分利用 lazysizes 和 lightGallery 两个依赖库. 支持本地资源引用的完整用法. image shortcode 有以下命名参数: src [必需] (第一个位置参数) 图片的 URL. alt [可选] (第二个位置参数) 图片无法显示时的替代文本, 默认值是 src 参数的值. 支持 Markdown 或者 HTML 格式. caption [可选] (第三个位置参数) 图片标题. 支持 Markdown 或者 HTML 格式. title [可选] 当悬停在图片上会显示的提示. class [可选] HTML figure 标签的 class 属性. src_s [可选] 图片缩略图的 URL, 用在画廊模式中, 默认值是 src 参数的值. src_l [可选] 高清图片的 URL, 用在画廊模式中, 默认值是 src 参数的值. height [可选] 图片的 height 属性. width [可选] 图片的 width 属性. linked [可选] 图片是否需要被链接, 默认值是 true. rel [可选] HTML a 标签 的 rel 补充属性, 仅在 linked 属性设置成 true 时有效. 一个 image 示例: {{\u003c image src=\"/images/lighthouse.jpg\" caption=\"Lighthouse (`image`)\" src_s=\"/images/lighthouse-small.jpg\" src_l=\"/images/lighthouse-large.jpg\" \u003e}} 呈现的输出效果如下: Lighthouse (image)\r","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:3:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"4 admonition admonition shortcode 支持 12 种 帮助你在页面中插入提示的横幅. 支持 Markdown 或者 HTML 格式. 注意\r一个 注意 横幅\r摘要\r一个 摘要 横幅\r信息\r一个 信息 横幅\r技巧\r一个 技巧 横幅\r成功\r一个 成功 横幅\r问题\r一个 问题 横幅\r警告\r一个 警告 横幅\r失败\r一个 失败 横幅\r危险\r一个 危险 横幅\rBug\r一个 Bug 横幅\r示例\r一个 示例 横幅\r引用\r一个 引用 横幅\radmonition shortcode 有以下命名参数: type [可选] (第一个位置参数) admonition 横幅的类型, 默认值是 note. title [可选] (第二个位置参数) admonition 横幅的标题, 默认值是 type 参数的值. open [可选] (第三个位置参数) 横幅内容是否默认展开, 默认值是 true. 一个 admonition 示例: {{\u003c admonition type=tip title=\"This is a tip\" open=false \u003e}} 一个 **技巧** 横幅 {{\u003c /admonition \u003e}} 或者 {{\u003c admonition tip \"This is a tip\" false \u003e}} 一个 **技巧** 横幅 {{\u003c /admonition \u003e}} 呈现的输出效果如下: This is a tip\r一个 技巧 横幅\r","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:4:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"5 mermaid mermaid shortcode 使用 Mermaid 库提供绘制图表和流程图的功能. 完整文档请查看页面 主题文档 - mermaid Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:5:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"6 echarts echarts shortcode 使用 ECharts 库提供数据可视化的功能. 完整文档请查看页面 主题文档 - echarts Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:6:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"7 mapbox mapbox shortcode 使用 Mapbox GL JS 库提供互动式地图的功能. 完整文档请查看页面 主题文档 - mapbox Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:7:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"8 music music shortcode 基于 APlayer 和 MetingJS 库提供了一个内嵌的响应式音乐播放器. 完整文档请查看页面 主题文档 - music Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:8:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"9 bilibili bilibili shortcode 提供了一个内嵌的用来播放 bilibili 视频的响应式播放器. 完整文档请查看页面 主题文档 - bilibili Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:9:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"10 typeit typeit shortcode 基于 TypeIt 库提供了打字动画. 完整文档请查看页面 主题文档 - typeit Shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:10:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"11 script script shortcode 用来在你的文章中插入  Javascript 脚本. 注意\r脚本内容可以保证在所有的第三方库加载之后按顺序执行. 所以你可以自由地使用第三方库.\r一个 script 示例: {{\u003c script \u003e}} console.log('Hello LoveIt!'); {{\u003c /script \u003e}} 你可以在开发者工具的控制台中看到输出. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:11:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"12 raw raw shortcode 用来在你的文章中插入原始  HTML 内容. 一个 raw 示例: 行内公式: {{\u003c raw \u003e}}\\(\\mathbf{E}=\\sum_{i} \\mathbf{E}_{i}=\\mathbf{E}_{1}+\\mathbf{E}_{2}+\\mathbf{E}_{3}+\\cdots\\){{\u003c /raw \u003e}} 公式块: {{\u003c raw \u003e}} \\[ a=b+c \\\\ d+e=f \\] {{\u003c /raw \u003e}} 原始的带有 Markdown 语法的内容: {{\u003c raw \u003e}}**Hello**{{\u003c /raw \u003e}} 呈现的输出效果如下: 行内公式: 公式块: 原始的带有 Markdown 语法的内容: ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:12:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["documentation"],"content":"13 person person shortcode 用来在你的文章中以 h-card 的格式插入个人网站链接. person shortcode 有以下命名参数: url [必需] (第一个位置参数) URL of the personal page. name [必需] (第二个位置参数) Name of the person. text [可选] (第三个位置参数) Text to display as hover tooltip of the link. picture [可选] (第四个位置参数) A picture to use as person’s avatar. nick [可选] Nickame of the person. 一个 person 示例: {{\u003c person url=\"https://evgenykuznetsov.org\" name=\"Evgeny Kuznetsov\" nick=\"nekr0z\" text=\"author of this shortcode\" picture=\"https://evgenykuznetsov.org/img/avatar.jpg\" \u003e}} 呈现的输出效果为  Evgeny Kuznetsov (nekr0z). 一个使用通用图标的 person 示例: {{\u003c person \"https://dillonzq.com/\" Dillon \"author of the LoveIt theme\" \u003e}} 呈现的输出效果为  Dillon. ","date":"2020-03-03","objectID":"/theme-documentation-extended-shortcodes/:13:0","tags":["shortcodes"],"title":"主题文档 - 扩展 Shortcodes","uri":"/theme-documentation-extended-shortcodes/"},{"categories":["Markdown"],"content":"这篇文章展示了基本的 Markdown 语法和格式.","date":"2019-12-01","objectID":"/basic-markdown-syntax/","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意\r这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧\r 将此页保存为书签，以备将来参考!\r","date":"2019-12-01","objectID":"/basic-markdown-syntax/:0:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID\r要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:1:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:2:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:3:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:4:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:5:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"6 强调 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:6:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:7:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"8 列表 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧\r如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:8:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"9 代码 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments\rline 1 of code\rline 2 of code\rline 3 of code\r输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意\rHugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode.\r","date":"2019-12-01","objectID":"/basic-markdown-syntax/:9:4","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐\r在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:10:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"11 链接 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:1","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:2","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意\r定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了.\r","date":"2019-12-01","objectID":"/basic-markdown-syntax/:11:3","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:12:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["Markdown"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat\r像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The Dojocat\r稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧\rLoveIt 主题提供了一个包含更多功能的 图片的 shortcode.\r这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2019-12-01","objectID":"/basic-markdown-syntax/:13:0","tags":["Markdown","HTML"],"title":"Markdown 基本语法","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"mermaid shortcode 使用 Mermaid 库提供绘制图表和流程图的功能.","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":" mermaid shortcode 使用 Mermaid 库提供绘制图表和流程图的功能. mermaid 是一个可以帮助你在文章中绘制图表和流程图的库, 类似 Markdown 的语法. 只需将你的 mermaid 代码插入 mermaid shortcode 中即可. ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"流程图 一个 流程图 mermaid 示例: {{\u003c mermaid \u003e}} graph LR; A[Hard edge] --\u003e|Link text| B(Round edge) B --\u003e C{Decision} C --\u003e|One| D[Result one] C --\u003e|Two| E[Result two] {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:1:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"时序图 一个 时序图 mermaid 示例: {{\u003c mermaid \u003e}} sequenceDiagram participant Alice participant Bob Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts \u003cbr/\u003eprevail... John--\u003eAlice: Great! John-\u003eBob: How about you? Bob--\u003eJohn: Jolly good! {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:2:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"甘特图 一个 甘特图 mermaid 示例: {{\u003c mermaid \u003e}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:3:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"类图 一个 类图 mermaid 示例: {{\u003c mermaid \u003e}} classDiagram Animal \u003c|-- Duck Animal \u003c|-- Fish Animal \u003c|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:4:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"状态图 一个 状态图 mermaid 示例: {{\u003c mermaid \u003e}} stateDiagram-v2 [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:5:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"Git 图 一个 Git 图 mermaid 示例: {{\u003c mermaid \u003e}} gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:6:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"实体关系图 一个 实体关系图 mermaid 示例: {{\u003c mermaid \u003e}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:7:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"用户体验旅程图 一个 用户体验旅程图 mermaid 示例: {{\u003c mermaid \u003e}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:8:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"饼图 一个 饼图 mermaid 示例: {{\u003c mermaid \u003e}} pie \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:9:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["documentation"],"content":"依赖图 一个 依赖图 mermaid 示例: {{\u003c mermaid \u003e}} requirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } element test_entity { type: simulation } test_entity - satisfies -\u003e test_req {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mermaid-shortcode/:10:0","tags":["shortcodes"],"title":"主题文档 - mermaid Shortcode","uri":"/theme-documentation-mermaid-shortcode/"},{"categories":["Markdown"],"content":"Hugo 和 LoveIt 中的 Emoji 的用法指南.","date":"2019-10-01","objectID":"/emoji-support/","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"Emoji 可以通过多种方式在 Hugo 项目中启用. emojify 方法可以直接在模板中调用, 或者使用行内 Shortcodes. 要全局使用 emoji, 需要在你的网站配置中设置 enableEmoji 为 true, 然后你就可以直接在文章中输入 emoji 的代码. 它们以冒号开头和结尾，并且包含 emoji 的 代码: 去露营啦! :tent: 很快就回来. 真开心! :joy: 呈现的输出效果如下: 去露营啦! ⛺ 很快就回来. 真开心! 😂 以下符号清单是 emoji 代码的非常有用的参考. ","date":"2019-10-01","objectID":"/emoji-support/:0:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"表情与情感 ","date":"2019-10-01","objectID":"/emoji-support/:1:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"笑脸表情 图标 代码 图标 代码 😀 grinning 😃 smiley 😄 smile 😁 grin 😆 laughing satisfied 😅 sweat_smile 🤣 rofl 😂 joy 🙂 slightly_smiling_face 🙃 upside_down_face 😉 wink 😊 blush 😇 innocent ","date":"2019-10-01","objectID":"/emoji-support/:1:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"爱意表情 图标 代码 图标 代码 😍 heart_eyes 😘 kissing_heart 😗 kissing ☺️ relaxed 😚 kissing_closed_eyes 😙 kissing_smiling_eyes ","date":"2019-10-01","objectID":"/emoji-support/:1:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"吐舌头表情 图标 代码 图标 代码 😋 yum 😛 stuck_out_tongue 😜 stuck_out_tongue_winking_eye 😝 stuck_out_tongue_closed_eyes 🤑 money_mouth_face ","date":"2019-10-01","objectID":"/emoji-support/:1:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"带手的表情 图标 代码 图标 代码 🤗 hugs 🤔 thinking ","date":"2019-10-01","objectID":"/emoji-support/:1:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"中性表情 图标 代码 图标 代码 🤐 zipper_mouth_face 😐 neutral_face 😑 expressionless 😶 no_mouth 😏 smirk 😒 unamused 🙄 roll_eyes 😬 grimacing 🤥 lying_face ","date":"2019-10-01","objectID":"/emoji-support/:1:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"困倦的表情 图标 代码 图标 代码 😌 relieved 😔 pensive 😪 sleepy 🤤 drooling_face 😴 sleeping ","date":"2019-10-01","objectID":"/emoji-support/:1:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"不适的表情 图标 代码 图标 代码 😷 mask 🤒 face_with_thermometer 🤕 face_with_head_bandage 🤢 nauseated_face 🤧 sneezing_face 😵 dizzy_face ","date":"2019-10-01","objectID":"/emoji-support/:1:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"戴帽子的表情 图标 代码 图标 代码 🤠 cowboy_hat_face ","date":"2019-10-01","objectID":"/emoji-support/:1:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"戴眼镜的表情 图标 代码 图标 代码 😎 sunglasses 🤓 nerd_face ","date":"2019-10-01","objectID":"/emoji-support/:1:9","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"担心的表情 图标 代码 图标 代码 😕 confused 😟 worried 🙁 slightly_frowning_face ☹ frowning_face 😮 open_mouth 😯 hushed 😲 astonished 😳 flushed 😦 frowning 😧 anguished 😨 fearful 😰 cold_sweat 😥 disappointed_relieved 😢 cry 😭 sob 😱 scream 😖 confounded 😣 persevere 😞 disappointed 😓 sweat 😩 weary 😫 tired_face ","date":"2019-10-01","objectID":"/emoji-support/:1:10","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"否定的表情 图标 代码 图标 代码 😤 triumph 😡 pout rage 😠 angry 😈 smiling_imp 👿 imp 💀 skull ☠️ skull_and_crossbones ","date":"2019-10-01","objectID":"/emoji-support/:1:11","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"特殊打扮的表情 图标 代码 图标 代码 💩 hankey poop shit 🤡 clown_face 👹 japanese_ogre 👺 japanese_goblin 👻 ghost 👽 alien 👾 space_invader 🤖 robot ","date":"2019-10-01","objectID":"/emoji-support/:1:12","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"猫脸表情 图标 代码 图标 代码 😺 smiley_cat 😸 smile_cat 😹 joy_cat 😻 heart_eyes_cat 😼 smirk_cat 😽 kissing_cat 🙀 scream_cat 😿 crying_cat_face 😾 pouting_cat ","date":"2019-10-01","objectID":"/emoji-support/:1:13","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"猴脸表情 图标 代码 图标 代码 🙈 see_no_evil 🙉 hear_no_evil 🙊 speak_no_evil ","date":"2019-10-01","objectID":"/emoji-support/:1:14","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"情感 图标 代码 图标 代码 💋 kiss 💌 love_letter 💘 cupid 💝 gift_heart 💖 sparkling_heart 💗 heartpulse 💓 heartbeat 💞 revolving_hearts 💕 two_hearts 💟 heart_decoration ❣️ heavy_heart_exclamation 💔 broken_heart ❤️ heart 💛 yellow_heart 💚 green_heart 💙 blue_heart 💜 purple_heart 🖤 black_heart 💯 100 💢 anger 💥 boom collision 💫 dizzy 💦 sweat_drops 💨 dash 🕳️ hole 💣 bomb 💬 speech_balloon 👁️‍🗨️ eye_speech_bubble 🗯️ right_anger_bubble 💭 thought_balloon 💤 zzz ","date":"2019-10-01","objectID":"/emoji-support/:1:15","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"人与身体 ","date":"2019-10-01","objectID":"/emoji-support/:2:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"张开手掌的手势 图标 代码 图标 代码 👋 wave 🤚 raised_back_of_hand 🖐️ raised_hand_with_fingers_splayed ✋ hand raised_hand 🖖 vulcan_salute ","date":"2019-10-01","objectID":"/emoji-support/:2:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"部分手指的手势 图标 代码 图标 代码 👌 ok_hand ✌️ v 🤞 crossed_fingers 🤘 metal 🤙 call_me_hand ","date":"2019-10-01","objectID":"/emoji-support/:2:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"一根手指的手势 图标 代码 图标 代码 👈 point_left 👉 point_right 👆 point_up_2 🖕 fu middle_finger 👇 point_down ☝️ point_up ","date":"2019-10-01","objectID":"/emoji-support/:2:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"握紧的手势 图标 代码 图标 代码 👍 +1 thumbsup 👎 -1 thumbsdown ✊ fist fist_raised 👊 facepunch fist_oncoming punch 🤛 fist_left 🤜 fist_right ","date":"2019-10-01","objectID":"/emoji-support/:2:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"两只手 图标 代码 图标 代码 👏 clap 🙌 raised_hands 👐 open_hands 🤝 handshake 🙏 pray ","date":"2019-10-01","objectID":"/emoji-support/:2:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"握住东西的手势 图标 代码 图标 代码 ✍️ writing_hand 💅 nail_care 🤳 selfie ","date":"2019-10-01","objectID":"/emoji-support/:2:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"身体部位 图标 代码 图标 代码 💪 muscle 👂 ear 👃 nose 👀 eyes 👁️ eye 👅 tongue 👄 lips ","date":"2019-10-01","objectID":"/emoji-support/:2:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"人 图标 代码 图标 代码 👶 baby 👦 boy 👧 girl :blonde_man: blonde_man person_with_blond_hair 👨 man 👩 woman 👱‍♀️ blonde_woman 👴 older_man 👵 older_woman ","date":"2019-10-01","objectID":"/emoji-support/:2:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"身体动作 图标 代码 图标 代码 🙍‍♀️ frowning_woman person_frowning 🙍‍♂️ frowning_man 🙎‍♀️ person_with_pouting_face pouting_woman 🙎‍♂️ pouting_man 🙅‍♀️ ng_woman no_good no_good_woman 🙅‍♂️ ng_man no_good_man 🙆‍♀️ ok_woman 🙆‍♂️ ok_man 💁‍♀️ information_desk_person sassy_woman tipping_hand_woman 💁‍♂️ sassy_man tipping_hand_man 🙋‍♀️ raising_hand raising_hand_woman 🙋‍♂️ raising_hand_man 🙇 bow bowing_man 🙇‍♀️ bowing_woman 🤦‍♂️ man_facepalming 🤦‍♀️ woman_facepalming 🤷‍♂️ man_shrugging 🤷‍♀️ woman_shrugging ","date":"2019-10-01","objectID":"/emoji-support/:2:9","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"人物角色 图标 代码 图标 代码 👨‍⚕️ man_health_worker 👩‍⚕️ woman_health_worker 👨‍🎓 man_student 👩‍🎓 woman_student 👨‍🏫 man_teacher 👩‍🏫 woman_teacher 👨‍⚖️ man_judge 👩‍⚖️ woman_judge 👨‍🌾 man_farmer 👩‍🌾 woman_farmer 👨‍🍳 man_cook 👩‍🍳 woman_cook 👨‍🔧 man_mechanic 👩‍🔧 woman_mechanic 👨‍🏭 man_factory_worker 👩‍🏭 woman_factory_worker 👨‍💼 man_office_worker 👩‍💼 woman_office_worker 👨‍🔬 man_scientist 👩‍🔬 woman_scientist 👨‍💻 man_technologist 👩‍💻 woman_technologist 👨‍🎤 man_singer 👩‍🎤 woman_singer 👨‍🎨 man_artist 👩‍🎨 woman_artist 👨‍✈️ man_pilot 👩‍✈️ woman_pilot 👨‍🚀 man_astronaut 👩‍🚀 woman_astronaut 👨‍🚒 man_firefighter 👩‍🚒 woman_firefighter 👮‍♂️ cop policeman 👮‍♀️ policewoman 🕵 detective male_detective 🕵️‍♀️ female_detective 💂‍♂️ guardsman 💂‍♀️ guardswoman 👷‍♂️ construction_worker construction_worker_man 👷‍♀️ construction_worker_woman 🤴 prince 👸 princess 👳‍♂️ man_with_turban 👳‍♀️ woman_with_turban 👲 man_with_gua_pi_mao 🤵‍♂️ man_in_tuxedo 👰 bride_with_veil 🤰 pregnant_woman ","date":"2019-10-01","objectID":"/emoji-support/:2:10","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"幻想的人物 图标 代码 图标 代码 👼 angel 🎅 santa 🤶 mrs_claus ","date":"2019-10-01","objectID":"/emoji-support/:2:11","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"人物活动 图标 代码 图标 代码 💆‍♀️ massage massage_woman 💆‍♂️ massage_man 💇‍♀️ haircut haircut_woman 💇‍♂️ haircut_man 🚶‍♂️ walking walking_man 🚶‍♀️ walking_woman 🏃‍♂️ runner running running_man 🏃‍♀️ running_woman 💃 dancer 🕺 man_dancing 🕴️ business_suit_levitating 👯‍♀️ dancers dancing_women 👯‍♂️ dancing_men ","date":"2019-10-01","objectID":"/emoji-support/:2:12","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"体育 图标 代码 图标 代码 🤺 person_fencing 🏇 horse_racing ⛷️ skier 🏂 snowboarder 🏌️‍♂️ golfing_man 🏌️‍♀️ golfing_woman 🏄‍♂️ surfer surfing_man 🏄‍♀️ surfing_woman 🚣‍♂️ rowboat rowing_man 🚣‍♀️ rowing_woman 🏊‍♂️ swimmer swimming_man 🏊‍♀️ swimming_woman ⛹️‍♂️ basketball_man ⛹️‍♀️ basketball_woman 🏋️‍♂️ weight_lifting_man 🏋️‍♀️ weight_lifting_woman 🚴‍♂️ bicyclist biking_man 🚴‍♀️ biking_woman 🚵‍♂️ mountain_bicyclist mountain_biking_man 🚵‍♀️ mountain_biking_woman 🤸‍♂️ man_cartwheeling 🤸‍♀️ woman_cartwheeling 🤼‍♂️ men_wrestling 🤼‍♀️ women_wrestling 🤽‍♂️ man_playing_water_polo 🤽‍♀️ woman_playing_water_polo 🤾‍♂️ man_playing_handball 🤾‍♀️ woman_playing_handball 🤹‍♂️ man_juggling 🤹‍♀️ woman_juggling ","date":"2019-10-01","objectID":"/emoji-support/:2:13","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"休息 图标 代码 图标 代码 🛀 bath 🛌 sleeping_bed ","date":"2019-10-01","objectID":"/emoji-support/:2:14","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"家庭 图标 代码 图标 代码 👭 two_women_holding_hands 👫 couple 👬 two_men_holding_hands 👩‍❤️‍💋‍👨 couplekiss_man_woman 👨‍❤️‍💋‍👨 couplekiss_man_man 👩‍❤️‍💋‍👩 couplekiss_woman_woman 💑 couple_with_heart couple_with_heart_woman_man 👨‍❤️‍👨 couple_with_heart_man_man 👩‍❤️‍👩 couple_with_heart_woman_woman 👨‍👩‍👦 family family_man_woman_boy 👨‍👩‍👧 family_man_woman_girl 👨‍👩‍👧‍👦 family_man_woman_girl_boy 👨‍👩‍👦‍👦 family_man_woman_boy_boy 👨‍👩‍👧‍👧 family_man_woman_girl_girl 👨‍👨‍👦 family_man_man_boy 👨‍👨‍👧 family_man_man_girl 👨‍👨‍👧‍👦 family_man_man_girl_boy 👨‍👨‍👦‍👦 family_man_man_boy_boy 👨‍👨‍👧‍👧 family_man_man_girl_girl 👩‍👩‍👦 family_woman_woman_boy 👩‍👩‍👧 family_woman_woman_girl 👩‍👩‍👧‍👦 family_woman_woman_girl_boy 👩‍👩‍👦‍👦 family_woman_woman_boy_boy 👩‍👩‍👧‍👧 family_woman_woman_girl_girl 👨‍👦 family_man_boy 👨‍👦‍👦 family_man_boy_boy 👨‍👧 family_man_girl 👨‍👧‍👦 family_man_girl_boy 👨‍👧‍👧 family_man_girl_girl 👩‍👦 family_woman_boy 👩‍👦‍👦 family_woman_boy_boy 👩‍👧 family_woman_girl 👩‍👧‍👦 family_woman_girl_boy 👩‍👧‍👧 family_woman_girl_girl ","date":"2019-10-01","objectID":"/emoji-support/:2:15","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"人物符号 图标 代码 图标 代码 🗣 speaking_head 👤 bust_in_silhouette 👥 busts_in_silhouette 👣 footprints ","date":"2019-10-01","objectID":"/emoji-support/:2:16","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"动物与自然 ","date":"2019-10-01","objectID":"/emoji-support/:3:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"哺乳动物 图标 代码 图标 代码 🐵 monkey_face 🐒 monkey 🦍 gorilla 🐶 dog 🐕 dog2 🐩 poodle 🐺 wolf 🦊 fox_face 🐱 cat 🐈 cat2 🦁 lion 🐯 tiger 🐅 tiger2 🐆 leopard 🐴 horse 🐎 racehorse 🦄 unicorn 🦌 deer 🐮 cow 🐂 ox 🐃 water_buffalo 🐄 cow2 🐷 pig 🐖 pig2 🐗 boar 🐽 pig_nose 🐏 ram 🐑 sheep 🐐 goat 🐪 dromedary_camel 🐫 camel 🐘 elephant 🦏 rhinoceros 🐭 mouse 🐁 mouse2 🐀 rat 🐹 hamster 🐰 rabbit 🐇 rabbit2 🐿️ chipmunk 🦇 bat 🐻 bear 🐨 koala 🐼 panda_face 🐾 feet paw_prints ","date":"2019-10-01","objectID":"/emoji-support/:3:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"鸟类 图标 代码 图标 代码 🦃 turkey 🐔 chicken 🐓 rooster 🐣 hatching_chick 🐤 baby_chick 🐥 hatched_chick 🐦 bird 🐧 penguin 🕊 dove 🦅 eagle 🦆 duck 🦉 owl ","date":"2019-10-01","objectID":"/emoji-support/:3:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"两栖动物 icon code icon code 🐸 frog ","date":"2019-10-01","objectID":"/emoji-support/:3:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"爬虫类 图标 代码 图标 代码 🐊 crocodile 🐢 turtle 🦎 lizard 🐍 snake 🐲 dragon_face 🐉 dragon ","date":"2019-10-01","objectID":"/emoji-support/:3:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"海洋动物 图标 代码 图标 代码 🐳 whale 🐋 whale2 🐬 dolphin flipper 🐟 fish 🐠 tropical_fish 🐡 blowfish 🦈 shark 🐙 octopus 🐚 shell ","date":"2019-10-01","objectID":"/emoji-support/:3:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"虫类 图标 代码 图标 代码 🐌 snail 🦋 butterfly 🐛 bug 🐜 ant 🐝 bee honeybee 🪲 beetle 🕷️ spider 🕸️ spider_web 🦂 scorpion ","date":"2019-10-01","objectID":"/emoji-support/:3:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"花类植物 图标 代码 图标 代码 💐 bouquet 🌸 cherry_blossom 💮 white_flower 🏵️ rosette 🌹 rose 🥀 wilted_flower 🌺 hibiscus 🌻 sunflower 🌼 blossom 🌷 tulip ","date":"2019-10-01","objectID":"/emoji-support/:3:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"其它植物 图标 代码 图标 代码 🌱 seedling 🌲 evergreen_tree 🌳 deciduous_tree 🌴 palm_tree 🌵 cactus 🌾 ear_of_rice 🌿 herb ☘️ shamrock 🍀 four_leaf_clover 🍁 maple_leaf 🍂 fallen_leaf 🍃 leaves ","date":"2019-10-01","objectID":"/emoji-support/:3:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"食物与饮料 ","date":"2019-10-01","objectID":"/emoji-support/:4:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"水果 图标 代码 图标 代码 🍇 grapes 🍈 melon 🍉 watermelon 🍊 mandarin orange tangerine 🍋 lemon 🍌 banana 🍍 pineapple 🍎 apple 🍏 green_apple 🍐 pear 🍑 peach 🍒 cherries 🍓 strawberry 🥝 kiwi_fruit 🍅 tomato ","date":"2019-10-01","objectID":"/emoji-support/:4:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"蔬菜 图标 代码 图标 代码 🥑 avocado 🍆 eggplant 🥔 potato 🥕 carrot 🌽 corn 🌶️ hot_pepper 🥒 cucumber 🍄 mushroom 🥜 peanuts 🌰 chestnut ","date":"2019-10-01","objectID":"/emoji-support/:4:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"快餐 图标 代码 图标 代码 🍞 bread 🥐 croissant 🥖 baguette_bread 🥞 pancakes 🧀 cheese 🍖 meat_on_bone 🍗 poultry_leg 🥓 bacon 🍔 hamburger 🍟 fries 🍕 pizza 🌭 hotdog 🌮 taco 🌯 burrito 🥙 stuffed_flatbread 🥚 egg 🍳 fried_egg 🥘 shallow_pan_of_food 🍲 stew 🥗 green_salad 🍿 popcorn ","date":"2019-10-01","objectID":"/emoji-support/:4:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"亚洲食物 图标 代码 图标 代码 🍱 bento 🍘 rice_cracker 🍙 rice_ball 🍚 rice 🍛 curry 🍜 ramen 🍝 spaghetti 🍠 sweet_potato 🍢 oden 🍣 sushi 🍤 fried_shrimp 🍥 fish_cake 🍡 dango ","date":"2019-10-01","objectID":"/emoji-support/:4:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"海鲜 图标 代码 图标 代码 🦀 crab 🦐 shrimp 🦑 squid ","date":"2019-10-01","objectID":"/emoji-support/:4:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"甜点 图标 代码 图标 代码 🍦 icecream 🍧 shaved_ice 🍨 ice_cream 🍩 doughnut 🍪 cookie 🎂 birthday 🍰 cake 🍫 chocolate_bar 🍬 candy 🍭 lollipop 🍮 custard 🍯 honey_pot ","date":"2019-10-01","objectID":"/emoji-support/:4:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"饮料 图标 代码 图标 代码 🍼 baby_bottle 🥛 milk_glass ☕ coffee 🍵 tea 🍶 sake 🍾 champagne 🍷 wine_glass 🍸 cocktail 🍹 tropical_drink 🍺 beer 🍻 beers 🥂 clinking_glasses 🥃 tumbler_glass ","date":"2019-10-01","objectID":"/emoji-support/:4:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"餐具 图标 代码 图标 代码 🍽️ plate_with_cutlery 🍴 fork_and_knife 🥄 spoon 🔪 hocho knife 🏺 amphora ","date":"2019-10-01","objectID":"/emoji-support/:4:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"旅游与地理 ","date":"2019-10-01","objectID":"/emoji-support/:5:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"地图 图标 代码 图标 代码 🌍 earth_africa 🌎 earth_americas 🌏 earth_asia 🌐 globe_with_meridians 🗺️ world_map 🗾 japan ","date":"2019-10-01","objectID":"/emoji-support/:5:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"地理现象 图标 代码 图标 代码 🏔 mountain_snow ⛰️ mountain 🌋 volcano 🗻 mount_fuji 🏕️ camping ⛱ beach_umbrella 🏜️ desert 🏝️ desert_island 🏞️ national_park ","date":"2019-10-01","objectID":"/emoji-support/:5:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"建筑物 图标 代码 图标 代码 🏟️ stadium 🏛️ classical_building 🏗️ building_construction 🏘 houses 🏚 derelict_house 🏠 house 🏡 house_with_garden 🏢 office 🏣 post_office 🏤 european_post_office 🏥 hospital 🏦 bank 🏨 hotel 🏩 love_hotel 🏪 convenience_store 🏫 school 🏬 department_store 🏭 factory 🏯 japanese_castle 🏰 european_castle 💒 wedding 🗼 tokyo_tower 🗽 statue_of_liberty ","date":"2019-10-01","objectID":"/emoji-support/:5:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"宗教建筑 图标 代码 图标 代码 ⛪ church 🕌 mosque 🕍 synagogue ⛩️ shinto_shrine 🕋 kaaba ","date":"2019-10-01","objectID":"/emoji-support/:5:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"其它地点 图标 代码 图标 代码 ⛲ fountain ⛺ tent 🌁 foggy 🌃 night_with_stars 🏙️ cityscape 🌄 sunrise_over_mountains 🌅 sunrise 🌆 city_sunset 🌇 city_sunrise 🌉 bridge_at_night ♨️ hotsprings 🎠 carousel_horse 🎡 ferris_wheel 🎢 roller_coaster 💈 barber 🎪 circus_tent ","date":"2019-10-01","objectID":"/emoji-support/:5:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"陆路运输 图标 代码 图标 代码 🚂 steam_locomotive 🚃 railway_car 🚄 bullettrain_side 🚅 bullettrain_front 🚆 train2 🚇 metro 🚈 light_rail 🚉 station 🚊 tram 🚝 monorail 🚞 mountain_railway 🚋 train 🚌 bus 🚍 oncoming_bus 🚎 trolleybus 🚐 minibus 🚑 ambulance 🚒 fire_engine 🚓 police_car 🚔 oncoming_police_car 🚕 taxi 🚖 oncoming_taxi 🚗 car red_car 🚘 oncoming_automobile 🚙 blue_car 🚚 truck 🚛 articulated_lorry 🚜 tractor 🏎️ racing_car 🏍 motorcycle 🛵 motor_scooter 🚲 bike 🛴 kick_scooter 🚏 busstop 🛣️ motorway 🛤️ railway_track 🛢️ oil_drum ⛽ fuelpump 🚨 rotating_light 🚥 traffic_light 🚦 vertical_traffic_light 🛑 stop_sign 🚧 construction ","date":"2019-10-01","objectID":"/emoji-support/:5:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"水路运输 图标 代码 图标 代码 ⚓ anchor ⛵ boat sailboat 🛶 canoe 🚤 speedboat 🛳️ passenger_ship ⛴️ ferry 🛥️ motor_boat 🚢 ship ","date":"2019-10-01","objectID":"/emoji-support/:5:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"空中运输 图标 代码 图标 代码 ✈️ airplane 🛩️ small_airplane 🛫 flight_departure 🛬 flight_arrival 💺 seat 🚁 helicopter 🚟 suspension_railway 🚠 mountain_cableway 🚡 aerial_tramway 🛰️ artificial_satellite 🚀 rocket ","date":"2019-10-01","objectID":"/emoji-support/:5:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"旅馆 icon code icon code 🛎️ bellhop_bell ","date":"2019-10-01","objectID":"/emoji-support/:5:9","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"时间 图标 代码 图标 代码 ⌛ hourglass ⏳ hourglass_flowing_sand ⌚ watch ⏰ alarm_clock ⏱️ stopwatch ⏲️ timer_clock 🕰️ mantelpiece_clock 🕛 clock12 🕧 clock1230 🕐 clock1 🕜 clock130 🕑 clock2 🕝 clock230 🕒 clock3 🕞 clock330 🕓 clock4 🕟 clock430 🕔 clock5 🕠 clock530 🕕 clock6 🕡 clock630 🕖 clock7 🕢 clock730 🕗 clock8 🕣 clock830 🕘 clock9 🕤 clock930 🕙 clock10 🕥 clock1030 🕚 clock11 🕦 clock1130 ","date":"2019-10-01","objectID":"/emoji-support/:5:10","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"天空与天气 图标 代码 图标 代码 🌑 new_moon 🌒 waxing_crescent_moon 🌓 first_quarter_moon 🌔 moon waxing_gibbous_moon 🌕 full_moon 🌖 waning_gibbous_moon 🌗 last_quarter_moon 🌘 waning_crescent_moon 🌙 crescent_moon 🌚 new_moon_with_face 🌛 first_quarter_moon_with_face 🌜 last_quarter_moon_with_face 🌡️ thermometer ☀️ sunny 🌝 full_moon_with_face 🌞 sun_with_face ⭐ star 🌟 star2 🌠 stars 🌌 milky_way ☁️ cloud ⛅ partly_sunny ⛈ cloud_with_lightning_and_rain 🌤 sun_behind_small_cloud 🌥 sun_behind_large_cloud 🌦 sun_behind_rain_cloud 🌧 cloud_with_rain 🌨 cloud_with_snow 🌩 cloud_with_lightning 🌪️ tornado 🌫️ fog 🌬 wind_face 🌀 cyclone 🌈 rainbow 🌂 closed_umbrella ☂️ open_umbrella ☂️ umbrella ⛱️ parasol_on_ground ⚡ zap ❄️ snowflake ☃️ snowman_with_snow ☃️ snowman ☄️ comet 🔥 fire 💧 droplet 🌊 ocean ","date":"2019-10-01","objectID":"/emoji-support/:5:11","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"活动 ","date":"2019-10-01","objectID":"/emoji-support/:6:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"事件 图标 代码 图标 代码 🎃 jack_o_lantern 🎄 christmas_tree 🎆 fireworks 🎇 sparkler ✨ sparkles 🎈 balloon 🎉 tada 🎊 confetti_ball 🎋 tanabata_tree 🎍 bamboo 🎎 dolls 🎏 flags 🎐 wind_chime 🎑 rice_scene 🎀 ribbon 🎁 gift 🎗️ reminder_ribbon 🎟 tickets 🎫 ticket ","date":"2019-10-01","objectID":"/emoji-support/:6:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"奖杯与奖牌 图标 代码 图标 代码 🎖️ medal_military 🏆 trophy 🏅 medal_sports 🥇 1st_place_medal 🥈 2nd_place_medal 🥉 3rd_place_medal ","date":"2019-10-01","objectID":"/emoji-support/:6:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"体育运动 图标 代码 图标 代码 ⚽ soccer ⚾ baseball 🏀 basketball 🏐 volleyball 🏈 football 🏉 rugby_football 🎾 tennis 🎳 bowling 🦗 cricket 🏑 field_hockey 🏒 ice_hockey 🏓 ping_pong 🏸 badminton 🥊 boxing_glove 🥋 martial_arts_uniform 🥅 goal_net ⛳ golf ⛸️ ice_skate 🎣 fishing_pole_and_fish 🎽 running_shirt_with_sash 🎿 ski ","date":"2019-10-01","objectID":"/emoji-support/:6:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"游戏 图标 代码 图标 代码 🎯 dart 🎱 8ball 🔮 crystal_ball 🎮 video_game 🕹️ joystick 🎰 slot_machine 🎲 game_die ♠️ spades ♥️ hearts ♦️ diamonds ♣️ clubs 🃏 black_joker 🀄 mahjong 🎴 flower_playing_cards ","date":"2019-10-01","objectID":"/emoji-support/:6:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"艺术与工艺 图标 代码 图标 代码 🎭 performing_arts 🖼 framed_picture 🎨 art ","date":"2019-10-01","objectID":"/emoji-support/:6:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"物品 ","date":"2019-10-01","objectID":"/emoji-support/:7:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"服装 图标 代码 图标 代码 👓 eyeglasses 🕶️ dark_sunglasses 👔 necktie 👕 shirt tshirt 👖 jeans 👗 dress 👘 kimono 👙 bikini 👚 womans_clothes 👛 purse 👜 handbag 👝 pouch 🛍️ shopping 🎒 school_satchel 👞 mans_shoe shoe 👟 athletic_shoe 👠 high_heel 👡 sandal 👢 boot 👑 crown 👒 womans_hat 🎩 tophat 🎓 mortar_board ⛑️ rescue_worker_helmet 📿 prayer_beads 💄 lipstick 💍 ring 💎 gem ","date":"2019-10-01","objectID":"/emoji-support/:7:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"声音 图标 代码 图标 代码 🔇 mute 🔈 speaker 🔉 sound 🔊 loud_sound 📢 loudspeaker 📣 mega 📯 postal_horn 🔔 bell 🔕 no_bell ","date":"2019-10-01","objectID":"/emoji-support/:7:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"音乐 图标 代码 图标 代码 🎼 musical_score 🎵 musical_note 🎶 notes 🎙️ studio_microphone 🎚️ level_slider 🎛️ control_knobs 🎤 microphone 🎧 headphones 📻 radio ","date":"2019-10-01","objectID":"/emoji-support/:7:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"乐器 图标 代码 图标 代码 🎷 saxophone 🎸 guitar 🎹 musical_keyboard 🎺 trumpet 🎻 violin 🥁 drum ","date":"2019-10-01","objectID":"/emoji-support/:7:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"电话 图标 代码 图标 代码 📱 iphone 📲 calling ☎️ phone telephone 📞 telephone_receiver 📟 pager 📠 fax ","date":"2019-10-01","objectID":"/emoji-support/:7:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"电脑 图标 代码 图标 代码 🔋 battery 🔌 electric_plug 💻 computer 🖥️ desktop_computer 🖨️ printer ⌨️ keyboard 🖱 computer_mouse 🖲️ trackball 💽 minidisc 💾 floppy_disk 💿 cd 📀 dvd ","date":"2019-10-01","objectID":"/emoji-support/:7:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"灯光与影像 图标 代码 图标 代码 🎥 movie_camera 🎞️ film_strip 📽️ film_projector 🎬 clapper 📺 tv 📷 camera 📸 camera_flash 📹 video_camera 📼 vhs 🔍 mag 🔎 mag_right 🕯️ candle 💡 bulb 🔦 flashlight 🏮 izakaya_lantern lantern ","date":"2019-10-01","objectID":"/emoji-support/:7:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"书与纸张 图标 代码 图标 代码 📔 notebook_with_decorative_cover 📕 closed_book 📖 book open_book 📗 green_book 📘 blue_book 📙 orange_book 📚 books 📓 notebook 📒 ledger 📃 page_with_curl 📜 scroll 📄 page_facing_up 📰 newspaper 🗞️ newspaper_roll 📑 bookmark_tabs 🔖 bookmark 🏷️ label ","date":"2019-10-01","objectID":"/emoji-support/:7:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"钱 图标 代码 图标 代码 💰 moneybag 💴 yen 💵 dollar 💶 euro 💷 pound 💸 money_with_wings 💳 credit_card 💹 chart ","date":"2019-10-01","objectID":"/emoji-support/:7:9","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"邮件 图标 代码 图标 代码 ✉️ email envelope 📧 📧 📨 incoming_envelope 📩 envelope_with_arrow 📤 outbox_tray 📥 inbox_tray 📦 package 📫 mailbox 📪 mailbox_closed 📬 mailbox_with_mail 📭 mailbox_with_no_mail 📮 postbox 🗳 ballot_box ","date":"2019-10-01","objectID":"/emoji-support/:7:10","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"书写 图标 代码 图标 代码 ✏️ pencil2 ✒️ black_nib 🖋 fountain_pen 🖊 pen 🖌 paintbrush 🖍 crayon 📝 memo pencil ","date":"2019-10-01","objectID":"/emoji-support/:7:11","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"办公 图标 代码 图标 代码 💼 briefcase 📁 file_folder 📂 open_file_folder 🗂️ card_index_dividers 📅 date 📆 calendar 🗒 spiral_notepad 🗓 spiral_calendar 📇 card_index 📈 chart_with_upwards_trend 📉 chart_with_downwards_trend 📊 bar_chart 📋 clipboard 📌 pushpin 📍 round_pushpin 📎 paperclip 🖇 paperclips 📏 straight_ruler 📐 triangular_ruler ✂️ scissors 🗃️ card_file_box 🗄️ file_cabinet 🗑️ wastebasket ","date":"2019-10-01","objectID":"/emoji-support/:7:12","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"锁 图标 代码 图标 代码 🔒 lock 🔓 unlock 🔏 lock_with_ink_pen 🔐 closed_lock_with_key 🔑 key 🗝️ old_key ","date":"2019-10-01","objectID":"/emoji-support/:7:13","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"工具 图标 代码 图标 代码 🔨 hammer ⛏️ pick ⚒️ hammer_and_pick 🛠️ hammer_and_wrench 🗡 dagger ⚔️ crossed_swords 🔫 gun 🏹 bow_and_arrow 🛡️ shield 🔧 wrench 🔩 nut_and_bolt ⚙️ gear 🗜 clamp ⚖ balance_scale 🔗 link ⛓️ chains ","date":"2019-10-01","objectID":"/emoji-support/:7:14","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"科学 图标 代码 图标 代码 ⚗️ alembic 🔬 microscope 🔭 telescope 🛰️ satellite ","date":"2019-10-01","objectID":"/emoji-support/:7:15","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"医疗 图标 代码 图标 代码 💉 syringe 💊 pill ","date":"2019-10-01","objectID":"/emoji-support/:7:16","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"生活用品 图标 代码 图标 代码 🚪 door 🛏️ bed 🛋️ couch_and_lamp 🚽 toilet 🚿 shower 🛁 bathtub 🛒 shopping_cart ","date":"2019-10-01","objectID":"/emoji-support/:7:17","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"其它物品 图标 代码 图标 代码 🚬 smoking ⚰️ coffin ⚱️ funeral_urn 🗿 moyai ","date":"2019-10-01","objectID":"/emoji-support/:7:18","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"符号 ","date":"2019-10-01","objectID":"/emoji-support/:8:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"交通标识 图标 代码 图标 代码 🏧 atm 🚮 put_litter_in_its_place 🚰 potable_water ♿ wheelchair 🚹 mens 🚺 womens 🚻 restroom 🚼 baby_symbol 🚾 wc 🛂 passport_control 🛃 customs 🛄 baggage_claim 🛅 left_luggage ","date":"2019-10-01","objectID":"/emoji-support/:8:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"警告 图标 代码 图标 代码 ⚠️ warning 🚸 children_crossing ⛔ no_entry 🚫 no_entry_sign 🚳 no_bicycles 🚭 no_smoking 🚯 do_not_litter 🚱 🚱 🚷 no_pedestrians 📵 no_mobile_phones 🔞 underage ☢ radioactive ☣ biohazard ","date":"2019-10-01","objectID":"/emoji-support/:8:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"箭头 图标 代码 图标 代码 ⬆️ arrow_up ↗️ arrow_upper_right ➡️ arrow_right ↘️ arrow_lower_right ⬇️ arrow_down ↙️ arrow_lower_left ⬅️ arrow_left ↖️ arrow_upper_left ↕️ arrow_up_down ↔️ left_right_arrow ↩️ leftwards_arrow_with_hook ↪️ arrow_right_hook ⤴️ arrow_heading_up ⤵️ arrow_heading_down 🔃 arrows_clockwise 🔄 arrows_counterclockwise 🔙 back 🔚 end 🔛 on 🔜 soon 🔝 top ","date":"2019-10-01","objectID":"/emoji-support/:8:3","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"宗教 图标 代码 图标 代码 🛐 place_of_worship ⚛️ atom_symbol 🕉 om ✡️ star_of_david ☸️ wheel_of_dharma ☯️ yin_yang ✝️ latin_cross ☦️ orthodox_cross ☪️ star_and_crescent ☮️ peace_symbol 🕎 menorah 🔯 six_pointed_star ","date":"2019-10-01","objectID":"/emoji-support/:8:4","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"生肖 图标 代码 图标 代码 ♈ aries ♉ taurus ♊ gemini ♋ cancer ♌ leo ♍ virgo ♎ libra ♏ scorpius ♐ sagittarius ♑ capricorn ♒ aquarius ♓ pisces ⛎ ophiuchus ","date":"2019-10-01","objectID":"/emoji-support/:8:5","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"影像符号 图标 代码 图标 代码 🔀 twisted_rightwards_arrows 🔁 repeat 🔂 repeat_one ▶️ arrow_forward ⏩ fast_forward ⏭ next_track_button ⏯ play_or_pause_button ◀️ arrow_backward ⏪ rewind ⏮️ previous_track_button 🔼 arrow_up_small ⏫ arrow_double_up 🔽 arrow_down_small ⏬ arrow_double_down ⏸ pause_button ⏹ stop_button ⏺ record_button 🎦 cinema 🔅 low_brightness 🔆 high_brightness 📶 signal_strength 📳 vibration_mode 📴 mobile_phone_off ","date":"2019-10-01","objectID":"/emoji-support/:8:6","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"数学 图标 代码 图标 代码 ✖️ heavy_multiplication_x ➕ heavy_plus_sign ➖ heavy_minus_sign ➗ heavy_division_sign ","date":"2019-10-01","objectID":"/emoji-support/:8:7","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"标点符号 图标 代码 图标 代码 ‼️ bangbang ⁉️ interrobang ❓ question ❔ grey_question ❕ grey_exclamation ❗ exclamation heavy_exclamation_mark 〰️ wavy_dash ","date":"2019-10-01","objectID":"/emoji-support/:8:8","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"货币 图标 代码 图标 代码 💱 currency_exchange 💲 heavy_dollar_sign ","date":"2019-10-01","objectID":"/emoji-support/:8:9","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"按键符号 图标 代码 图标 代码 #️⃣ hash *️⃣ asterisk 0️⃣ zero 1️⃣ one 2️⃣ two 3️⃣ three 4️⃣ four 5️⃣ five 6️⃣ six 7️⃣ seven 8️⃣ eight 9️⃣ nine 🔟 keycap_ten ","date":"2019-10-01","objectID":"/emoji-support/:8:10","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"字母符号 图标 代码 图标 代码 🔠 capital_abcd 🔡 abcd 🔢 1234 🔣 symbols 🔤 abc 🅰️ a 🆎 ab 🅱️ b 🆑 cl 🆒 cool 🆓 free ℹ️ information_source 🆔 id ⓜ️ m 🆕 new 🆖 ng 🅾️ o2 🆗 ok 🅿️ parking 🆘 sos 🆙 up 🆚 vs 🈁 koko 🈂️ sa 🈷️ u6708 🈶 u6709 🈯 u6307 🉐 ideograph_advantage 🈹 u5272 🈚 u7121 🈲 u7981 🉑 accept 🈸 u7533 🈴 u5408 🈳 u7a7a ㊗️ congratulations ㊙️ secret 🈺 u55b6 🈵 u6e80 ","date":"2019-10-01","objectID":"/emoji-support/:8:11","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"几何符号 图标 代码 图标 代码 🔴 red_circle 🔵 large_blue_circle ⚫ black_circle ⚪ white_circle ⬛ black_large_square ⬜ white_large_square ◼️ black_medium_square ◻️ white_medium_square ◾ black_medium_small_square ◽ white_medium_small_square ▪️ black_small_square ▫️ white_small_square 🔶 large_orange_diamond 🔷 large_blue_diamond 🔸 small_orange_diamond 🔹 small_blue_diamond 🔺 small_red_triangle 🔻 small_red_triangle_down 💠 diamond_shape_with_a_dot_inside 🔘 radio_button 🔳 white_square_button 🔲 black_square_button ","date":"2019-10-01","objectID":"/emoji-support/:8:12","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"其它符合 图标 代码 图标 代码 ♻️ recycle ⚜️ fleur_de_lis 🔱 trident 📛 name_badge 🔰 beginner ⭕ o ✅ white_check_mark ☑️ ballot_box_with_check ✔️ heavy_check_mark ❌ x ❎ negative_squared_cross_mark ➰ curly_loop ➿ loop 〽️ part_alternation_mark ✳️ eight_spoked_asterisk ✴️ eight_pointed_black_star ❇️ sparkle ©️ copyright ®️ registered ™️ tm ","date":"2019-10-01","objectID":"/emoji-support/:8:13","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"旗帜 ","date":"2019-10-01","objectID":"/emoji-support/:9:0","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"常用旗帜 图标 代码 图标 代码 🏁 checkered_flag 🚩 triangular_flag_on_post 🎌 crossed_flags 🏴 black_flag 🏳 white_flag 🏳️‍🌈 rainbow_flag ","date":"2019-10-01","objectID":"/emoji-support/:9:1","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["Markdown"],"content":"国家和地区旗帜 图标 代码 图标 代码 🇦🇩 andorra 🇦🇪 united_arab_emirates 🇦🇫 afghanistan 🇦🇬 antigua_barbuda 🇦🇮 anguilla 🇦🇱 albania 🇦🇲 armenia 🇦🇴 angola 🇦🇶 antarctica 🇦🇷 argentina 🇦🇸 american_samoa 🇦🇹 austria 🇦🇺 australia 🇦🇼 aruba 🇦🇽 aland_islands 🇦🇿 azerbaijan 🇧🇦 bosnia_herzegovina 🇧🇧 barbados 🇧🇩 bangladesh 🇧🇪 belgium 🇧🇫 burkina_faso 🇧🇬 bulgaria 🇧🇭 bahrain 🇧🇮 burundi 🇧🇯 benin 🇧🇱 st_barthelemy 🇧🇲 bermuda 🇧🇳 brunei 🇧🇴 bolivia 🇧🇶 caribbean_netherlands 🇧🇷 brazil 🇧🇸 bahamas 🇧🇹 bhutan 🇧🇼 botswana 🇧🇾 belarus 🇧🇿 belize 🇨🇦 canada 🇨🇨 cocos_islands 🇨🇩 congo_kinshasa 🇨🇫 central_african_republic 🇨🇬 congo_brazzaville 🇨🇭 switzerland 🇨🇮 cote_divoire 🇨🇰 cook_islands 🇨🇱 chile 🇨🇲 cameroon 🇨🇳 cn 🇨🇴 colombia 🇨🇷 costa_rica 🇨🇺 cuba 🇨🇻 cape_verde 🇨🇼 curacao 🇨🇽 christmas_island 🇨🇾 cyprus 🇨🇿 czech_republic 🇩🇪 de 🇩🇯 djibouti 🇩🇰 denmark 🇩🇲 dominica 🇩🇴 dominican_republic 🇩🇿 algeria 🇪🇨 ecuador 🇪🇪 estonia 🇪🇬 egypt 🇪🇭 western_sahara 🇪🇷 eritrea 🇪🇸 es 🇪🇹 ethiopia 🇪🇺 eu european_union 🇫🇮 finland 🇫🇯 fiji 🇫🇰 falkland_islands 🇫🇲 micronesia 🇫🇴 faroe_islands 🇫🇷 fr 🇬🇦 gabon 🇬🇧 gb uk 🇬🇩 grenada 🇬🇪 georgia 🇬🇫 french_guiana 🇬🇬 guernsey 🇬🇭 ghana 🇬🇮 gibraltar 🇬🇱 greenland 🇬🇲 gambia 🇬🇳 guinea 🇬🇵 guadeloupe 🇬🇶 equatorial_guinea 🇬🇷 greece 🇬🇸 south_georgia_south_sandwich_islands 🇬🇹 guatemala 🇬🇺 guam 🇬🇼 guinea_bissau 🇬🇾 guyana 🇭🇰 hong_kong 🇭🇳 honduras 🇭🇷 croatia 🇭🇹 haiti 🇭🇺 hungary 🇮🇨 canary_islands 🇮🇩 indonesia 🇮🇪 ireland 🇮🇱 israel 🇮🇲 isle_of_man 🇮🇳 india 🇮🇴 british_indian_ocean_territory 🇮🇶 iraq 🇮🇷 iran 🇮🇸 iceland 🇮🇹 it 🇯🇪 jersey 🇯🇲 jamaica 🇯🇴 jordan 🇯🇵 jp 🇰🇪 kenya 🇰🇬 kyrgyzstan 🇰🇭 cambodia 🇰🇮 kiribati 🇰🇲 comoros 🇰🇳 st_kitts_nevis 🇰🇵 north_korea 🇰🇷 kr 🇰🇼 kuwait 🇰🇾 cayman_islands 🇰🇿 kazakhstan 🇱🇦 laos 🇱🇧 lebanon 🇱🇨 st_lucia 🇱🇮 liechtenstein 🇱🇰 sri_lanka 🇱🇷 liberia 🇱🇸 lesotho 🇱🇹 lithuania 🇱🇺 luxembourg 🇱🇻 latvia 🇱🇾 libya 🇲🇦 morocco 🇲🇨 monaco 🇲🇩 moldova 🇲🇪 montenegro 🇲🇬 madagascar 🇲🇭 marshall_islands 🇲🇰 macedonia 🇲🇱 mali 🇲🇲 myanmar 🇲🇳 mongolia 🇲🇴 macau 🇲🇵 northern_mariana_islands 🇲🇶 martinique 🇲🇷 mauritania 🇲🇸 montserrat 🇲🇹 malta 🇲🇺 mauritius 🇲🇻 maldives 🇲🇼 malawi 🇲🇽 mexico 🇲🇾 malaysia 🇲🇿 mozambique 🇳🇦 namibia 🇳🇨 new_caledonia 🇳🇪 niger 🇳🇫 norfolk_island 🇳🇬 nigeria 🇳🇮 nicaragua 🇳🇱 netherlands 🇳🇴 norway 🇳🇵 nepal 🇳🇷 nauru 🇳🇺 niue 🇳🇿 new_zealand 🇴🇲 oman 🇵🇦 panama 🇵🇪 peru 🇵🇫 french_polynesia 🇵🇬 papua_new_guinea 🇵🇭 philippines 🇵🇰 pakistan 🇵🇱 poland 🇵🇲 st_pierre_miquelon 🇵🇳 pitcairn_islands 🇵🇷 puerto_rico 🇵🇸 palestinian_territories 🇵🇹 portugal 🇵🇼 palau 🇵🇾 paraguay 🇶🇦 qatar 🇷🇪 reunion 🇷🇴 romania 🇷🇸 serbia 🇷🇺 ru 🇷🇼 rwanda 🇸🇦 saudi_arabia 🇸🇧 solomon_islands 🇸🇨 seychelles 🇸🇩 sudan 🇸🇪 sweden 🇸🇬 singapore 🇸🇭 st_helena 🇸🇮 slovenia 🇸🇰 slovakia 🇸🇱 sierra_leone 🇸🇲 san_marino 🇸🇳 senegal 🇸🇴 somalia 🇸🇷 suriname 🇸🇸 south_sudan 🇸🇹 sao_tome_principe 🇸🇻 el_salvador 🇸🇽 sint_maarten 🇸🇾 syria 🇸🇿 swaziland 🇹🇨 turks_caicos_islands 🇹🇩 chad 🇹🇫 french_southern_territories 🇹🇬 togo 🇹🇭 thailand 🇹🇯 tajikistan 🇹🇰 tokelau 🇹🇱 timor_leste 🇹🇲 turkmenistan 🇹🇳 tunisia 🇹🇴 tonga 🇹🇷 tr 🇹🇹 trinidad_tobago 🇹🇻 tuvalu 🇹🇼 taiwan 🇹🇿 tanzania 🇺🇦 ukraine 🇺🇬 uganda 🇺🇸 us 🇺🇾 uruguay 🇺🇿 uzbekistan 🇻🇦 vatican_city 🇻🇨 st_vincent_grenadines 🇻🇪 venezuela 🇻🇬 british_virgin_islands 🇻🇮 us_virgin_islands 🇻🇳 vietnam 🇻🇺 vanuatu 🇼🇫 wallis_futuna 🇼🇸 samoa 🇽🇰 kosovo 🇾🇪 yemen 🇾🇹 mayotte 🇿🇦 south_africa 🇿🇲 zambia 🇿🇼 zimbabwe ","date":"2019-10-01","objectID":"/emoji-support/:9:2","tags":["emoji"],"title":"Emoji 支持","uri":"/emoji-support/"},{"categories":["documentation"],"content":"echarts shortcode 使用 ECharts 库提供数据可视化的功能.","date":"2020-03-03","objectID":"/theme-documentation-echarts-shortcode/","tags":["shortcodes"],"title":"主题文档 - echarts Shortcode","uri":"/theme-documentation-echarts-shortcode/"},{"categories":["documentation"],"content":"echarts shortcode 使用 ECharts 库提供数据可视化的功能. ECharts 是一个帮助你生成交互式数据可视化的库. ECharts 提供了常规的 折线图, 柱状图, 散点图, 饼图, K线图, 用于统计的 盒形图, 用于地理数据可视化的 地图, 热力图, 线图, 用于关系数据可视化的 关系图, treemap, 旭日图, 多维数据可视化的 平行坐标, 还有用于 BI 的 漏斗图, 仪表盘, 并且支持图与图之间的混搭. 只需在 echarts shortcode 中以 JSON/YAML/TOML格式插入 ECharts 选项即可. 一个 JSON 格式的 echarts 示例: {{\u003c echarts \u003e}} { \"title\": { \"text\": \"折线统计图\", \"top\": \"2%\", \"left\": \"center\" }, \"tooltip\": { \"trigger\": \"axis\" }, \"legend\": { \"data\": [\"邮件营销\", \"联盟广告\", \"视频广告\", \"直接访问\", \"搜索引擎\"], \"top\": \"10%\" }, \"grid\": { \"left\": \"5%\", \"right\": \"5%\", \"bottom\": \"5%\", \"top\": \"20%\", \"containLabel\": true }, \"toolbox\": { \"feature\": { \"saveAsImage\": { \"title\": \"保存为图片\" } } }, \"xAxis\": { \"type\": \"category\", \"boundaryGap\": false, \"data\": [\"周一\", \"周二\", \"周三\", \"周四\", \"周五\", \"周六\", \"周日\"] }, \"yAxis\": { \"type\": \"value\" }, \"series\": [ { \"name\": \"邮件营销\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [120, 132, 101, 134, 90, 230, 210] }, { \"name\": \"联盟广告\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [220, 182, 191, 234, 290, 330, 310] }, { \"name\": \"视频广告\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [150, 232, 201, 154, 190, 330, 410] }, { \"name\": \"直接访问\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [320, 332, 301, 334, 390, 330, 320] }, { \"name\": \"搜索引擎\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [820, 932, 901, 934, 1290, 1330, 1320] } ] } {{\u003c /echarts \u003e}} 一个 YAML 格式的 echarts 示例: {{\u003c echarts \u003e}} title: text: 折线统计图 top: 2% left: center tooltip: trigger: axis legend: data: - 邮件营销 - 联盟广告 - 视频广告 - 直接访问 - 搜索引擎 top: 10% grid: left: 5% right: 5% bottom: 5% top: 20% containLabel: true toolbox: feature: saveAsImage: title: 保存为图片 xAxis: type: category boundaryGap: false data: - 周一 - 周二 - 周三 - 周四 - 周五 - 周六 - 周日 yAxis: type: value series: - name: 邮件营销 type: line stack: 总量 data: - 120 - 132 - 101 - 134 - 90 - 230 - 210 - name: 联盟广告 type: line stack: 总量 data: - 220 - 182 - 191 - 234 - 290 - 330 - 310 - name: 视频广告 type: line stack: 总量 data: - 150 - 232 - 201 - 154 - 190 - 330 - 410 - name: 直接访问 type: line stack: 总量 data: - 320 - 332 - 301 - 334 - 390 - 330 - 320 - name: 搜索引擎 type: line stack: 总量 data: - 820 - 932 - 901 - 934 - 1290 - 1330 - 1320 {{\u003c /echarts \u003e}} 一个 TOML 格式的 echarts 示例: {{\u003c echarts \u003e}} [title] text = \"折线统计图\" top = \"2%\" left = \"center\" [tooltip] trigger = \"axis\" [legend] data = [ \"邮件营销\", \"联盟广告\", \"视频广告\", \"直接访问\", \"搜索引擎\" ] top = \"10%\" [grid] left = \"5%\" right = \"5%\" bottom = \"5%\" top = \"20%\" containLabel = true [toolbox] [toolbox.feature] [toolbox.feature.saveAsImage] title = \"保存为图片\" [xAxis] type = \"category\" boundaryGap = false data = [ \"周一\", \"周二\", \"周三\", \"周四\", \"周五\", \"周六\", \"周日\" ] [yAxis] type = \"value\" [[series]] name = \"邮件营销\" type = \"line\" stack = \"总量\" data = [ 120.0, 132.0, 101.0, 134.0, 90.0, 230.0, 210.0 ] [[series]] name = \"联盟广告\" type = \"line\" stack = \"总量\" data = [ 220.0, 182.0, 191.0, 234.0, 290.0, 330.0, 310.0 ] [[series]] name = \"视频广告\" type = \"line\" stack = \"总量\" data = [ 150.0, 232.0, 201.0, 154.0, 190.0, 330.0, 410.0 ] [[series]] name = \"直接访问\" type = \"line\" stack = \"总量\" data = [ 320.0, 332.0, 301.0, 334.0, 390.0, 330.0, 320.0 ] [[series]] name = \"搜索引擎\" type = \"line\" stack = \"总量\" data = [ 820.0, 932.0, 901.0, 934.0, 1290.0, 1330.0, 1320.0 ] {{\u003c /echarts \u003e}} 呈现的输出效果如下: echarts shortcode 还有以下命名参数: width [可选] (第一个位置参数) 数据可视化的宽度, 默认值是 100%. height [可选] (第二个位置参数) 数据可视化的高度, 默认值是 30rem. ","date":"2020-03-03","objectID":"/theme-documentation-echarts-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - echarts Shortcode","uri":"/theme-documentation-echarts-shortcode/"},{"categories":["documentation"],"content":"mapbox shortcode 使用 Mapbox GL JS 库提供互动式地图的功能.","date":"2020-03-03","objectID":"/theme-documentation-mapbox-shortcode/","tags":["shortcodes"],"title":"主题文档 - mapbox Shortcode","uri":"/theme-documentation-mapbox-shortcode/"},{"categories":["documentation"],"content":" mapbox shortcode 使用 Mapbox GL JS 库提供互动式地图的功能. Mapbox GL JS 是一个 JavaScript 库，它使用 WebGL, 以 vector tiles 和 Mapbox styles 为来源, 将它们渲染成互动式地图. mapbox shortcode 有以下命名参数来使用 Mapbox GL JS: lng [必需] (第一个位置参数) 地图初始中心点的经度, 以度为单位. lat [必需] (第二个位置参数) 地图初始中心点的纬度, 以度为单位. zoom [可选] (第三个位置参数) 地图的初始缩放级别, 默认值是 10. marked [可选] (第四个位置参数) 是否在地图的初始中心点添加图钉, 默认值是 true. light-style [可选] (第五个位置参数) 浅色主题的地图样式, 默认值是前置参数或者网站配置中设置的值. dark-style [可选] (第六个位置参数) 深色主题的地图样式, 默认值是前置参数或者网站配置中设置的值. navigation [可选] 是否添加 NavigationControl, 默认值是前置参数或者网站配置中设置的值. geolocate [可选] 是否添加 GeolocateControl, 默认值是前置参数或者网站配置中设置的值. scale [可选] 是否添加 ScaleControl, 默认值是前置参数或者网站配置中设置的值. fullscreen [可选] 是否添加 FullscreenControl, 默认值是前置参数或者网站配置中设置的值. width [可选] 地图的宽度, 默认值是 100%. height [可选] 地图的高度, 默认值是 20rem. 一个简单的 mapbox 示例: {{\u003c mapbox 121.485 31.233 12 \u003e}} 或者 {{\u003c mapbox lng=121.485 lat=31.233 zoom=12 \u003e}} 呈现的输出效果如下: 一个带有自定义样式的 mapbox 示例: {{\u003c mapbox -122.252 37.453 10 false \"mapbox://styles/mapbox/streets-zh-v1?optimize=true\" \u003e}} 或者 {{\u003c mapbox lng=-122.252 lat=37.453 zoom=10 marked=false light-style=\"mapbox://styles/mapbox/streets-zh-v1?optimize=true\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-mapbox-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - mapbox Shortcode","uri":"/theme-documentation-mapbox-shortcode/"},{"categories":["documentation"],"content":"music shortcode 基于 APlayer 和 MetingJS 库提供了一个内嵌的响应式音乐播放器.","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"music shortcode 基于 APlayer 和 MetingJS 库提供了一个内嵌的响应式音乐播放器. 有三种方式使用 music shortcode. ","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"1 自定义音乐 URL 支持本地资源引用的完整用法. music shortcode 有以下命名参数来使用自定义音乐 URL: server [必需] 音乐的链接. type [可选] 音乐的名称. artist [可选] 音乐的创作者. cover [可选] 音乐的封面链接. 一个使用自定义音乐 URL 的 music 示例: {{\u003c music url=\"/music/Wavelength.mp3\" name=Wavelength artist=oldmanyoung cover=\"/images/Wavelength.jpg\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/:1:0","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"2 音乐平台 URL 的自动识别 music shortcode 有一个命名参数来使用音乐平台 URL 的自动识别: auto [必需]] (第一个位置参数) 用来自动识别的音乐平台 URL, 支持 netease, tencent 和 xiami 平台. 一个使用音乐平台 URL 的自动识别的 music 示例: {{\u003c music auto=\"https://music.163.com/#/playlist?id=60198\" \u003e}} 或者 {{\u003c music \"https://music.163.com/#/playlist?id=60198\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/:2:0","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"3 自定义音乐平台, 类型和 ID music shortcode 有以下命名参数来使用自定义音乐平台: server [必需] (第一个位置参数) [netease, tencent, kugou, xiami, baidu] 音乐平台. type [必需] (第二个位置参数) [song, playlist, album, search, artist] 音乐类型. id [必需] (第三个位置参数) 歌曲 ID, 或者播放列表 ID, 或者专辑 ID, 或者搜索关键词, 或者创作者 ID. 一个使用自定义音乐平台的 music 示例: {{\u003c music server=\"netease\" type=\"song\" id=\"1868553\" \u003e}} 或者 {{\u003c music netease song 1868553 \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/:3:0","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"4 其它参数 music shortcode 有一些可以应用于以上三种方式的其它命名参数: theme [可选] 音乐播放器的主题色, 默认值是 #448aff. fixed [可选] 是否开启固定模式, 默认值是 false. mini [可选] 是否开启迷你模式, 默认值是 false. autoplay [可选] 是否自动播放音乐, 默认值是 false. volume [可选] 第一次打开播放器时的默认音量, 会被保存在浏览器缓存中, 默认值是 0.7. mutex [可选] 是否自动暂停其它播放器, 默认值是 true. music shortcode 还有一些只适用于音乐列表方式的其它命名参数: loop [可选] [all, one, none] 音乐列表的循环模式, 默认值是 none. order [可选] [list, random] 音乐列表的播放顺序, 默认值是 list. list-folded [可选] 初次打开的时候音乐列表是否折叠, 默认值是 false. list-max-height [可选] 音乐列表的最大高度, 默认值是 340px. ","date":"2020-03-03","objectID":"/theme-documentation-music-shortcode/:4:0","tags":["shortcodes"],"title":"主题文档 - music Shortcode","uri":"/theme-documentation-music-shortcode/"},{"categories":["documentation"],"content":"bilibili shortcode 提供了一个内嵌的用来播放 bilibili 视频的响应式播放器.","date":"2020-03-03","objectID":"/theme-documentation-bilibili-shortcode/","tags":["shortcodes"],"title":"主题文档 - bilibili Shortcode","uri":"/theme-documentation-bilibili-shortcode/"},{"categories":["documentation"],"content":" bilibili shortcode 提供了一个内嵌的用来播放 bilibili 视频的响应式播放器. 如果视频只有一个部分, 则仅需要视频的 BV id, 例如: https://www.bilibili.com/video/BV1Sx411T7QQ 一个 bilibili 示例: {{\u003c bilibili BV1Sx411T7QQ \u003e}} 或者 {{\u003c bilibili id=BV1Sx411T7QQ \u003e}} 呈现的输出效果如下: 如果视频包含多个部分, 则除了视频的 BV id 之外, 还需要 p, 默认值为 1, 例如: https://www.bilibili.com/video/BV1TJ411C7An?p=3 一个带有 p 参数的 bilibili 示例: {{\u003c bilibili BV1TJ411C7An 3 \u003e}} 或者 {{\u003c bilibili id=BV1TJ411C7An p=3 \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-bilibili-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - bilibili Shortcode","uri":"/theme-documentation-bilibili-shortcode/"},{"categories":["documentation"],"content":"typeit shortcode 基于 TypeIt 库提供了打字动画.","date":"2020-03-03","objectID":"/theme-documentation-typeit-shortcode/","tags":["shortcodes"],"title":"主题文档 - typeit Shortcode","uri":"/theme-documentation-typeit-shortcode/"},{"categories":["documentation"],"content":"typeit shortcode 基于 TypeIt 库提供了打字动画. 只需将你需要打字动画的内容插入 typeit shortcode 中即可. ","date":"2020-03-03","objectID":"/theme-documentation-typeit-shortcode/:0:0","tags":["shortcodes"],"title":"主题文档 - typeit Shortcode","uri":"/theme-documentation-typeit-shortcode/"},{"categories":["documentation"],"content":"1 简单内容 允许使用 Markdown 格式的简单内容, 并且 不包含 富文本的块内容, 例如图像等等… 一个 typeit 示例: {{\u003c typeit \u003e}} 这一个带有基于 [TypeIt](https://typeitjs.com/) 的 **打字动画** 的 *段落*... {{\u003c /typeit \u003e}} 呈现的输出效果如下: 另外, 你也可以自定义 HTML 标签. 一个带有 h4 标签的 typeit 示例: {{\u003c typeit tag=h4 \u003e}} 这一个带有基于 [TypeIt](https://typeitjs.com/) 的 **打字动画** 的 *段落*... {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-typeit-shortcode/:1:0","tags":["shortcodes"],"title":"主题文档 - typeit Shortcode","uri":"/theme-documentation-typeit-shortcode/"},{"categories":["documentation"],"content":"2 代码内容 代码内容也是允许的, 并且通过使用参数 code 指定语言类型可以实习语法高亮. 一个带有 code 参数的 typeit 示例: {{\u003c typeit code=java \u003e}} public class HelloWorld { public static void main(String []args) { System.out.println(\"Hello World\"); } } {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-typeit-shortcode/:2:0","tags":["shortcodes"],"title":"主题文档 - typeit Shortcode","uri":"/theme-documentation-typeit-shortcode/"},{"categories":["documentation"],"content":"3 分组内容 默认情况下, 所有打字动画都是同时开始的. 但是有时你可能需要按顺序开始一组 typeit 内容的打字动画. 一组具有相同 group 参数值的 typeit 内容将按顺序开始打字动画. 一个带有 group 参数的 typeit 示例: {{\u003c typeit group=paragraph \u003e}} **首先**, 这个段落开始 {{\u003c /typeit \u003e}} {{\u003c typeit group=paragraph \u003e}} **然后**, 这个段落开始 {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/theme-documentation-typeit-shortcode/:3:0","tags":["shortcodes"],"title":"主题文档 - typeit Shortcode","uri":"/theme-documentation-typeit-shortcode/"},{"categories":null,"content":"关于 LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"  LoveIt 是一个由  Dillon 开发的简洁、优雅且高效的 Hugo 博客主题。 它的原型基于 LeaveIt 主题 和 KeepIt 主题。 Hugo 主题 LoveIt\r","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特性 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 Plausible Analytics  支持 Yandex Metrica  支持搜索引擎的网站验证 (Google, Bind, Yandex and Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 ","date":"2019-08-02","objectID":"/about/:1:1","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"外观和布局  桌面端/移动端 响应式布局  浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 73 种社交链接  支持多达 24 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook comments 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 utterances 评论系统  支持 giscus 评论系统 ","date":"2019-08-02","objectID":"/about/:1:2","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightGallery 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $\\KaTeX$ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅  支持人物标签的 shortcode … ","date":"2019-08-02","objectID":"/about/:1:3","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特别感谢 LoveIt 主题中用到了以下项目，感谢它们的作者： normalize.css Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 LoveIt","uri":"/about/"}]