<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Chapter4 ：Continuous predictors: Piecewise models - Alex_Wang</title><meta name="Description" content="This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.  "><meta property="og:title" content="Chapter4 ：Continuous predictors: Piecewise models" />
<meta property="og:description" content="This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.  " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forest293.github.io/3.continuous-predictors_piecewise-models/" /><meta property="og:image" content="https://forest293.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T16:29:41+08:00" />
<meta property="article:modified_time" content="2023-12-31T23:45:40+08:00" /><meta property="og:site_name" content="Alex_Wang" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://forest293.github.io/logo.png"/>

<meta name="twitter:title" content="Chapter4 ：Continuous predictors: Piecewise models"/>
<meta name="twitter:description" content="This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.  "/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://forest293.github.io/3.continuous-predictors_piecewise-models/" /><link rel="prev" href="https://forest293.github.io/2.continuous-predictors_polynomials/" /><link rel="next" href="https://forest293.github.io/5.continuous-by-continuous-interactions/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Chapter4 ：Continuous predictors: Piecewise models",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/forest293.github.io\/3.continuous-predictors_piecewise-models\/"
        },"image": ["https:\/\/forest293.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "Continuous predictors, stata","wordcount":  4578 ,
        "url": "https:\/\/forest293.github.io\/3.continuous-predictors_piecewise-models\/","datePublished": "2023-12-29T16:29:41+08:00","dateModified": "2023-12-31T23:45:40+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/forest293.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Alex_Wang"
            },"description": "This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.  "
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Alex_Wang">Alex Wang</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/categories/documentation/"> 文档 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a><a href="javascript:void(0);" class="menu-item language" title="选择语言">
                    <i class="fa fa-globe" aria-hidden="true"></i>                      
                    <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/3.continuous-predictors_piecewise-models/" selected>简体中文</option></select>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Alex_Wang">Alex Wang</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/categories/documentation/" title="">文档</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="选择语言">
                    <i class="fa fa-globe fa-fw" aria-hidden="true"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/3.continuous-predictors_piecewise-models/" selected>简体中文</option></select>
                </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Chapter4 ：Continuous predictors: Piecewise models</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Alex_Wang</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/interpreting-and-visualizing-regression-models-using-stata/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Interpreting and Visualizing Regression Models Using Stata</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2023-12-29">2023-12-29</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 4578 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 22 分钟&nbsp;<span id="/3.continuous-predictors_piecewise-models/" class="leancloud_visitors" data-flag-title="Chapter4 ：Continuous predictors: Piecewise models">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-introduction-to-piecewise-regression-models">1 Introduction to piecewise regression models</a></li>
    <li><a href="#2-piecewise-with-one-known-knot">2 Piecewise with one known knot</a>
      <ul>
        <li><a href="#21-examples-using-the-gss">2.1 Examples using the GSS</a>
          <ul>
            <li><a href="#211-individual-slope-coding">2.1.1 Individual slope coding</a></li>
            <li><a href="#212-change-in-slope-coding">2.1.2 Change in slope coding</a></li>
            <li><a href="#213-summary">2.1.3 Summary</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-piecewise-with-two-known-knots">3 Piecewise with two known knots</a>
      <ul>
        <li><a href="#31-examples-using-the-gss">3.1 Examples using the GSS</a></li>
      </ul>
    </li>
    <li><a href="#4-piecewise-with-one-knot-and-one-jump">4 Piecewise with one knot and one jump</a>
      <ul>
        <li><a href="#41-examples-using-the-gss">4.1 Examples using the GSS</a></li>
      </ul>
    </li>
    <li><a href="#5-piecewise-with-two-knots-and-two-jumps">5 Piecewise with two knots and two jumps</a>
      <ul>
        <li><a href="#51-examples-using-the-gss">5.1 Examples using the GSS</a></li>
      </ul>
    </li>
    <li><a href="#6-piecewise-with-an-unknown-knot">6 Piecewise with an unknown knot</a></li>
    <li><a href="#7-piecewise-model-with-multiple-unknown-knots">7 Piecewise model with multiple unknown knots</a></li>
    <li><a href="#8-automating-graphs-of-piecewise-models">8 Automating graphs of piecewise models</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><strong>This chapter illustrates the use of piecewise regression. This involves fitting separate line segments, demarcated by knots, that account for the nonlinearity between the predictor and outcome.</strong></p>
<h2 id="1-introduction-to-piecewise-regression-models">1 Introduction to piecewise regression models</h2>
<p>A piecewise regression goes by several names, including <strong>spline regression</strong>,<strong>broken line regression</strong>, <strong>broken stick regression</strong>, and even <strong>hockey stick models</strong>.</p>
<p>Consider the example, predicting annual income from education, shown in the figure below</p>
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise.png"title="Piecewise regression with one knot (left) and two knots (right)"  />
</div>
<p><strong>A knot can signify a change of slope and a change of intercept, yielding an increase (or decrease) in the outcome upon attaining a particular milestone.</strong></p>
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/picewise1.png"title="Piecewise regression with one knot (left) and two knots (right)"  />
</div>
<blockquote>
<p>Note! Instantaneous jumps?</p>
<blockquote>
<p>As a thought experiment, imagine someone being one day short of graduating high school and the wages they would obtain as they seek a job. Compare this person with an identical job seeker who has one more day of education (that is, they graduated high school). These two people are identical except that one crossed the threshold of getting a diploma. It is indeed plausible that the second person would be offered an annual income $2,200 more than the first person$.</p>
</blockquote>
</blockquote>
<p>Suppose you have a predictor that shows a nonlinear relationship with the outcome, and you believe that a piecewise model with one knot signifying a change in slope would fit your data well. However, unlike the previous examples, you do not have a theoretical or practical basis for selecting the placement of the knot. You could haphazardly try a variety of placements for the knot, trying to find a placement that results in the best fitting model. Alternatively, <strong>you can let Stata do the work for you by using a least-squares procedure for selecting a location for the knot that produces the lowest residual sum of squares.</strong></p>
<h2 id="2-piecewise-with-one-known-knot">2 Piecewise with one known knot</h2>
<p>This section illustrates piecewise regression with one knot.</p>
<h3 id="21-examples-using-the-gss">2.1 Examples using the GSS</h3>
<p>Let’s use the GSS dataset to illustrate a piecewise model with one knot, focusing on <strong>the relationship between income and education.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  reg realrinc i.educ,vce(robust)
</span></span><span class="line"><span class="cl">  margins educ
</span></span><span class="line"><span class="cl">  marginsplot,noci
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise2.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise2.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise2.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise2.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/piecewise2.png"
        title="Mean of income at each level of education" /></p>
<p>It looks like the relationship between education and income could be fit well with a piecewise model with a knot at 12 (corresponding to graduating high school). The following subsections illustrate two different ways to fit this kind of piecewise model: <strong>using individual slope coding</strong> and <strong>using change in slope coding.</strong></p>
<h4 id="211-individual-slope-coding">2.1.1 Individual slope coding</h4>
<p>The individual slope coding scheme <strong>estimates the slope of each line segment of the piecewise model.</strong></p>
<p>The first step is to <strong>create two new variables that are coded to represent the educ slope before and after graduating high school.</strong> The <strong>mkspline</strong> command creates the variables ed1 and ed2 based on the original variable educ. The value of 12 is inserted between ed1 and ed2, indicating that this is the knot.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  mkspline ed1 12 ed2 = educ
</span></span><span class="line"><span class="cl">  showcoding educ ed1 ed2
</span></span></code></pre></td></tr></table>
</div>
</div><div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/showcoding.png"title="showcoding educ ed1 ed2" width = "300" height = "400" />
</div>
<p>The next step is to use the regress command to predict realrinc from ed1 and ed2. This will yield a piecewise model with 12 years of education as the knot.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  reg realrinc ed1 ed2 female,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,183
                                                 F(3, 32179)       =    1030.24
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.1420
                                                 Root MSE          =      25045
</code></pre>
<hr>
<pre><code>         |               Robust
realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]
                                                                          
     ed1 |     832.27      72.38    11.50   0.000       690.40      974.14
     ed2 |    3441.33      93.42    36.84   0.000      3258.21     3624.44
  female |  -12372.38     276.35   -44.77   0.000    -12914.05   -11830.72
   _cons |   12052.18     793.42    15.19   0.000     10497.04    13607.31
</code></pre>
<hr>
<p>Among non–high school graduates(ed1), each additional year of education is predicted to increase income by $832.27$.The coefficient for ed2 is the slope for those with 12 or more years of education (high school graduates). Income increases by $3,441.33$ for each additional year of education beyond 12 years of education(ed2). Each of these slopes is significantly different from 0.</p>
<p>Say that we want to compute the adjusted mean given that a person has eight years of education. We can compute this adjusted mean using the <strong>margins command</strong>;</p>
<p>To graph the adjusted means as a function of education, we need to compute the adjusted means when education is 0, 12, and 20. The margins command below computes these three adjusted means by using the at() option three times.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  margins,at(ed1=0 ed2=0) at(ed1=12 ed2=0) at(ed1=12 ed2=8) vsquish
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Predictive margins                                      Number of obs = 32,183
 Model VCE: Robust

 Expression: Linear prediction, predict()
 1._at: ed1 =  0
        ed2 =  0
 2._at: ed1 = 12
        ed2 =  0
 3._at: ed1 = 12
        ed2 =  8
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]
                                                                          
     _at |
      1  |    5964.98     794.24     7.51   0.000      4408.23     7521.72
      2  |   15952.22     161.46    98.80   0.000     15635.75    16268.69
      3  |   43482.83     657.66    66.12   0.000     42193.79    44771.86
</code></pre>
<hr>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  preserve
</span></span><span class="line"><span class="cl">  clear
</span></span><span class="line"><span class="cl">  input educ yhat
</span></span><span class="line"><span class="cl">  0  5964.977
</span></span><span class="line"><span class="cl">  12 15952.22
</span></span><span class="line"><span class="cl">  20 43482.83
</span></span><span class="line"><span class="cl">  end
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  graph twoway line yhat educ,xlabel(0(4)20) xline(12)
</span></span><span class="line"><span class="cl">  restore
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20knot.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20knot.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20knot.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20knot.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20knot.png"
        title="Adjusted means for income from a piecewise model with one knot at educ = 12" /></p>
<h4 id="212-change-in-slope-coding">2.1.2 Change in slope coding</h4>
<p>This coding scheme estimates the slope for the line segment before the first knot (for example, for non–high school graduates) and then estimates the difference in the slopes of adjacent line segments (for example, for high school graduates versus non–high school graduates). This strategy emphasizes the change in slope that occurs at each knot.</p>
<p>The key difference is that <strong>we add the marginal option to the mkspline command,</strong> as shown below. I name the variables ed1m and ed2m, adding the m to emphasize that <strong>these variables were created using the marginal option.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  mkspline ed1m 12 ed2m = educ,marginal
</span></span></code></pre></td></tr></table>
</div>
</div><div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/showcoding1.png"title="showcoding" width = "300" height = "400" />
</div>
<p>The next step is to enter ed1m and ed2m as predictors of income, as shown below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  reg realrinc ed1m ed2m female,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,183
                                                 F(3, 32179)       =    1030.24
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.1420
                                                 Root MSE          =      25045
</code></pre>
<hr>
<pre><code>         |               Robust
realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]
                                                                          
    ed1m |     832.27      72.38    11.50   0.000       690.40      974.14
    ed2m |    2609.06     134.40    19.41   0.000      2345.63     2872.48
  female |  -12372.38     276.35   -44.77   0.000    -12914.05   -11830.72
   _cons |   12052.18     793.42    15.19   0.000     10497.04    13607.31
</code></pre>
<hr>
<h4 id="213-summary">2.1.3 Summary</h4>
<p>The individual slope coding method <strong>omitted the marginal option on the mkspline command and yielded estimates of the educ slope before and after the knot.</strong> We also saw the change in slope coding method, which <strong>included the marginal option on the mkspline command, and yielded an estimate of the educ slope before the knot and the change in the educ slope before and after the knot.</strong></p>
<h2 id="3-piecewise-with-two-known-knots">3 Piecewise with two known knots</h2>
<h3 id="31-examples-using-the-gss">3.1 Examples using the GSS</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  mkspline ed1m 12 ed2m 16 ed3m = educ,marginal
</span></span><span class="line"><span class="cl">  showcoding educ ed1m ed2m ed3m
</span></span></code></pre></td></tr></table>
</div>
</div><div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/showcoding2.png"title="showcoding" width = "300" height = "400" />
</div>
<p>The coefficient for ed2m will represent the change in slope for <strong>high school graduates versus non–high school graduates.</strong> The coefficient for ed3m will represent the change in slope <strong>comparing college graduates with high school graduates.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  reg realrinc ed1m ed2m ed3m female,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,183
                                                 F(4, 32178)       =     784.42
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.1432
                                                 Root MSE          =      25029
</code></pre>
<hr>
<pre><code>         |               Robust
realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]
                                                                          
    ed1m |     939.67      70.55    13.32   0.000       801.40     1077.95
    ed2m |    2022.42     144.24    14.02   0.000      1739.71     2305.13
    ed3m |    1657.45     412.15     4.02   0.000       849.62     2465.28
  female |  -12336.74     277.09   -44.52   0.000    -12879.84   -11793.64
   _cons |   11215.32     787.53    14.24   0.000      9671.73    12758.92
</code></pre>
<hr>
<p>We can use the margins command to compute adjusted means for any given value of education by expressing education in terms of the variables ed1m, ed2m, and ed3m.</p>
<p>To graph the entire range of education values, we need to compute the adjusted means for the minimum of education (0), for each of the knots (12 and 16), and for the maximum of education (20). <strong>The margins command below computes these adjusted means using the at() option once for each of these four levels of education.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  margins,at(ed1m=0 ed2m=0 ed3m=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=12 ed2m=0 ed3m=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=16 ed2m=4 ed3m=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=20 ed2m=8 ed3m=4) vsquish   
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Predictive margins                                      Number of obs = 32,183
 Model VCE: Robust

 Expression: Linear prediction, predict()
 1._at: ed1m =  0
        ed2m =  0
        ed3m =  0
 2._at: ed1m = 12
        ed2m =  0
        ed3m =  0
 3._at: ed1m = 16
        ed2m =  4
        ed3m =  0
 4._at: ed1m = 20
        ed2m =  8
        ed3m =  4
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]

     _at |
      1  |    5145.66     785.16     6.55   0.000      3606.72     6684.60
      2  |   16421.73     145.60   112.79   0.000     16136.36    16707.11
      3  |   28270.11     383.13    73.79   0.000     27519.16    29021.06
      4  |   46748.30    1242.79    37.62   0.000     44312.38    49184.22
</code></pre>
<hr>
<p>We can then manually input the adjusted means from the margins command into a dataset as shown below.
The graph command is then used to graph the relationship between education and income.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  preserve
</span></span><span class="line"><span class="cl">  clear
</span></span><span class="line"><span class="cl">  input educ yhat
</span></span><span class="line"><span class="cl">  0 5154.66
</span></span><span class="line"><span class="cl">  12 16421.73
</span></span><span class="line"><span class="cl">  16 28270.11
</span></span><span class="line"><span class="cl">  20 46748.3
</span></span><span class="line"><span class="cl">  end
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  graph twoway line yhat educ,xlabel(0(4)20) xline(12 16) xtitle(Education) ytitle(Adjusted mean)
</span></span><span class="line"><span class="cl">  restore
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20knot.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20knot.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20knot.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20knot.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20knot.png"
        title="Adjusted means from piecewise model with knots at educ = 12 and educ = 16" /></p>
<h2 id="4-piecewise-with-one-knot-and-one-jump">4 Piecewise with one knot and one jump</h2>
<h3 id="41-examples-using-the-gss">4.1 Examples using the GSS</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  mkspline ed1m 12 ed2m = educ,marginal
</span></span><span class="line"><span class="cl">  reg realrinc ed1m ed2m hsgrad female,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><p>The variable <strong>hsgrad</strong> is coded 1 if someone has 12 or more years of education, and 0 otherwise.</p>
<pre><code> Linear regression                               Number of obs     =     32,183
                                                 F(4, 32178)       =     803.67
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.1425
                                                 Root MSE          =      25039
</code></pre>
<hr>
<pre><code>         |               Robust
realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]

    ed1m |     273.10     105.88     2.58   0.010        65.56      480.64
    ed2m |    3102.95     141.83    21.88   0.000      2824.97     3380.94
  hsgrad |    2721.54     412.82     6.59   0.000      1912.40     3530.67
  female |  -12391.31     276.30   -44.85   0.000    -12932.87   -11849.74
   _cons |   16345.24     988.38    16.54   0.000     14407.98    18282.49
</code></pre>
<hr>
<p>At 12 years of education, the adjusted mean is <strong>computed twice</strong>, once assuming the absence of a high school degree and once <strong>assuming a high school degree</strong>, illustrating the jump in income due to graduating high school.</p>
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump1.png"title="Adjusted means from piecewise model with one knot and one jump at educ = 12"  />
</div>
<p><strong>How tow interpret the regression coefficient?</strong></p>
<ul>
<li>For each additional year of education (up to 12), income increases by $273.10.$figure shows the adjusted means given zero and one year of education. This difference in these adjusted means equals 273.10 $(10521.83-10248.73)$</li>
<li>The coefficient of ed2m is 3,102.95, which is the change (increase) in slope for high school graduates compared with non–high school graduates.</li>
<li>Finally, the hsgrad coefficient (2,721.54) represents the predicted jump (increase in income) due to graduating high school.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  showcoding educ hsgrad ed1m ed2m
</span></span><span class="line"><span class="cl">  margins,at(ed1m=0 ed2m=0 hsgrad=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=12 ed2m=0 hsgrad=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=12 ed2m=0 hsgrad=1) ///
</span></span><span class="line"><span class="cl">          at(ed1m=20 ed2m=8 hsgrad=1) vsquish 
</span></span></code></pre></td></tr></table>
</div>
</div><div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/12.31.png"title="showcoding" width = "300" height = "400" />
</div>
<pre><code> Predictive margins                                      Number of obs = 32,183
 Model VCE: Robust

 Expression: Linear prediction, predict()
 1._at: ed1m   =  0
        ed2m   =  0
        hsgrad =  0
 2._at: ed1m   = 12
        ed2m   =  0
        hsgrad =  0
 3._at: ed1m   = 12
        ed2m   =  0
        hsgrad =  1
 4._at: ed1m   = 20
        ed2m   =  8
        hsgrad =  1
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]

      1  |   10248.73     987.42    10.38   0.000      8313.35    12184.10
      2  |   13525.93     374.97    36.07   0.000     12790.97    14260.89
      3  |   16247.46     174.79    92.95   0.000     15904.86    16590.07
      4  |   43255.90     664.00    65.14   0.000     41954.43    44557.37
</code></pre>
<hr>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump2.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump2.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump2.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump2.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/one%20jump2.png"
        title="Adjusted means from piecewise model with one knot and one jump at educ = 12" /></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  preserve
</span></span><span class="line"><span class="cl">  clear
</span></span><span class="line"><span class="cl">  input educ yhat
</span></span><span class="line"><span class="cl">  0  10248.73
</span></span><span class="line"><span class="cl">  12  13525.93
</span></span><span class="line"><span class="cl">  12  16247.46
</span></span><span class="line"><span class="cl">  20  43255.9
</span></span><span class="line"><span class="cl">  end
</span></span><span class="line"><span class="cl">  graph twoway line yhat educ,xlabel(0(4)20) xline(12)
</span></span><span class="line"><span class="cl">  restore
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Note! Individual slope coding</p>
<blockquote>
<p>This model was fit using the change in slope coding method (that is, with the marginal option on the mkspline command). If you wished, you could fit this model using individual slope coding by omitting the marginal option on the mkspline command.</p>
</blockquote>
</blockquote>
<h2 id="5-piecewise-with-two-knots-and-two-jumps">5 Piecewise with two knots and two jumps</h2>
<p><strong>This section will illustrate a model with two knots signifying a change of slope and intercept.</strong></p>
<h3 id="51-examples-using-the-gss">5.1 Examples using the GSS</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  mkspline ed1m 12 ed2m 16 ed3m = educ,marginal
</span></span><span class="line"><span class="cl">  reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,183
                                                 F(6, 32176)       =     544.02
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.1458
                                                 Root MSE          =      24991
</code></pre>
<hr>
<pre><code>         |               Robust
realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]

    ed1m |     272.27     105.87     2.57   0.010        64.76      479.79
    ed2m |    1329.81     189.31     7.02   0.000       958.75     1700.88
    ed3m |    2540.17     398.71     6.37   0.000      1758.69     3321.65
  hsgrad |    3925.58     405.81     9.67   0.000      3130.18     4720.98
  cograd |    5740.76     733.17     7.83   0.000      4303.73     7177.80
  female |  -12358.72     276.69   -44.67   0.000    -12901.04   -11816.40
   _cons |   16339.10     988.28    16.53   0.000     14402.04    18276.16
</code></pre>
<hr>
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump.png"title="Adjusted means from piecewise model with knots and jumps at educ = 12 and educ = 16"  />
</div>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  showcoding educ ed1m ed2m ed3m hsgrad cograd
</span></span><span class="line"><span class="cl">  margins,at (ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) ///
</span></span><span class="line"><span class="cl">          at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1) vsquish noatlegend
</span></span></code></pre></td></tr></table>
</div>
</div><div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump1.png"title="showcoding" width = "300" height = "400" />
</div>
<pre><code> Predictive margins                                      Number of obs = 32,183
 Model VCE: Robust

 Expression: Linear prediction, predict()
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]

     _at |
      1  |   10258.62     987.32    10.39   0.000      8323.44    12193.81
      2  |   13525.88     374.93    36.08   0.000     12791.01    14260.75
      3  |   17451.46     157.37   110.90   0.000     17143.02    17759.91
      4  |   23859.81     558.53    42.72   0.000     22765.07    24954.55
      5  |   29600.57     475.61    62.24   0.000     28668.35    30532.79
      6  |   46169.58    1255.73    36.77   0.000     43708.30    48630.87
</code></pre>
<hr>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  preserve
</span></span><span class="line"><span class="cl">  clear
</span></span><span class="line"><span class="cl">  input educ yhat
</span></span><span class="line"><span class="cl">  0 10258.62
</span></span><span class="line"><span class="cl">  12 13525.88
</span></span><span class="line"><span class="cl">  12 17451.46
</span></span><span class="line"><span class="cl">  16 23858.81
</span></span><span class="line"><span class="cl">  16 29600.57
</span></span><span class="line"><span class="cl">  20 46169.58
</span></span><span class="line"><span class="cl">  end
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  graph twoway line yhat educ,xlabel(0(4)20) xline(12 16) xtitle(Education) ytitle(Adjusted means)
</span></span><span class="line"><span class="cl">  restore
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump2.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump2.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump2.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump2.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/two%20jump2.png"
        title="Adjusted means from piecewise model with knots and jumps at educ = 12 and educ = 16" /></p>
<h2 id="6-piecewise-with-an-unknown-knot">6 Piecewise with an unknown knot</h2>
<p>This section illustrates a method for fitting a piecewise model with one knot where the location of the knot is uncertain.</p>
<p>Consider the relationship between year of birth and level of education. In this dataset, the year of birth is recorded in the variable yrborn and education level is recorded in the variable educ. To visualize the relationship between year of birth and education, let’s make a graph showing the mean of educ at each level of yrborn.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  keep if (yrborn&gt;=1905 &amp; yrborn&lt;=1985) &amp; !missing(educ)
</span></span><span class="line"><span class="cl">  reg educ i.yrborn
</span></span><span class="line"><span class="cl">  margins yrborn
</span></span><span class="line"><span class="cl">  marginsplot,noci
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkoownjump.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkoownjump.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkoownjump.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkoownjump.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkoownjump.png"
        title="Average education at each level of year of birth" /></p>
<p>We could haphazardly select different years for the placement of the knot and select the knot that yields the best fitting model. Rather than manually doing this selection process, we can use the <strong>nl command</strong> to <em><strong>automate the process of selecting the optimal knot, by selecting a knot location that yields the lowest residual sum of squares.</strong></em> The code for fitting such a model is shown below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  nl (educ = ({cons} + {b1}*yrborn)*(yrborn&lt;{knot}) + ///
</span></span><span class="line"><span class="cl">  ({cons} + {b1}*{knot} + {b2}*(yrborn-{knot}))*(yrborn&gt;={knot})), ///
</span></span><span class="line"><span class="cl">  initial(knot 1945 b1 .1 b2 -.0125 cons -181)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Iteration 0:  Residual SS = 464140
 Iteration 1:  Residual SS = 464092.3
 Iteration 2:  Residual SS = 464092.3


  Source |      SS            df       MS
                                                Number of obs =     52,873
   Model |  48574.186          3  16191.3952    R-squared     =     0.0947
Residual |  464092.28      52869  8.77815515    Adj R-squared =     0.0947
                                                Root MSE      =   2.962795
   Total |  512666.47      52872  9.69636992    Res. dev.     =   264897.3
</code></pre>
<hr>
<pre><code>    educ | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]

   /cons |    -152.07       3.24   -46.88   0.000      -158.43     -145.71
     /b1 |       0.09       0.00    50.59   0.000         0.08        0.09
   /knot |    1946.97       0.51  3800.38   0.000      1945.96     1947.97
     /b2 |      -0.01       0.00    -2.98   0.003        -0.01       -0.00
</code></pre>
<hr>
<p>Note: Parameter cons is used as a constant term during estimation.</p>
<ul>
<li>The coefficient labeled cons is the constant for the model (the predicted value of educ when yrborn is 0). This value is generally uninteresting.</li>
<li>The coefficient labeled knot is the location of the knot, selected as 1946.97 (which we can round to 1947).</li>
<li>The coefficient labeled b1 is the slope of the relationship between education and year of birth for those born before the knot (before 1947).</li>
<li>The coefficient labeled b2 is the slope for those born in or after 1947.</li>
<li>The key is that 1947 was selected as the optimal location for the knot.</li>
</ul>
<p><strong>How to compute the coef respectively and interpret the graph ?</strong></p>
<blockquote>
<p>In place of educ, you would insert your outcome variable, and in place of yrborn, you would place your predictor variable. Then for the initial() option, you would insert plausible values for knot, b1, b2, and cons. These correspond to <strong>the placement of the knot</strong>, <strong>the slope before the knot</strong>, <strong>the slope after the knot</strong>, and <strong>the constant</strong>, respectively.</p>
</blockquote>
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump1.png"title="Average education with hand-drawn fitted lines"  />
</div>
<ul>
<li>In this example, I used 1945 as the knot. To estimate b1, I looked at the graph and saw that the mean education rose about <strong>4 units</strong> from 1905 to 1945. <strong>Taking a change of 4 units divided by 40 gave me an estimate of 0.1 for b1.</strong></li>
<li>Likewise, I estimated that education declined by about 0.5 units from 1945 to 1985 and divided $-0.5$ units by 40 to yield $-0.0125$ as an estimate of b2.</li>
<li>Finally, to estimate cons I estimated the average education to be 9.5 units at 1905 and then used the estimated slope of 0.1 to estimate the education at year 0 would be $9.5-1905×0.1=-181.$</li>
</ul>
<h2 id="7-piecewise-model-with-multiple-unknown-knots">7 Piecewise model with multiple unknown knots</h2>
<p><strong>This section illustrates the use of piecewise regression models where there could be multiple knots in the relationship between the predictor and outcome, and you have no basis for the placement of the knots.</strong></p>
<p>Consider the relationship between age and income. I would suspect that income would initially rise rapidly with increasing age, hit a peak, and then decline with increasing age.
In such a case, we can intentionally fit a model with too many knots and then progressively remove the superfluous knots.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  keep if age&lt;=80
</span></span><span class="line"><span class="cl">  * Model 0
</span></span><span class="line"><span class="cl">  reg realrinc i.age,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>The test of these indicators is significant, and they have an $R^2$  value of 0.0581. This $R^2$ value is the highest amount of variance we could hope to explain using age as a predictor. <strong>This is because this set of indicators accounts for every tiny bump and drop in the relationship between age and income.</strong></li>
<li>Any simpler model (for example, linear, quadratic, or piecewise) will not account for all the bumps and drops and thus will have a lower $R^2$ .</li>
<li>However, a good model will account for the major bumps and drops and have an $R^2$ that is not too much smaller than the $R^2$ from the indicator model. This is our goal in fitting the piecewise model with multiple knots.</li>
</ul>
<p><strong>Let’s visualize the relationship between age and income. We can do this by using the predict command to create predicted values based on the indicator model, in this case named yhatind.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  predict yhatind
</span></span><span class="line"><span class="cl">  graph twoway line yhatind age,sort xlabel(18 20(5)80)
</span></span><span class="line"><span class="cl">  graph twoway line yhatind age,xlabel(25 30 35 45 55 65) xline(25 30 35 45 55 65)sort
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/multiple%20unknown%20knots.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/multiple%20unknown%20knots.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/multiple%20unknown%20knots.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/multiple%20unknown%20knots.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/multiple%20unknown%20knots.png"
        title="Income predicted from age using indicator model with lines at ages 25, 30, 35, 45, 55, and 65" /></p>
<p><strong>Let’s first fit a model specified by the knots at ages 25, 30, 35, 45, 55, and 65, which we will call model 1.</strong> we will use the <strong>mkspline</strong> command to create knots at each of the ages, and this creates the variables age18to24m to age65to80m.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  model1 : full model*
</span></span><span class="line"><span class="cl">  mkspline age18to24m 25 age25to29m 30 ///
</span></span><span class="line"><span class="cl">           age30to34m 35 age35to44m 45 ///
</span></span><span class="line"><span class="cl">		   age45to54m 55 age55to64m 65 ///
</span></span><span class="line"><span class="cl">           age65to80m=age,marginal
</span></span><span class="line"><span class="cl">  reg realrinc age18to24m-age65to80m,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,100
                                                 F(7, 32092)       =     712.84
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.0559
                                                 Root MSE          =      26153
</code></pre>
<hr>
<pre><code>            |               Robust
   realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]
                                                                               
 age18to24m |    1559.14      66.34    23.50   0.000      1429.10     1689.18
 age25to29m |    -582.00     131.65    -4.42   0.000      -840.04     -323.96
 age30to34m |     -45.67     188.34    -0.24   0.808      -414.82      323.48
 age35to44m |    -494.46     184.93    -2.67   0.008      -856.93     -131.99
 age45to54m |    -310.18     154.30    -2.01   0.044      -612.61       -7.76
 age55to64m |    -827.83     190.35    -4.35   0.000     -1200.93     -454.73
 age65to80m |      -4.33     214.92    -0.02   0.984      -425.59      416.93
      _cons |  -25134.60    1502.49   -16.73   0.000    -28079.54   -22189.66
</code></pre>
<hr>
<p>When a coefficient regarding the change in the slope in the line segments is not significant, <strong>it indicates a knot that can be removed because the slopes before and after the knot are not significantly different. We can use this as a guide for removing superfluous knots.</strong></p>
<p>we can see that the slope for those who are 55 to 64 years old is similar to the slope for those who are 65 years old and older. Thus, the knot at age 65 is not really needed and we can assume one slope from ages 55 to 80.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  *model 2 :drop knot at age 65
</span></span><span class="line"><span class="cl">  drop age18to24m-age65to80m
</span></span><span class="line"><span class="cl">  mkspline age18to24m 25 age25to29m 30 ///
</span></span><span class="line"><span class="cl">           age30to34m 35 age35to44m 45 ///
</span></span><span class="line"><span class="cl">		   age45to54m 55 age55to80m=age,marginal
</span></span><span class="line"><span class="cl">  reg realrinc age18to24m-age55to80m,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,100
                                                 F(6, 32093)       =     830.57
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.0559
                                                 Root MSE          =      26152
</code></pre>
<hr>
<pre><code>            |               Robust
   realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]

 age18to24m |    1559.15      66.34    23.50   0.000      1429.11     1689.18
 age25to29m |    -582.03     131.64    -4.42   0.000      -840.05     -324.01
 age30to34m |     -45.57     188.23    -0.24   0.809      -414.50      323.36
 age35to44m |    -494.68     184.31    -2.68   0.007      -855.94     -133.42
 age45to54m |    -309.49     146.24    -2.12   0.034      -596.12      -22.87
 age55to80m |    -829.99     133.15    -6.23   0.000     -1090.96     -569.01
      _cons |  -25134.71    1502.46   -16.73   0.000    -28079.59   -22189.83
</code></pre>
<hr>
<p>In model 2, the coefficient for age30to34m is not significant. This suggests that the slope for those aged 30 to 34 are not different from those aged 25 to 29. Let’s consolidate the slope for the ages 25 to 35 and refit the model, calling it model 3.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  *model 3 :drop knot at age 30
</span></span><span class="line"><span class="cl">  drop age18to24m-age55to80m
</span></span><span class="line"><span class="cl">  mkspline age18to24m 25 age25to34m 35 ///
</span></span><span class="line"><span class="cl">           age35to44m 45 age45to54m 55 ///
</span></span><span class="line"><span class="cl">		   age55to80m=age,marginal
</span></span><span class="line"><span class="cl">  reg realrinc age18to24m-age55to80m,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,100
                                                 F(5, 32094)       =     961.72
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.0559
                                                 Root MSE          =      26152
</code></pre>
<hr>
<pre><code>              |               Robust
     realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]

   age18to24m |    1570.77      66.99    23.45   0.000      1439.47     1702.07
   age25to34m |    -617.88     105.51    -5.86   0.000      -824.69     -411.08
   age35to44m |    -520.35     108.28    -4.81   0.000      -732.58     -308.11
   age45to54m |    -303.91     139.22    -2.18   0.029      -576.79      -31.03
   age55to80m |    -831.48     132.55    -6.27   0.000     -1091.27     -571.68
        _cons |  -25377.50    1512.81   -16.78   0.000    -28342.66   -22412.33
</code></pre>
<hr>
<p>we should be mindful that we have a <strong>very large-sample size with considerable statistical power to detect minor changes in slopes.</strong> If we focus solely on statistical significance as our guide for removing knots,we could <strong>overfit the model.</strong> Let’s visualize the fit of this model against the mean of income at each level of age to see how well the model fits.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  predict yhat
</span></span><span class="line"><span class="cl">  line yhat yhatind age,sort xline(25 35 45 55) xlabel(25 35 45 55) ///
</span></span><span class="line"><span class="cl">  legend(label(1 &#34;piecewise model&#34;)label(2 &#34;indicator model&#34;))
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump3.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump3.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump3.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump3.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/unkownjump3.png"
        title="Income predicted from age using indicator model and piecewise model 3 with four knots at 25, 35, 45, and 55" /></p>
<p>For the sake of creating a parsimonious model, let’s try removing the knot at age 45. This fits one slope for those who are 35 to 54 years old. Let’s call this model 4.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  *model 4:drop knot at age 45
</span></span><span class="line"><span class="cl">  drop age18to24m-age55to80m
</span></span><span class="line"><span class="cl">  mkspline age18to24m 25 age25to34m 35 ///
</span></span><span class="line"><span class="cl">           age35to54m 55 age55to80m=age,marginal
</span></span><span class="line"><span class="cl">  reg realrinc age18to24m-age55to80m,vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Linear regression                               Number of obs     =     32,100
                                                 F(4, 32095)       =    1201.52
                                                 Prob &gt; F          =     0.0000
                                                 R-squared         =     0.0557
                                                 Root MSE          =      26154
</code></pre>
<hr>
<pre><code>            |               Robust
   realrinc | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]

 age18to24m |    1526.97      66.45    22.98   0.000      1396.73     1657.21
 age25to34m |    -503.65     101.85    -4.95   0.000      -703.28     -304.02
 age35to54m |    -736.21      72.34   -10.18   0.000      -878.01     -594.42
 age55to80m |   -1047.58      78.90   -13.28   0.000     -1202.23     -892.94
      _cons |  -24462.77    1502.23   -16.28   0.000    -27407.21   -21518.34
</code></pre>
<hr>
<h2 id="8-automating-graphs-of-piecewise-models">8 Automating graphs of piecewise models</h2>
<p>If you change your data (for example, fix incorrect values), the adjusted means will not be automatically updated to reflect the new data.<strong>This section illustrates a more efficient, but trickier, way of creating such graphs that does not require retyping the data.</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  mkspline ed1m 12 ed2m 16 ed3m = educ,marginal
</span></span><span class="line"><span class="cl">  reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust)
</span></span><span class="line"><span class="cl">  margins,at(ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=1 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=13 ed2m=1 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=17 ed2m=5 ed3m=1 hsgrad=1 cograd=1) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1)
</span></span><span class="line"><span class="cl">		  
</span></span></code></pre></td></tr></table>
</div>
</div><p>The following steps <strong>save the adjusted means from the margins command, as well as the corresponding values of education into the active dataset.</strong> The graph command is then used to graph the adjusted means by education, creating the graph shown below</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  matrix yhat = r(b)&#39;
</span></span><span class="line"><span class="cl">  svmat yhat
</span></span><span class="line"><span class="cl">  matrix educ = ( 0 \ 1 \ 12 \ 12 \ 13 \ 16 \ 16 \ 17 \ 20 )
</span></span><span class="line"><span class="cl">  svmat educ
</span></span><span class="line"><span class="cl">  graph twoway line yhat1 educ1, xline(12 16) xtitle(Education) ytitle(Adjusted mean)
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/automating%20graph%20of%20piecewise%20model.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/automating%20graph%20of%20piecewise%20model.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/automating%20graph%20of%20piecewise%20model.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/automating%20graph%20of%20piecewise%20model.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/automating%20graph%20of%20piecewise%20model.png"
        title="Adjusted means from piecewise regression with two knots and two jumps" /></p>
<p>Let’s walk through this process again, but do so more slowly.</p>
<ul>
<li>First, repeat the use gss_ivrm command, as well as the mkspline, regress, and margins commands from above.</li>
<li>Now, the adjusted means computed by the margins command are stored in a matrix named r(b) with one row and nine columns, corresponding to the nine values specified with the at() option.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  use gss_ivrm.dta
</span></span><span class="line"><span class="cl">  mkspline ed1m 12 ed2m 16 ed3m = educ,marginal
</span></span><span class="line"><span class="cl">  reg realrinc ed1m ed2m ed3m hsgrad cograd female,vce(robust)
</span></span><span class="line"><span class="cl">  margins,at(ed1m=0 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">          at(ed1m=1 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=12 ed2m=0 ed3m=0 hsgrad=0 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=12 ed2m=0 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=13 ed2m=1 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=0) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=16 ed2m=4 ed3m=0 hsgrad=1 cograd=1) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=17 ed2m=5 ed3m=1 hsgrad=1 cograd=1) ///
</span></span><span class="line"><span class="cl">		      at(ed1m=20 ed2m=8 ed3m=4 hsgrad=1 cograd=1)
</span></span><span class="line"><span class="cl">	matrix list r(b)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> r(b)[1,9]
             1.         2.         3.         4.         5.         6.         7.         8.         9.
           _at        _at        _at        _at        _at        _at        _at        _at        _at
 r1  10258.623  10530.894  13525.881  17451.464   19053.55   23859.81  29600.571  33742.824  46169.582
</code></pre>
<p>Let’s store these adjusted means as a matrix called yhat and in the process transpose the matrix (converting the columns to rows).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  matrix yhat = r(b)&#39;
</span></span><span class="line"><span class="cl">  matrix list yhat
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> yhat[9,1]
               r1
 1._at  10258.623
 2._at  10530.894
 3._at  13525.881
 4._at  17451.464
 5._at  19053.55
 6._at  23859.81
 7._at  29600.571
 8._at  33742.824
 9._at  46169.582
</code></pre>
<p>We can then save yhat into the current dataset with the <strong>svmat</strong> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  svmat yhat
</span></span><span class="line"><span class="cl">  list yhat1 in 1/10
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>      +----------+
      |    yhat1 |
      |----------|
 1.   | 10258.62 |
 2.   | 10530.89 |
 3.   | 13525.88 |
 4.   | 17451.46 |
 5.   | 19053.55 |
 6.   | 23859.81 |
 7.   | 29600.57 |
 8.   | 33742.82 |
 9.   | 46169.58 |
 10.  |        . |
      +----------+
</code></pre>
<p>Now, let’s make a matrix containing the values of education. <strong>This is stored in the matrix named educ. We then save this matrix into the dataset,</strong> as shown below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  matrix educ = (0 \ 1 \ 12 \ 12 \ 13 \ 16 \ 16 \ 17 \ 20)
</span></span><span class="line"><span class="cl">  svmat educ
</span></span><span class="line"><span class="cl">  list yhat1 educ1 in 1/10
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>     +------------------+
     |    yhat1   educ1 |
     |------------------|
  1. | 10258.62       0 |
  2. | 10530.89       1 |
  3. | 13525.88      12 |
  4. | 17451.46      12 |
  5. | 19053.55      13 |
  6. | 23859.81      16 |
  7. | 29600.57      16 |
  8. | 33742.82      17 |
  9. | 46169.58      20 |
 10. |        .       . |
     +------------------+
</code></pre>
<p>Now, we can graph the adjusted means, called yhat1, by the levels of education, called educ1, as shown below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">  graph twoway line yhat1 educ1, xline(12 16)xtitle(Education) ytitle(Adjusted mean)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Although the process of creating this graph is more complicated, <strong>the benefit is that it will automatically be updated if the dataset changes. This can be a little more work in the short run but saves us time in the long run.</strong></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2023-12-31</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/3.continuous-predictors_piecewise-models/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/continuous-predictors/">Continuous predictors</a>,&nbsp;<a href="/tags/stata/">stata</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2.continuous-predictors_polynomials/" class="prev" rel="prev" title="Chapter3 ：Continuous predictors: Polynomials"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>Chapter3 ：Continuous predictors: Polynomials</a>
            <a href="/5.continuous-by-continuous-interactions/" class="next" rel="next" title="Chapter5 ：Continuous by continuous interactions">Chapter5 ：Continuous by continuous interactions<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2023 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Alex_Wang</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"valine":{"appId":"QGzwQXOqs5JOhN4RGPOkR2mR-MdYXbMMI","appKey":"WBmoGyJtbqUswvfLh6L8iEBr","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"zh-CN","pageSize":10,"placeholder":"你的评论 ...","recordIP":true,"serverURLs":"https://leancloud.hugoloveit.com","visitor":true}},"lightgallery":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
