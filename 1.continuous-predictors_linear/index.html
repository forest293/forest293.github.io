<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Chapter2 ：Continuous predictors:Linear - Alex_Wang</title><meta name="Description" content="This Chapter focuses on how interpret the coefficient of a continuous predictor in a linear regression models. "><meta property="og:title" content="Chapter2 ：Continuous predictors:Linear" />
<meta property="og:description" content="This Chapter focuses on how interpret the coefficient of a continuous predictor in a linear regression models. " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forest293.github.io/1.continuous-predictors_linear/" /><meta property="og:image" content="https://forest293.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-09T16:29:41+08:00" />
<meta property="article:modified_time" content="2023-12-09T23:45:40+08:00" /><meta property="og:site_name" content="Alex_Wang" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://forest293.github.io/logo.png"/>

<meta name="twitter:title" content="Chapter2 ：Continuous predictors:Linear"/>
<meta name="twitter:description" content="This Chapter focuses on how interpret the coefficient of a continuous predictor in a linear regression models. "/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://forest293.github.io/1.continuous-predictors_linear/" /><link rel="prev" href="https://forest293.github.io/theme-documentation-basics/" /><link rel="next" href="https://forest293.github.io/2.continuous-predictors_polynomials/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Chapter2 ：Continuous predictors:Linear",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/forest293.github.io\/1.continuous-predictors_linear\/"
        },"image": ["https:\/\/forest293.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "Continuous predictors, stata","wordcount":  2959 ,
        "url": "https:\/\/forest293.github.io\/1.continuous-predictors_linear\/","datePublished": "2023-12-09T16:29:41+08:00","dateModified": "2023-12-09T23:45:40+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/forest293.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Alex_Wang"
            },"description": "This Chapter focuses on how interpret the coefficient of a continuous predictor in a linear regression models. "
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Alex_Wang">Alex Wang</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/categories/documentation/"> 文档 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a><a href="javascript:void(0);" class="menu-item language" title="选择语言">
                    <i class="fa fa-globe" aria-hidden="true"></i>                      
                    <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/1.continuous-predictors_linear/" selected>简体中文</option></select>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Alex_Wang">Alex Wang</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/categories/documentation/" title="">文档</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="选择语言">
                    <i class="fa fa-globe fa-fw" aria-hidden="true"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/1.continuous-predictors_linear/" selected>简体中文</option></select>
                </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Chapter2 ：Continuous predictors:Linear</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Alex_Wang</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/interpreting-and-visualizing-regression-models-using-stata/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Interpreting and Visualizing Regression Models Using Stata</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2023-12-09">2023-12-09</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 2959 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 14 分钟&nbsp;<span id="/1.continuous-predictors_linear/" class="leancloud_visitors" data-flag-title="Chapter2 ：Continuous predictors:Linear">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-simple-linear-regression">1 Simple linear regression</a>
      <ul>
        <li><a href="#11-computing-predicted-means-using-the-margins-command">1.1 Computing predicted means using the margins command</a></li>
        <li><a href="#12-graphing-predicted-means-using-the-marginsplot-command">1.2 Graphing predicted means using the marginsplot command</a></li>
      </ul>
    </li>
    <li><a href="#2-multiple-regression">2 Multiple regression</a>
      <ul>
        <li><a href="#21-computing-adjusted-means-using-the-margins-command">2.1 Computing adjusted means using the margins command</a></li>
      </ul>
    </li>
    <li><a href="#3-checking-for-nonlinearity-graphically">3 Checking for nonlinearity graphically</a>
      <ul>
        <li><a href="#31-using-scatterplots-to-check-for-nonlinearity">3.1 Using scatterplots to check for nonlinearity</a></li>
        <li><a href="#32-checking-for-nonlinearity-using-residuals">3.2 Checking for nonlinearity using residuals</a></li>
        <li><a href="#33-checking-for-nonlinearity-using-locally-weighted-smoother">3.3 Checking for nonlinearity using locally weighted smoother</a></li>
        <li><a href="#34-graphing-outcome-mean-at-each-level-of-predictor">3.4 Graphing outcome mean at each level of predictor</a></li>
      </ul>
    </li>
    <li><a href="#4-checking-for-nonlinearity-analytically">4 Checking for nonlinearity analytically</a>
      <ul>
        <li><a href="#41-adding-power-terms">4.1 Adding power terms</a></li>
        <li><a href="#42-using-factor-variables">4.2 Using factor variables</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><em><strong>This Chapter focuses on how to interpret the coefficient of a continuous predictor in a linear regression model.</strong></em></p>
<h2 id="1-simple-linear-regression">1 Simple linear regression</h2>
<p><strong>This section illustrates the use of a continuous predictor for predicting a continuous outcome using ordinary least-squares regression.</strong></p>
<blockquote>
<p>Terminology: Continuous and categorical variables</p>
<blockquote>
<p>When I use the termcontinuous variable, I am referring to a variable that is measured on an
interval or ratio scale.
By contrast, when I speak of a categorical variable,I am referring to either a nominal variable or an ordinal/interval/ratio variable that we wish to treat as though it were a nominal variable.</p>
</blockquote>
</blockquote>
<p>Let’s run a simple regression model in which we predict the education of the respondent from the education of the respondent’s father.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    regress educ paeduc
</span></span></code></pre></td></tr></table>
</div>
</div><p>The result as shown below</p>
<pre><code>  Source |       SS           df       MS      Number of obs   =       696
                                               F(1, 694)       =    228.14
   Model |  1649.70181         1  1649.70181   Prob &gt; F        =    0.0000
Residual |  5018.43038       694  7.23116769   R-squared       =    0.2474
                                               Adj R-squared   =    0.2463
   Total |  6668.13218       695   9.5944348   Root MSE        =    2.6891
</code></pre>
<hr>
<pre><code>    educ | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]

  paeduc |      0.359      0.024    15.10   0.000        0.313       0.406
   _cons |      9.740      0.286    34.08   0.000        9.179      10.301
</code></pre>
<hr>
<p>The regression equation can be written as shown below</p>
<p>$$ \widehat{educ}=9.74 + 0.36paeduc $$</p>
<p>The intercept is the predicted mean of the respondent’s education when the father’s education is <strong>0</strong>. For
<strong>every one-year increase in the education of the father</strong>, we would predict that the education of the respondent increases by 0.36 years.</p>
<h3 id="11-computing-predicted-means-using-the-margins-command">1.1 Computing predicted means using the margins command</h3>
<p>Suppose we wanted to compute the predicted mean of education for the respondent, assuming separately that the father had 8, 12, or 16 years of education.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    margins,at (paeduc=(8 12 16)) vsquish
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Note: The <strong>vsquish</strong> option</p>
<blockquote>
<p>The vsquish option vertically <strong>squishes the output by omitting extra blank lines.</strong></p>
</blockquote>
</blockquote>
<pre><code>Adjusted predictions                                       Number of obs = 696
Model VCE: OLS

Expression: Linear prediction, predict()
1._at: paeduc =  8
2._at: paeduc = 12
3._at: paeduc = 16

         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]

     _at |
      1  |     12.616      0.128    98.93   0.000       12.365      12.866
      2  |     14.053      0.104   135.64   0.000       13.850      14.257
      3  |     15.491      0.153   101.42   0.000       15.191      15.791
</code></pre>
<hr>
<p>Sometimes, we might want to compute the predicted means given a range of values for a predictor. For example, we might want to compute the predicted means when father’s education is 0, 4, 8, 12, 16, and 20.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      margins,at(paeduc=(0(4)20)) vsquish
</span></span></code></pre></td></tr></table>
</div>
</div><p>Rather than typing all of these values, we can <strong>specify 0(4)20</strong>, which tells Stata that <strong>we mean 0 to 20 in 4-unit increments</strong>.</p>
<pre><code>Adjusted predictions                                       Number of obs = 696
Model VCE: OLS

Expression: Linear prediction, predict()
1._at: paeduc =  0
2._at: paeduc =  4
3._at: paeduc =  8
4._at: paeduc = 12
5._at: paeduc = 16
6._at: paeduc = 20
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]

     _at |
      1  |      9.740      0.286    34.08   0.000        9.179      10.301
      2  |     11.178      0.200    55.95   0.000       10.786      11.570
      3  |     12.616      0.128    98.93   0.000       12.365      12.866
      4  |     14.053      0.104   135.64   0.000       13.850      14.257
      5  |     15.491      0.153   101.42   0.000       15.191      15.791
      6  |     16.929      0.232    72.82   0.000       16.472      17.385
</code></pre>
<hr>
<h3 id="12-graphing-predicted-means-using-the-marginsplot-command">1.2 Graphing predicted means using the marginsplot command</h3>
<p>We can use the <strong>marginsplot</strong> command to create a graph showing the predicted means and confidence intervals based on the most recent margins command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    marginsplot
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Note：The margins and marginsplot commands work together as a team.</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot.png"
        title="marginsplot" /></p>
<p>Let’s now create a graph that shows the <strong>fitted line</strong> with a <strong>shaded confidence interval</strong>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    margins,at(paeduc=(0(1)20))
</span></span><span class="line"><span class="cl">    marginsplot,recast(line) recastci(rarea)
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <strong>recast()</strong> option specifies that the fitted line should be displayed as a line graph (suppressing the markers). The <strong>recastci()</strong> option specifies that the confidence interval should be displayed as an rarea graph, displaying a shaded area for the confidence region.</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot2.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot2.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot2.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot2.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot2.png"
        title="marginsplot" /></p>
<h2 id="2-multiple-regression">2 Multiple regression</h2>
<p>Let’s now turn to a multiple regression model that predicts the respondent’s education from the father’s
education (paeduc), the mother’s education (maeduc), and the age of the respondent (age).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    reg educ paeduc maeduc age
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>  Source |       SS           df       MS      Number of obs   =       650
                                               F(3, 646)       =     92.93
   Model |  1822.26082         3  607.420272   Prob &gt; F        =    0.0000
Residual |  4222.37918       646  6.53619069   R-squared       =    0.3015
                                               Adj R-squared   =    0.2982
   Total |     6044.64       649  9.31377504   Root MSE        =    2.5566
</code></pre>
<hr>
<pre><code>    educ | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]

  paeduc |      0.258      0.033     7.82   0.000        0.193       0.323
  maeduc |      0.208      0.038     5.48   0.000        0.133       0.282
     age |      0.034      0.007     5.28   0.000        0.022       0.047
   _cons |      6.962      0.511    13.63   0.000        5.959       7.965
</code></pre>
<hr>
<p>The equation as shown below</p>
<p>$$ \widehat{educ}=6.86 + 0.26paeduc + 0.21maeduc + 0.03age $$</p>
<p>The coefficients from this multiple regression model reflect the association between each predictor and the outcome after adjusting for all the other predictors.</p>
<h3 id="21-computing-adjusted-means-using-the-margins-command">2.1 Computing adjusted means using the margins command</h3>
<p>The margins command allows us to hold more than one variable constant at a time. In the example below, we compute the adjusted means when the father’s education equals 8, 12, and 16, while holding the mother’s education constant at 14.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    reg educ paeduc maeduc age
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> Predictive margins                                         Number of obs = 650
 Model VCE: OLS

 Expression: Linear prediction, predict()
 1._at: paeduc =  8
        maeduc = 14
 2._at: paeduc = 12
        maeduc = 14
 3._at: paeduc = 16
        maeduc = 14
</code></pre>
<hr>
<pre><code>         |            Delta-method
         |     Margin   std. err.      t    P&gt;|t|     [95% conf. interval]
     _at |
      1  |     13.544      0.211    64.18   0.000       13.130      13.958
      2  |     14.576      0.128   113.76   0.000       14.325      14.828
      3  |     15.609      0.152   102.52   0.000       15.310      15.908
</code></pre>
<hr>
<blockquote>
<p>Terminology: Adjusted means</p>
<blockquote>
<p>For example, we can say that the predicted mean, given the father has 8 years of education, is 13.544 after adjusting for all other predictors. We could also call this an adjusted mean.</p>
<blockquote>
<p>The term adjusted mean implies after adjusting for all other predictors in the model. When using nonlinear models (such as a logistic regression model), we will use a more general term, such as <strong>predictive margin</strong>.</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="3-checking-for-nonlinearity-graphically">3 Checking for nonlinearity graphically</h2>
<p>This section illustrates <strong>graphical approaches</strong> for checking for <strong>nonlinearity</strong> in the relationship between a predictor and outcome variable. These approaches include</p>
<ol>
<li><strong>examining scatterplots of the predictor and outcome.</strong></li>
<li><strong>examining residual-versusfitted plots.</strong></li>
<li><strong>creating plots based on locally weighted smoothers.</strong></li>
<li><strong>plotting the mean of the outcome for each level of the predictor.</strong></li>
</ol>
<h3 id="31-using-scatterplots-to-check-for-nonlinearity">3.1 Using scatterplots to check for nonlinearity</h3>
<p>Let’s look at a scatterplot of the size of the engine (displacement) by length of the car (length) with a line showing the linear fit, as shown in figure</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    use autosubset
</span></span><span class="line"><span class="cl">    graph twoway (scatter displacement length) (lfit displacement length),ytitle(&#34;Engine displacement(cu in.) &#34;) legend (off) 
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot3.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot3.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot3.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot3.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot3.png"
        title="Scatterplot of engine displacement by car length with linear fit line" /></p>
<p>The relationship between these two variables looks fairly linear, but the addition of the linear fit line helps us to see the nonlinearity. Note how for short cars (whenlength is below 160) the fit line underpredicts and for longer cars (when length is above 210) the fit line also underpredicts.</p>
<p>Using a scatterplot like this can be a simple means of looking at the linearity of the simple relationship between a predictor and outcome variable. However, this <strong>does not account for other predictors that you might want to include in a model</strong>. To this end, let’s next look at how we can use the <strong>residuals</strong> for checking linearity</p>
<h3 id="32-checking-for-nonlinearity-using-residuals">3.2 Checking for nonlinearity using residuals</h3>
<p>For example, let’s run a regression predicting displacement from length, trunk, and weight, as shown below</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      reg displacement length trunk weight
</span></span></code></pre></td></tr></table>
</div>
</div><p>We can then look at the residuals versus the fitted values, as shown in figure</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">     rvfplot
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/residual.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/residual.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/residual.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/residual.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/residual.png"
        title="Residual-versus-fitted plot of engine displacement by car length, trunk size, and weight" /></p>
<p>Note the <strong>U-shaped pattern</strong> of the residuals. This pattern suggests that the relationship between the predictors and outcome is <strong>not linear</strong>.</p>
<p>There are many excellent resources that illustrate Stata’s regression diagnostic tools, including the manual entry for [R] regress postestimation. You can also see the help entries for avplot, rvfplot, and rvpplot.</p>
<h3 id="33-checking-for-nonlinearity-using-locally-weighted-smoother">3.3 Checking for nonlinearity using locally weighted smoother</h3>
<p>With larger datasets, it can be harder to visualize nonlinearity using scatterplots or residual-versus-fitted plots.
Suppose we want to determine the nature of the relationship between the year that the respondent was born (yrborn) and education level (educ).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      use gss_ivrm.dta
</span></span><span class="line"><span class="cl">      scatter educ yrborn,msymbol(oh)
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter.png"
        title="Scatterplot of education by year of birth" /></p>
<p>It is hard to discern the nature of the relationship between year of birth and education using this scatterplot. With so many observations, the scatterplot is saturated with data points creating one big blotch that tells us little about the shape of the relationship between the predictor and outcome</p>
<p>The <strong>lowess command</strong> below creates a graph showing the <strong>locally weighted regression</strong> of education on year of birth, as shown in figure</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    lowess educ yrborn,msymbol(p)
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter2.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter2.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter2.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter2.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/scatter2.png"
        title="Locally weighted regression of education by year of birth" /></p>
<p>The lowess graph suggests that there is nonlinearity in the relationship between year of birth and education. Education increases with year of birth until the 1950s, at which point the smoothed education values level out and then start to decline. The graph produced by the lowess command is much more informative than the scatterplot alone.</p>
<h3 id="34-graphing-outcome-mean-at-each-level-of-predictor">3.4 Graphing outcome mean at each level of predictor</h3>
<p>Another way to visualize the relationship between the predictor and outcome is to <strong>create a graph showing the mean of the outcome at each level of the predictor</strong>.</p>
<p>Using the example predicting education from year of birth means creating a graph of the average of education at each level of year of birth.</p>
<p>Although the variable yrborn can assume many values (from 1883 to 1990), the variable is composed of discrete integers with reasonably many observations (usually more than 100) for each value. In such a case, we can explore the nature of the relationship between the predictor and outcome by <strong>creating a graph of the mean of the outcome variable (education level) for each level of the predictor (year of birth)</strong>. This kind of graph imposes no structure on the shape of the relationship between year of birth and education and allows us to <strong>observe the nature of the relationship between the predictor and the outcome</strong>.</p>
<p>One simple way to create such a graph is to fit a regression model predicting the outcome <strong>treating the predictor variable as a factor variable</strong>.
Following that, the margins command is used to <strong>obtain the predicted mean of the outcome for each level of the predictor</strong>. In the regress command below, <strong>specifying i.yrborn indicates that the variable yrborn should be treated as a factor variable</strong>. The following margins command computes the predicted mean of the outcome (education) at each year of birth</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      reg educ i.yrborn
</span></span><span class="line"><span class="cl">      margins yrborn
</span></span><span class="line"><span class="cl">      marginsplot
</span></span></code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot4.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot4.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot4.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot4.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/marginsplot4.png"
        title="Mean education by year of birth" /></p>
<p>The predicted means vary erratically for the years before 1900 because of the <strong>few observations per year during those years</strong>. For these years, the confidence intervals are much wider compared with later years, reflecting <strong>greater uncertainty of the estimates because of fewer observations</strong>.</p>
<p>If all the years had such few observations, then the entire graph <strong>might be dominated by wild swings in the means and show little about the nature of the relationship between the predictor and outcome.</strong></p>
<h2 id="4-checking-for-nonlinearity-analytically">4 Checking for nonlinearity analytically</h2>
<p>This section shows how to check for nonlinearity using analytic approaches, including adding power terms and using factor variables.</p>
<h3 id="41-adding-power-terms">4.1 Adding power terms</h3>
<p>Another way to check for nonlinearity of a continuous variable is to add power terms (for example, quadratic or cubic).</p>
<p>Using the example with education as a function of year of birth.
Let’s introduce a quadratic term (in addition to the linear term) by adding c.yrborn#c.yrborn to the model. This introduces a quadratic effect that would account for <strong>one bend</strong> in the line relating year of birth to education. We would expect the quadratic term to be significant based on the graphs we saw in figures</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      use gss_ivrm.dta
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>  Source |       SS           df       MS      Number of obs   =    54,745
                                               F(2, 54742)     =   3567.49
   Model |  63778.2779         2  31889.1389   Prob &gt; F        =    0.0000
Residual |  489328.985    54,742  8.93882184   R-squared       =    0.1153
                                               Adj R-squared   =    0.1153
   Total |  553107.263    54,744   10.103523   Root MSE        =    2.9898
</code></pre>
<hr>
<pre><code>              educ | Coefficient  Std. err.      t    P&gt;|t|

            yrborn |      4.218      0.102    41.46   0.000
                   |
 c.yrborn#c.yrborn |     -0.001      0.000   -41.00   0.000
                   |
             _cons |  -4129.000     98.816   -41.78   0.000
</code></pre>
<hr>
<blockquote>
<p>Note! Using the noci option for <strong>clearer output</strong></p>
<blockquote>
<p>When models include interactions,those labels can get rather wide, and Stata is forced to display those labels across multiple lines, which can make the output confusing and hard to read.
This omits the display of the confidence intervals, which makes enough room to display the label for every term in the model in a single line. <strong>but!,the confidence interval are also important for our research.</strong></p>
</blockquote>
</blockquote>
<p>The quadratic term is significant in this model.Furthermore, the R2 for this model increased to 0.1153 compared with 0.0881 for the linear model. This provides analytic support for including a quadratic term for year of birth when predicting education.</p>
<p>A cubic term would imply that the line fitting year of birth and education has a tendency to have two bends in it.c.yrborn##c.yrborn##c.yrborn as a predictor is a shorthand for including the linear, quadratic, and cubic terms for year of birth (yrborn).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    reg educ c.yrborn##c.yrborn##c.yrborn,noci
</span></span></code></pre></td></tr></table>
</div>
</div><p>note: c.yrborn#c.yrborn#c.yrborn omitted because of <strong>collinearity</strong>.</p>
<pre><code>  Source |       SS           df       MS      Number of obs   =       926
                                               F(2, 923)       =     11.47
   Model |  219.843988         2  109.921994   Prob &gt; F        =    0.0000
Residual |  8846.14737       923    9.584125   R-squared       =    0.0242
                                               Adj R-squared   =    0.0221
   Total |  9065.99136       925  9.80107174   Root MSE        =    3.0958
</code></pre>
<hr>
<pre><code>                       educ | Coefficient  Std. err.      t    P&gt;|t|

                     yrborn |      6.159      1.287     4.79   0.000
                            |
          c.yrborn#c.yrborn |     -0.002      0.000    -4.79   0.000
                            |
 c.yrborn#c.yrborn#c.yrborn |      0.000  (omitted)
                            |
                      _cons |  -6015.618   1259.800    -4.78   0.000
</code></pre>
<hr>
<p>There was a problem running this model. There is a note saying that the cubic term was omitted because of <strong>collinearity</strong>. This is a common problem when entering cubic terms, which can be solved by <strong>centering yrborn</strong>. The dataset includes a variable called yrborn40, which is <strong>the variable yrborn centered around the year 1940 (that is, 1940 is subtracted from each value of yrborn).</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">       reg educ c.yrborn40##c.yrborn40##c.yrborn40,noci
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>  Source |       SS           df       MS      Number of obs   =       926
                                               F(3, 922)       =      7.72
   Model |  222.175819         3  74.0586064   Prob &gt; F        =    0.0000
Residual |  8843.81554       922  9.59199083   R-squared       =    0.0245
                                               Adj R-squared   =    0.0213
   Total |  9065.99136       925  9.80107174   Root MSE        =    3.0971
</code></pre>
<hr>
<pre><code>                             educ | Coefficient  Std. err.      t    P&gt;|t|

                         yrborn40 |      0.058      0.014     4.20   0.000
                                  |
            c.yrborn40#c.yrborn40 |     -0.002      0.001    -2.14   0.033
                                  |
 c.yrborn40#c.yrborn40#c.yrborn40 |      0.000      0.000     0.49   0.622
                                  |
                            _cons |     13.427      0.201    66.87   0.000
</code></pre>
<hr>
<p>The results show, as expected, that the cubic term is significant. However, this dataset has many observations, so the model has the statistical power to detect very small effects. Note how the is 0.1162 for the cubic model compared with 0.1153 for the quadratic model. This is a <strong>trivial increase</strong>, suggesting that the cubic trend is not really an important term to include in this model.</p>
<h3 id="42-using-factor-variables">4.2 Using factor variables</h3>
<p>The strategy of using factor variables to check for nonlinearity makes sense <strong>only when you have a relatively limited number of levels of the predictor that are coded as whole numbers.</strong></p>
<p>let’s perform an analysis to <strong>detect any kind of nonlinearity</strong> in the relationship between decade of age and health status.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      use gss_ivrm.dta
</span></span><span class="line"><span class="cl">      reg health c.agedec i.agedec
</span></span></code></pre></td></tr></table>
</div>
</div><p>note: 8.agedec omitted because of collinearity.</p>
<pre><code>  Source |       SS           df       MS      Number of obs   =    40,984
                                               F(7, 40976)     =    451.59
   Model |  2111.10121         7  301.585887   Prob &gt; F        =    0.0000
Residual |  27364.9308    40,976  .667828261   R-squared       =    0.0716
                                               Adj R-squared   =    0.0715
   Total |   29476.032    40,983  .719225826   Root MSE        =    .81721
</code></pre>
<hr>
<pre><code>  health | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]

  agedec |     -0.098      0.005   -18.46   0.000       -0.108      -0.087
         |
  agedec |
    20s  |      0.110      0.028     3.97   0.000        0.055       0.164
    30s  |      0.165      0.024     6.85   0.000        0.118       0.212
    40s  |      0.135      0.022     6.24   0.000        0.093       0.178
    50s  |      0.065      0.021     3.15   0.002        0.025       0.106
    60s  |     -0.006      0.021    -0.28   0.783       -0.047       0.036
    70s  |     -0.038      0.024    -1.60   0.110       -0.084       0.009
    80s  |      0.000  (omitted)
         |
   _cons |      3.320      0.035    95.81   0.000        3.253       3.388
</code></pre>
<hr>
<p>This unconventional-looking model divides the relationship between the age decade and the outcome into two pieces:</p>
<ol>
<li>the linear relationship, which is accounted for by c.agedec</li>
<li>any remaining nonlinear components, which are explained by the indicator variables specified by i.agedec.</li>
</ol>
<p>Let’s now use the <strong>testparm</strong> command to perform a test of the indicator variables, giving us an <strong>overall test of the nonlinearity</strong> in the relationship between age decade and health status.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">     testparm i.agedec  
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code> (1)  2.agedec = 0
 (2)  3.agedec = 0
 (3)  4.agedec = 0
 (4)  5.agedec = 0
 (5)  6.agedec = 0
 (6)  7.agedec = 0

   F(  6, 40976) =   20.61
        Prob &gt; F =    0.0000
</code></pre>
<p>This general strategy tells us that there is nonlinearity between the age decade and health status but does not pinpoint the exact nature of the nonlinearity.</p>
<p>Let’s try another strategy that will <strong>pinpoint the nature of the nonlinearity.</strong> And use the contrast command with the p. contrast operator to obtain a detailed breakdown of possible nonlinear trends in the relationship between the age decade and health status</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">     reg health i.agedec
</span></span><span class="line"><span class="cl">     contrast p.agedec
</span></span></code></pre></td></tr></table>
</div>
</div><p>Contrasts of marginal linear predictions</p>
<p>Margins: asbalanced</p>
<hr>
<pre><code>                  |         df           F        P&gt;F

      agedec      |
     (linear)     |          1     1187.58     0.0000
     (quadratic)  |          1       26.65     0.0000
     (cubic)      |          1       52.99     0.0000
     (quartic)    |          1        1.18     0.2778
     (quintic)    |          1        1.00     0.3179
     (sextic)     |          1        0.15     0.6959
     (septic)     |          1        0.02     0.8748
      Joint       |          7      451.59     0.0000
                  |
      Denominator |      40976
</code></pre>
<hr>
<hr>
<pre><code>             |    Contrast    Std. err.     [95% conf. interval]

    agedec   |
 (linear)    |     -0.260      0.008        -0.275      -0.245
 (quadratic) |     -0.038      0.007        -0.053      -0.024
 (cubic)     |      0.047      0.006         0.034       0.059
 (quartic)   |      0.006      0.005        -0.005       0.016
 (quintic)   |     -0.004      0.004        -0.013       0.004
 (sextic)    |      0.001      0.004        -0.006       0.009
 (septic)    |     -0.001      0.004        -0.008       0.006
</code></pre>
<hr>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2023-12-09</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/1.continuous-predictors_linear/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/continuous-predictors/">Continuous predictors</a>,&nbsp;<a href="/tags/stata/">stata</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/theme-documentation-basics/" class="prev" rel="prev" title="主题文档 - 基本概念"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>主题文档 - 基本概念</a>
            <a href="/2.continuous-predictors_polynomials/" class="next" rel="next" title="Chapter3 ：Continuous predictors: Polynomials">Chapter3 ：Continuous predictors: Polynomials<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Alex_Wang</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"valine":{"appId":"QGzwQXOqs5JOhN4RGPOkR2mR-MdYXbMMI","appKey":"WBmoGyJtbqUswvfLh6L8iEBr","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"zh-CN","pageSize":10,"placeholder":"你的评论 ...","recordIP":true,"serverURLs":"https://leancloud.hugoloveit.com","visitor":true}},"lightgallery":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
