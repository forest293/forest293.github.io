<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates - Alex_Wang</title><meta name="Description" content="In this chapter, we extend the variance-components models introduced in the previous chapter by including observed explanatory variables or covariates $x$ ."><meta property="og:title" content="[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates" />
<meta property="og:description" content="In this chapter, we extend the variance-components models introduced in the previous chapter by including observed explanatory variables or covariates $x$ ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://forest293.github.io/chapter-3-random-intercept-models-with-covariates/" /><meta property="og:image" content="https://forest293.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-09-19T16:29:41+08:00" />
<meta property="article:modified_time" content="2024-09-29T23:45:40+08:00" /><meta property="og:site_name" content="Alex_Wang" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://forest293.github.io/logo.png"/>

<meta name="twitter:title" content="[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates"/>
<meta name="twitter:description" content="In this chapter, we extend the variance-components models introduced in the previous chapter by including observed explanatory variables or covariates $x$ ."/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://forest293.github.io/chapter-3-random-intercept-models-with-covariates/" /><link rel="prev" href="https://forest293.github.io/chapter-2-variance-components-models/" /><link rel="next" href="https://forest293.github.io/4.chapter-4-random-coefficient-models/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/forest293.github.io\/chapter-3-random-intercept-models-with-covariates\/"
        },"image": ["https:\/\/forest293.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "Multilevel \u0026 Longitudinal Models, stata","wordcount":  30161 ,
        "url": "https:\/\/forest293.github.io\/chapter-3-random-intercept-models-with-covariates\/","datePublished": "2024-09-19T16:29:41+08:00","dateModified": "2024-09-29T23:45:40+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/forest293.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Alex_Wang"
            },"description": "In this chapter, we extend the variance-components models introduced in the previous chapter by including observed explanatory variables or covariates $x$ ."
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Alex_Wang">Alex Wang</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/categories/documentation/"> 文档 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a><a href="javascript:void(0);" class="menu-item language" title="选择语言">
                    <i class="fa fa-globe" aria-hidden="true"></i>                      
                    <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/chapter-3-random-intercept-models-with-covariates/" selected>简体中文</option></select>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Alex_Wang">Alex Wang</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/categories/documentation/" title="">文档</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="选择语言">
                    <i class="fa fa-globe fa-fw" aria-hidden="true"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/chapter-3-random-intercept-models-with-covariates/" selected>简体中文</option></select>
                </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Alex_Wang</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/multilevel-longitudinal-models-using-stata/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Multilevel & Longitudinal Models Using stata</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-09-19">2024-09-19</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 30161 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 61 分钟&nbsp;<span id="/chapter-3-random-intercept-models-with-covariates/" class="leancloud_visitors" data-flag-title="[Multilevel  Longitudinal Models] Chapter 3 ：Random-intercept models with covariates">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#2-does-smoking-during-pregnancy-affect-birthweight">2 Does smoking during pregnancy affect birthweight?</a>
      <ul>
        <li><a href="#21-data-structure-and-descriptive-statistics">2.1 Data structure and descriptive statistics</a>
          <ul>
            <li><a href="#协变量covariate的层次">协变量（Covariate）的层次</a></li>
            <li><a href="#为什么level-2协变量的数量很重要">为什么Level-2协变量的数量很重要？</a></li>
            <li><a href="#经验法则公式解析">经验法则公式解析</a></li>
            <li><a href="#-j---q--42-">$ J - q &gt; 42 $</a></li>
            <li><a href="#例子">例子</a></li>
            <li><a href="#-jq-geq-10-">$ J/q \geq 10 $</a></li>
            <li><a href="#例子-1">例子</a></li>
            <li><a href="#变量在不同层次的变异性">变量在不同层次的变异性</a></li>
            <li><a href="#总结">总结</a></li>
            <li><a href="#1-标准差的概念">1. 标准差的概念</a></li>
            <li><a href="#2-整体标准差overall-standard-deviation">2. 整体标准差（Overall Standard Deviation）</a></li>
            <li><a href="#3-组间标准差between-standard-deviation">3. 组间标准差（Between Standard Deviation）</a></li>
            <li><a href="#4-组内标准差within-standard-deviation">4. 组内标准差（Within Standard Deviation）</a></li>
            <li><a href="#例子-2">例子</a></li>
            <li><a href="#1-计算整体平均分--overlinex_-">1. 计算整体平均分 $ \overline{x}_{..} $</a></li>
            <li><a href="#2-计算每个学校的平均分--overlinex_cdot-j-">2. 计算每个学校的平均分 $ \overline{x}_{\cdot j} $</a></li>
            <li><a href="#3-计算整体标准差--s_xo-">3. 计算整体标准差 $ s_{xO} $</a></li>
            <li><a href="#4-计算组间标准差--s_xb-">4. 计算组间标准差 $ s_{xB} $</a></li>
            <li><a href="#5-计算组内标准差--s_xw">5. 计算组内标准差 $ s_{xW}$</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-the-linear-random-intercept-model-with-covariates">3 The linear random-intercept model with covariates</a>
      <ul>
        <li><a href="#31-model-specification">3.1 Model specification</a></li>
        <li><a href="#32-model-assumptions">3.2 Model assumptions</a></li>
        <li><a href="#33-mean-structure">3.3 Mean structure</a></li>
        <li><a href="#34-residual-covariance-structure">3.4 Residual covariance structure</a></li>
        <li><a href="#35-graphical-illustration-of-random-intercept-model">3.5 Graphical illustration of random-intercept model</a></li>
      </ul>
    </li>
    <li><a href="#4-estimation-using-stata">4 Estimation using Stata</a></li>
    <li><a href="#5-coefficients-of-determination-or-variance-explained">5 Coefficients of determination or variance explained</a></li>
    <li><a href="#6-hypothesis-tests-and-confidence-intervals">6 Hypothesis tests and confidence intervals</a>
      <ul>
        <li><a href="#61-hypothesis-tests-for-individual-regression-coefficients">6.1 Hypothesis tests for individual regression coefficients</a></li>
        <li><a href="#62-joint-hypothesis-tests-for-several-regression-coefficients">6.2 Joint hypothesis tests for several regression coefficients</a></li>
        <li><a href="#63-predicted-means-and-confidence-intervals">6.3 Predicted means and confidence intervals</a></li>
        <li><a href="#64-hypothesis-test-for-random-intercept-variance">6.4 Hypothesis test for random-intercept variance</a></li>
      </ul>
    </li>
    <li><a href="#7-between-and-within-effects-of-level-1-covariates">7 Between and within effects of level-1 covariates</a>
      <ul>
        <li><a href="#71-between-mother-effects">7.1 Between-mother effects</a></li>
        <li><a href="#72-within-mother-effects">7.2 Within-mother effects</a></li>
      </ul>
    </li>
    <li><a href="#8-fixed-versus-random-effects-revisited">8 Fixed versus random effects revisited</a>
      <ul>
        <li><a href="#第一部分模型选择的决策">第一部分：模型选择的决策</a></li>
        <li><a href="#第二部分模型的特点和应用">第二部分：模型的特点和应用</a></li>
        <li><a href="#第三部分模型选择的具体应用">第三部分：模型选择的具体应用</a></li>
        <li><a href="#第四部分模型的比较和选择">第四部分：模型的比较和选择</a></li>
        <li><a href="#第五部分模型的预测和应用">第五部分：模型的预测和应用</a></li>
        <li><a href="#第六部分模型的选择和实际操作">第六部分：模型的选择和实际操作</a></li>
        <li><a href="#实际应用中的考虑">实际应用中的考虑</a></li>
        <li><a href="#总结-1">总结</a></li>
        <li><a href="#11-summary">11 Summary</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="2-does-smoking-during-pregnancy-affect-birthweight">2 Does smoking during pregnancy affect birthweight?</h2>
<p>Abrevaya (2006) investigates the effect of smoking on birth outcomes with the Natality datasets derived from birth certificates by the U.S. National Center for Health Statistics. This is of considerable public health interest because many pregnant women in the U.S. continue to smoke during pregnancy. Indeed, around the time of the study, it was estimated that only 18% to 25% of smokers quit smoking once they become pregnant, according to the 2004 Surgeon General’s Report on The Health Consequences of Smoking.</p>
<p>Abrevaya identified multiple births from the same mothers in nine datasets from 1990–1998 by matching mothers across the datasets. Unlike, for instance, the Nordic countries, a unique person identifier such as a social security number is rarely available in U.S. datasets. Perfect matching is thus precluded, and matching must proceed by identifying mothers who have identical values on a set of variables in all datasets. In this study, matching was accomplished by considering mother’s state of birth and child’s state of birth, as well as mother’s county and city of birth; mother’s age, race, education, and marital status; and, if married, husband’s age and race. For the matching on mother’s and child’s states of birth to be useful, the data were restricted to combinations of states that occur rarely.</p>
<p>Here we consider the subset of the matches where the observed interval between births was consistent with the interval since the last birth recorded on the birth certificate. The data are restricted to births with complete data for the variables considered by Abrevaya (2006), singleton births (no twins or other multiple births), and births to mothers for whom at least two births between 1990 and 1998 could be matched and whose race was classified as White or Black.</p>
<p>The birth outcome we will concentrate on is birthweight. Abrevaya (2006) motivates his study by citing a report from the U.S. Surgeon General:</p>
<p>The dataset used by Abrevaya (2006) is available from the Journal of Applied Econometrics Data Archive. Here we took a 10% random sample of the mothers, yielding 8,604 births from 3,978 mothers. We use the following variables from smoking.dta:</p>
<ul>
<li>momid: mother identifier</li>
<li>birwt: birthweight (in grams)</li>
<li>smoke: dummy variable for mother smoking during pregnancy (1: smoking; 0: not smoking)</li>
<li>male: dummy variable for baby being male (1: male; 0: female)</li>
<li>mage: mother’s age at the birth of the child (in years)</li>
<li>Mother’s education (reference category: did not graduate from high school)</li>
<li>hsgrad: dummy variable for having graduated from high school (1: graduated; 0: otherwise)</li>
<li>somecoll: dummy variable for having some college education, but no degree (1: some college; 0: otherwise)</li>
<li>collgrad: dummy variable for having graduated from college (1: graduated; 0: otherwise)</li>
<li>married: dummy variable for mother being married (1: married; 0: unmarried)</li>
<li>black: dummy variable for mother being Black (1: Black; 0: White)</li>
<li>Kessner index (reference category: Kessner index = 1, or adequate prenatal care)</li>
<li>kessner2: dummy variable for Kessner index = 2, or intermediate prenatal care (1: index=2; 0: otherwise)</li>
<li>kessner3: dummy variable for Kessner index = 3, or inadequate prenatal care (1: index=3; 0: otherwise)</li>
<li>Timing of first prenatal visit (reference category: first trimester)</li>
<li>novisit: dummy variable for no prenatal care visit (1: no visit; 0: otherwise)</li>
<li>pretri2: dummy variable for first prenatal care visit having occurred in second trimester (1: yes; 0: otherwise)</li>
<li>pretri3: dummy variable for first prenatal care visit having occurred in third trimester (1: yes; 0: otherwise)</li>
</ul>
<p>Smoking status was determined from the answer to the question asked on the birth certificate whether there was tobacco use during pregnancy.</p>
<p>The dummy variables for mother’s education—hsgrad, somecoll, and collgrad—were derived from the years of education given on the birth certificate. The Kessner index is a measure of the adequacy of prenatal care (1: adequate; 2: intermediate; 3: inadequate) based on the timing of the first prenatal visit and the number of prenatal visits, taking into account the gestational age of the fetus.</p>
<h3 id="21-data-structure-and-descriptive-statistics">2.1 Data structure and descriptive statistics</h3>
<p>The data have a two-level structure with births (or children or pregnancies) as units at level 1 and mothers as clusters at level 2. <strong>In multilevel models, the response variable always varies at the lowest level, taking on different values for different level-1 units within the same level-2 cluster.</strong> However, <strong>covariates can either vary at level 1 (and therefore usually also at level 2) or vary at level 2 only.</strong> For instance, while smoke can change from one pregnancy to the next, black is constant between pregnancies. smoke is therefore said to be a level-1 variable, whereas black is a level-2 variable. Among the variables listed above, black appears to be the only one that cannot in principle change between pregnancies. However, because of the way the matching was done, the education dummy variables (hsgrad, somecoll, and collgrad) and married also remain constant across births for the same mother and are thus level-2 variables. There are a total of 5 level-2 covariates and 8 level-1 covariates here.</p>
<p>As we will see in this chapter, the distinction between level-1 and level-2 covariates is important in several ways. Keeping track of the number of level-2 covariates is necessary when the number of level-2 units is not large because the rule of thumb in display 2.1 for choosing between ML and REML, deciding whether robust standard errors can be trusted, and whether asymptotic tests can be used, is $J-q&gt;42$, where $q$ is the number of level-2 covariates. When considering the maximum number of level-2 covariates that can reasonably be included in the model, a rough rule of thumb is that there should be at least about 10 clusters per level-2 covariate; $J/q\geq10$.</p>
<p>It is useful to know not just whether variables vary at levels 1 and 2 but also how much they vary at each of the levels. Variation at the two levels can be explored using the <code>xtsum</code> command (after reading the data and declaring their two-level structure by using <code>xtset</code>):</p>
<h4 id="协变量covariate的层次">协变量（Covariate）的层次</h4>
<ul>
<li><strong>Level-1协变量</strong>：这些是与个体层次相关的变量，比如学生的性别、年龄等。</li>
<li><strong>Level-2协变量</strong>：这些是与群体层次相关的变量，比如学校的资源水平、学校类型等。</li>
</ul>
<h4 id="为什么level-2协变量的数量很重要">为什么Level-2协变量的数量很重要？</h4>
<p>当Level-2单位（如学校）的数量不多时，Level-2协变量的数量会影响模型的估计和检验。这是因为：</p>
<ol>
<li><strong>模型估计方法</strong>：选择最大似然估计（MLE）还是限制最大似然估计（REML）。</li>
<li><strong>标准误的稳健性</strong>：判断稳健标准误是否可信。</li>
<li><strong>渐近检验的适用性</strong>：判断是否可以使用基于渐近理论的检验。</li>
</ol>
<h4 id="经验法则公式解析">经验法则公式解析</h4>
<h4 id="-j---q--42-">$ J - q &gt; 42 $</h4>
<ul>
<li><strong>$ J $</strong>：Level-2单位的数量，例如学校的数量。</li>
<li><strong>$ q $</strong>：Level-2协变量的数量。</li>
<li>这个条件告诉我们，如果Level-2单位的数量减去Level-2协变量的数量大于42，我们可以考虑使用MLE或REML方法，并且可以信赖稳健标准误和使用渐近检验。</li>
</ul>
<h4 id="例子">例子</h4>
<p>假设有45所学校，考虑使用3个Level-2协变量（比如学校的资源水平、师生比例、学校类型）：</p>
<ul>
<li>$ J = 45 $（学校数量）</li>
<li>$ q = 3 $（Level-2协变量数量）</li>
<li>$ J - q = 45 - 3 = 42 $
在这个例子中，$ J - q = 42 $，正好等于42，这意味着我们处于经验法则的边界上。如果学校数量再少一些，或者协变量数量再多一些，我们可能就无法使用MLE或REML方法，或者不能信赖稳健标准误和渐近检验了。</li>
</ul>
<h4 id="-jq-geq-10-">$ J/q \geq 10 $</h4>
<ul>
<li>这个条件告诉我们，对于每个Level-2协变量，至少应该有10个Level-2单位。这是一个粗略的经验法则，用于确定模型中可以合理包含的Level-2协变量的最大数量。</li>
</ul>
<h4 id="例子-1">例子</h4>
<p>如果我们有45所学校，根据经验法则，我们可以包含的Level-2协变量的最大数量是：</p>
<ul>
<li>$ J = 45 $（学校数量）</li>
<li>$ q $ 应该满足 $ 45/q \geq 10 $</li>
<li>解这个不等式，我们得到 $ q \leq 4.5 $
因为我们不能有半个协变量，所以我们可以说最多可以有4个Level-2协变量。</li>
</ul>
<h4 id="变量在不同层次的变异性">变量在不同层次的变异性</h4>
<p>了解变量在不同层次的变异性对于模型的构建和解释非常重要。可以使用<code>xtsum</code>命令来探索这种变异性。在使用<code>xtsum</code>之前，需要使用<code>xtset</code>来声明数据的层次结构。</p>
<h4 id="总结">总结</h4>
<ul>
<li>理解Level-1和Level-2协变量的区别。</li>
<li>知道Level-2协变量数量对模型估计和检验的影响。</li>
<li>掌握经验法则公式，并能够应用它们来决定模型中可以包含的协变量数量。</li>
<li>使用<code>xtsum</code>和<code>xtset</code>来探索和分析数据的层次结构。
希望这个更详细的解释能帮助你更好地理解这些概念。如果你还有任何疑问，或者需要进一步的例子，请随时告诉我。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">use &#34;F:\【3】Electronic books\0[Applied Statistics]\（3）第三本\datasets\smoking.dta&#34;
</span></span><span class="line"><span class="cl">quietly xtset momid 
</span></span><span class="line"><span class="cl">xtsum birwt smoke black
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Variable         |      Mean   Std. dev.       Min        Max |    Observations
-----------------+--------------------------------------------+----------------
birwt    overall |  3469.931   527.1394        284       5642 |     N =    8604
         between |             451.1943       1361     5183.5 |     n =    3978
         within  |             276.7966   1528.431   5411.431 | T-bar =  2.1629
                 |                                            |
smoke    overall |  .1399349   .3469397          0          1 |     N =    8604
         between |             .3216459          0          1 |     n =    3978
         within  |             .1368006  -.5267318   .8066016 | T-bar =  2.1629
                 |                                            |
black    overall |  .0717108   .2580235          0          1 |     N =    8604
         between |              .257512          0          1 |     n =    3978
         within  |                    0   .0717108   .0717108 | T-bar =  2.1629
</code></pre>
<p>The total number of observations is $N=8604$; the number of clusters is $J=3978$ (n in the output); and there are on average about 2.2 births per mother (<code>T-bar</code> in the output) in the dataset.</p>
<p>Three different sample standard deviations are given for each variable. The first is the <strong>overall standard deviation</strong>, $s_{ro}$, defined as usual as the square root of the mean squared deviation of observations from the overall mean:</p>
<p>$$s_{xO} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_{j}}(x_{ij}-\overline{x}_{..})^2}$$</p>
<p>The second is the <strong>between standard deviation</strong>, defined as the square root of the mean squared deviation of the cluster means from the overall mean:</p>
<p>$$s_{xB} = \sqrt{\frac{1}{J-1}\sum_{j=1}^J(\overline x_{\cdot j}-\overline{x}_{\cdot\cdot})^2}$$</p>
<p>This third is the <strong>within standard deviation</strong>, defined as the square root of the mean squared deviation of observations from the cluster means:</p>
<p>$$s_{xW} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_j}(x_{ij}-\overline{x}_{\cdot j})^2}$$</p>
<h4 id="1-标准差的概念">1. 标准差的概念</h4>
<p>首先，标准差是一种衡量数据分散程度的统计量，它表示数据点与平均值的偏差大小。</p>
<h4 id="2-整体标准差overall-standard-deviation">2. 整体标准差（Overall Standard Deviation）</h4>
<p><strong>公式</strong>：
$$ s_{xO} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_{j}}(x_{ij}-\overline{x}_{..})^2} $$</p>
<ul>
<li><strong>$ s_{xO} $</strong>：表示整体标准差。</li>
<li><strong>$ N $</strong>：是所有观察值的总数。</li>
<li><strong>$ J $</strong>：是群体（如学校）的数量。</li>
<li><strong>$ n_j $</strong>：是第 $ j $ 个群体中的观察值数量。</li>
<li><strong>$ x_{ij} $</strong>：表示第 $ j $ 个群体中第 $ i $ 个观察值。</li>
<li><strong>$ \overline{x}_{..} $</strong>：表示所有观察值的平均值。</li>
</ul>
<p><strong>解释</strong>：
整体标准差测量的是所有观察值与整体平均值的偏差。它考虑了所有数据点，不考虑它们属于哪个群体。</p>
<h4 id="3-组间标准差between-standard-deviation">3. 组间标准差（Between Standard Deviation）</h4>
<p><strong>公式</strong>：
$$ s_{xB} = \sqrt{\frac{1}{J-1}\sum_{j=1}^J(\overline x_{\cdot j}-\overline{x}_{\cdot\cdot})^2} $$</p>
<ul>
<li><strong>$ s_{xB} $</strong>：表示组间标准差。</li>
<li><strong>$ \overline x_{\cdot j} $</strong>：表示第 $ j $ 个群体的平均值。
<strong>解释</strong>：
组间标准差测量的是不同群体的平均值与整体平均值之间的偏差。它反映了群体间的差异。</li>
</ul>
<h4 id="4-组内标准差within-standard-deviation">4. 组内标准差（Within Standard Deviation）</h4>
<p><strong>公式</strong>：
$$ s_{xW} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_j}(x_{ij}-\overline{x}_{\cdot j})^2} $$</p>
<ul>
<li>
<p><strong>$ s_{xW} $</strong>：表示组内标准差。
<strong>解释</strong>：
组内标准差测量的是每个群体内的观察值与该群体平均值的偏差。它反映了群体内部的差异。</p>
</li>
<li>
<p><strong>整体标准差</strong>：测量所有观察值与整体平均值的偏差。</p>
</li>
<li>
<p><strong>组间标准差</strong>：测量不同群体的平均值与整体平均值的偏差。</p>
</li>
<li>
<p><strong>组内标准差</strong>：测量每个群体内的观察值与该群体平均值的偏差。</p>
</li>
</ul>
<h4 id="例子-2">例子</h4>
<p>假设我们有3所学校（群体），每所学校有10名学生，总共30名学生（观察值）。学生的成绩如下：</p>
<ul>
<li>学校A：学生成绩 [60, 65, 70, 75, 80, 85, 90, 95, 100, 105]</li>
<li>学校B：学生成绩 [50, 55, 60, 65, 70, 75, 80, 85, 90, 95]</li>
<li>学校C：学生成绩 [70, 72, 74, 76, 78, 80, 82, 84, 86, 88]</li>
</ul>
<h4 id="1-计算整体平均分--overlinex_-">1. 计算整体平均分 $ \overline{x}_{..} $</h4>
<p>首先，我们需要计算所有学生成绩的总和，然后除以学生总数（30）。</p>
<p>$$ \overline{x}_{..} = \frac{\text{所有成绩总和}}{30} $$</p>
<p>把所有成绩加起来：</p>
<p>$$ \text{总和} = 60 + 65 + \cdots + 105 $$</p>
<p>$$ \text{总和} = 1650 $$
然后计算平均分：</p>
<p>$$ \overline{x}_{..} = \frac{1650}{30} = 55 $$</p>
<h4 id="2-计算每个学校的平均分--overlinex_cdot-j-">2. 计算每个学校的平均分 $ \overline{x}_{\cdot j} $</h4>
<ul>
<li>学校A的平均分：</li>
</ul>
<p>$$ \overline{x}_{\cdot A} = \frac{60 + 65 + \cdots + 105}{10} = \frac{675}{10} = 67.5 $$</p>
<ul>
<li>学校B和学校C的计算方法相同，分别计算它们的平均分。</li>
</ul>
<h4 id="3-计算整体标准差--s_xo-">3. 计算整体标准差 $ s_{xO} $</h4>
<p>使用公式：</p>
<p>$$ s_{xO} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_{j}}(x_{ij}-\overline{x}_{..})^2} $$</p>
<p>我们需要计算每个学生的成绩与整体平均分的差的平方，然后求和，最后除以（N-1）并开方。</p>
<p>$$ \sum_{i=1}^{30}(x_{i}-\overline{x}_{..})^2 = (60-55)^2 + (65-55)^2 + \cdots + (105-55)^2 $$</p>
<p>计算差的平方并求和：</p>
<p>$$ \text{求和} = (5)^2 + (10)^2 + \cdots + (50)^2 $$</p>
<p>$$ \text{求和} = 25 + 100 + \cdots + 2500 $$</p>
<p>$$ \text{求和} = 4550 $$</p>
<p>然后计算整体标准差：</p>
<p>$$ s_{xO} = \sqrt{\frac{4550}{29}} \approx \sqrt{156.55} \approx 12.52 $$</p>
<h4 id="4-计算组间标准差--s_xb-">4. 计算组间标准差 $ s_{xB} $</h4>
<p>使用公式：</p>
<p>$$ s_{xB} = \sqrt{\frac{1}{J-1}\sum_{j=1}^J(\overline x_{\cdot j}-\overline{x}_{\cdot\cdot})^2} $$
计算每个学校平均分与整体平均分的差的平方，然后求和，最后除以（J-1）并开方。</p>
<p>$$ \sum_{j=1}^{3}(\overline x_{\cdot j}-\overline{x}_{\cdot\cdot})^2 = (67.5 - 55)^2 + (62.5 - 55)^2 + (78 - 55)^2 $$</p>
<p>$$ \text{求和} = 122.5 + 62.5 + 552 $$</p>
<p>$$ \text{求和} = 737.5 $$
然后计算组间标准差：</p>
<p>$$ s_{xB} = \sqrt{\frac{737.5}{2}} \approx \sqrt{368.75} \approx 19.21 $$</p>
<h4 id="5-计算组内标准差--s_xw">5. 计算组内标准差 $ s_{xW}$</h4>
<p>使用公式：</p>
<p>$$ s_{xW} = \sqrt{\frac{1}{N-1}\sum_{j=1}^{J}\sum_{i=1}^{n_j}(x_{ij}-\overline{x}_{\cdot j})^2} $$</p>
<p>对于每个学校，计算每个学生的成绩与该学校平均分的差的平方，然后求和，最后除以（N-1）并开方。</p>
<p>我们以学校A为例：</p>
<p>$$ \sum_{i=1}^{10}(x_{Ai}-\overline{x}_{\cdot A})^2 = (60-67.5)^2 + (65-67.5)^2 + \cdots + (105-67.5)^2 $$
$$ \text{求和} = 62.5 + 12.25 + \cdots + 302.25 $$
$$ \text{求和} = 412.5 $$</p>
<p>计算组内标准差（注意这里我们需要计算所有学校的总和）：</p>
<p>$$ s_{xW} = \sqrt{\frac{\text{所有学校求和}}{29}} $$
$$ s_{xW} = \sqrt{\frac{412.5 + \text{学校B和C的求和}}{29}} $$</p>
<p>假设学校B和C的求和分别为400和450，那么总和为：</p>
<p>$$ \text{总和} = 412.5 + 400 + 450 = 1262.5 $$</p>
<p>然后计算组内标准差：</p>
<p>$$ s_{xW} = \sqrt{\frac{1262.5}{29}} \approx \sqrt{43.53} \approx 6.60 $$</p>
<p>通过这个例子，我们可以看到：</p>
<ul>
<li><strong>整体标准差</strong> $ s_{xO} $ 反映了所有学生成绩的分散程度。</li>
<li><strong>组间标准差</strong> $ s_{xB} $ 反映了不同学校平均成绩之间的分散程度。</li>
<li><strong>组内标准差</strong> $ s_{xW} $ 反映了每个学校内部学生成绩的分散程度。</li>
</ul>
<p>We see that birthweight and smoking vary more between mothers than within mothers, whereas being Black does not vary at all within mothers, as expected. It is important to be aware of how much the level-1 variables vary within clusters because some estimators utilize only within-cluster variability of covariates (and not between-cluster variability).</p>
<p>There are two different ways of expressing the mean or proportion for a level-2 variable: considering the summary either across units (with the level-1 units as the unit of analysis) or across clusters (with the clusters as the unit of analysis). For instance, the mean for Black produced by <code>xtsum</code> is the mean (or proportion, because Black is binary) across units, the proportion of children born to Black mothers. We could also consider the mean across mothers, or the proportion of mothers who are Black. To do so, we define a dummy variable <code>pickone</code> equal to 1 for one child per mother by using the <code>egen</code> command with the <code>tag()</code> function.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">egen pickone = tag(momid)
</span></span></code></pre></td></tr></table>
</div>
</div><p>and summarize <strong>black</strong> across mothers by specifying if <code>pickone==1</code> in the command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">summarize black if pickone==1
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
       black |      3,978    .0713927     .257512          0          1
</code></pre>
<p>We see that the proportion of mothers who are Black is very close to the proportion of children born to Black mothers, probably because the average number of children per mother in the dataset does not differ much between Black and White mothers.</p>
<p>We can calculate the number of children per mother by using <code>egen</code> with the <code>count()</code> function:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">egen num = count(birwt), by(momid)
</span></span><span class="line"><span class="cl">tabulate num if pickone==1
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>        num |      Freq.     Percent        Cum.
------------+-----------------------------------
          2 |      3,330       83.71       83.71
          3 |        648       16.29      100.00
------------+-----------------------------------
      Total |      3,978      100.00
</code></pre>
<p>Most mothers have two children in the data, and about 16% have three.</p>
<p>For level-1 categorical variables, such as <strong>smoke</strong>, <code>xttab</code> produces a table of summaries:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">xttab smoke
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>                  Overall             Between            Within
    smoke |    Freq.  Percent      Freq.  Percent        Percent
----------+-----------------------------------------------------
 Nonsmoke |    7400     86.01      3565     89.62          95.69
   Smoker |    1204     13.99       717     18.02          79.03
----------+-----------------------------------------------------
    Total |    8604    100.00      4282    107.64          92.90
                              (n = 3978)
</code></pre>
<p>In the Overall table, we see that mothers smoked during their pregnancies for 14% of the children. According to the Between table, 90% of mothers had at least one pregnancy where they did not smoke, and 18% of mothers had at least one pregnancy where they did smoke. The Within table shows that the women who were ever nonsmokers during a pregnancy (row 1) were nonsmokers for an average of 96% of their pregnancies. The women who ever smoked during a pregnancy (row 2) did so for an average of 79% of their pregnancies.</p>
<h2 id="3-the-linear-random-intercept-model-with-covariates">3 The linear random-intercept model with covariates</h2>
<h3 id="31-model-specification">3.1 Model specification</h3>
<p>An obvious model to consider for the continuous response variable, birthweight, is a multiple linear regression model (discussed in chapter 1), including smoking status and various other variables as explanatory variables or covariates.</p>
<p>The model for the birthweight $y_ij$ of child $i$ of mother $j$ is specified as</p>
<p>$$y_{ij} = \beta_1+\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\xi_{ij}$$</p>
<p>where $x_{2ij}$ through $x_{pij}$ are covariates and $\xi _{ij}$ is a residual or error term.</p>
<p>It may be unrealistic to assume that the birthweights of children born to the same mother are uncorrelated given the observed covariates, or in other words that the residuals $\xi _{ij}$ and $\xi _{i&rsquo;j}$ are uncorrelated. <strong>We can therefore use the idea introduced in the previous chapter to split the total residual or error into two error components: $\zeta _{j}$,</strong> which is shared between children of the same mother $j$, and $\epsilon _{ij}$, which is unique for each child $ij$:</p>
<p>$$\xi _{ij} = \zeta _{j} + \epsilon _{ij}$$</p>
<p>Substituting for $\xi _{ij}$ into the multiple regression model (3.1), we obtain a linear random-intercept model with covariates :</p>
<p>$$\begin{aligned}y_{ij}&amp;=\quad\beta_1+\beta_2x_{2ij}+\cdots+\beta_px_{pij}+(\zeta_j+\epsilon_{ij})\end{aligned}$$</p>
<p>$$=\quad(\beta_1+\zeta_j)+\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\epsilon_{ij}$$</p>
<p>This model can be viewed as a regression model with an added level-2 residual $\xi_j$, or with a mother-specific intercept $\beta_1 + \xi_j$. The random intercept $\xi_j$ can be considered a latent variable that is not estimated along with the fixed parameters $\beta_1$ through $\beta_p$, but whose variance $\psi$ is estimated together with the variance $\theta$ of the level-1 residuals $\epsilon_{ij}$. The linear random-intercept model with covariates is the simplest example of a linear mixed (effects) model where there are both fixed and random effects.</p>
<p>The random intercept or level-2 residual $\zeta_j$ is a mother-specific error component, which remains constant across births, whereas the level-1 residual $\epsilon_{ij}$ is a child-specific error component, which varies between children $i$ as well as mothers $j$. The $\zeta_j$ are uncorrelated over mothers, the $\epsilon_{ij}$ are uncorrelated over mothers and children, and the two error components are uncorrelated with each other.</p>
<p>The mother-specific error component $\zeta_j$ represents the combined effects of all omitted mother characteristics or unobserved heterogeneity at the mother level. (Strictly speaking, $\zeta_j$ represents only the component of this combined effect that is uncorrelated with the covariates because of the level-2 exogeneity assumption discussed below.) If $\zeta_j$ is positive, the total residuals for mother $j$, $\xi_{ij}$, will tend to be positive, leading to heavier babies than predicted by the covariates. If $\zeta_j$ is negative, the total residuals will tend to be negative. Because $\zeta_j$ is shared by all responses for the same mother, it induces within-mother dependence among the total residuals $\xi_{ij}$. On first reading, you may want to skip the following more technical material and go to section 3.3.5.</p>
<p>我们来一步一步地理解这个线性混合模型（linear mixed model），特别是它如何应用于分析婴儿出生体重这样的连续响应变量。我会尽量简化解释，让你更容易理解。</p>
<p><strong>1. 第一步：理解多重线性回归模型</strong></p>
<p>首先，我们有一个多重线性回归模型，用来预测婴儿的出生体重 $ y_{ij} $。这个模型包括吸烟状态和其他一些变量作为解释变量或协变量。模型可以写成：</p>
<p>$ y_{ij} = \beta_1 + \beta_2 x_{2ij} + \cdots + \beta_p x_{pij} + \xi_{ij} $</p>
<p>这里：</p>
<ul>
<li>$ y_{ij} $ 是第 $ i $ 个婴儿（母亲 $ j $ 的孩子）的出生体重。</li>
<li>$ \beta_1, \beta_2, \ldots, \beta_p $ 是模型参数。</li>
<li>$ x_{2ij}, \ldots, x_{pij} $ 是协变量，比如母亲的年龄、体重、是否吸烟等。</li>
<li>$ \xi_{ij} $ 是残差项，也就是模型未能解释的部分。</li>
</ul>
<p><strong>2. 第二步：考虑同一母亲的婴儿体重的相关性</strong></p>
<p>在实际中，同一母亲所生的婴儿体重可能存在相关性，因为它们共享相同的遗传和环境因素。因此，我们不能简单地假设 $ \xi_{ij} $ 和 $ \xi_{i&rsquo;j} $（不同婴儿的残差）是不相关的。</p>
<p><strong>3. 第三步：引入随机截距模型</strong></p>
<p>为了解决这个问题，我们可以将残差 $ \xi_{ij} $ 分解为两部分：</p>
<ul>
<li>$ \zeta_j $：同一母亲 $ j $ 的所有孩子共享的残差部分。</li>
<li>$ \epsilon_{ij} $：每个婴儿 $ ij $ 独有的残差部分。
这样，模型可以写成：
$ \xi_{ij} = \zeta_j + \epsilon_{ij} $
将这个分解代入原始的多重线性回归模型，我们得到：
$ y_{ij} = (\beta_1 + \zeta_j) + \beta_2 x_{2ij} + \cdots + \beta_p x_{pij} + \epsilon_{ij} $
这个模型现在包括了一个随机截距 $ \zeta_j $，它代表了每个母亲特有的效应。</li>
</ul>
<p><strong>4. 第四步：理解模型的组成部分</strong></p>
<ul>
<li><strong>固定效应</strong>：$ \beta_1, \beta_2, \ldots, \beta_p $ 是固定参数，它们对所有母亲和婴儿都是一样的。</li>
<li><strong>随机效应</strong>：$ \zeta_j $ 是随机截距，它为每个母亲引入了一个特定的效应。</li>
<li><strong>残差</strong>：$ \epsilon_{ij} $ 是每个婴儿独有的随机误差。</li>
</ul>
<p><strong>5. 第五步：模型的解释</strong></p>
<ul>
<li><strong>$ \zeta_j $</strong>：这个随机截距代表了所有未观测到的母亲特征的综合效应。如果 $ \zeta_j $ 是正的，那么这位母亲所生的婴儿的出生体重通常会比仅根据协变量预测的要重。如果 $ \zeta_j $ 是负的，则相反。</li>
<li><strong>$ \epsilon_{ij} $</strong>：这个残差代表了每个婴儿特有的随机波动，它在不同的婴儿和母亲之间是不相关的。
通过这种方式，模型能够同时考虑婴儿出生体重的个体差异和母亲之间的差异，从而更准确地预测和分析数据。</li>
</ul>
<h3 id="32-model-assumptions">3.2 Model assumptions</h3>
<p>We now explicitly state a set of assumptions that are sufficient for everything we want to do in this chapter but are not always necessary. For this purpose, all observed covariates for unit $i$ in cluster $j$ are placed in the vector $\mathbf{x}_{ij}$, and the covariates for all the units in cluster $j$ are placed in the matrix $\mathbf{X}_j$ (with rows $\mathbf{x_i}_j&rsquo;$).</p>
<p>It is assumed that the level-1 residual $\epsilon_{ij}$ has zero expectation or mean, given the covariates and the random intercept:</p>
<p>$$E(\epsilon_{ij}|\mathbf{X}_j,\zeta_j)=0$$</p>
<p>This mean-independence assumption implies that $E(\epsilon_{ij}|\mathbf X_j)=0$ and that Cor($\epsilon_{ij},\mathbf x_{ij})=0$ and Cor($\epsilon_{ij},\overline{\mathbf{x}}_{.j})=0$. <strong>We call this lack of correlation between covariates and level-1 residual &ldquo;level-1 exogeneity&rdquo;. (See also section 1.13 on the exogeneity assumption in standard linear regression.)</strong></p>
<p>The random intercept $\zeta_j$ is assumed to have zero expectation given the covariates,</p>
<p>$$E(\zeta_j|\mathbf{X}_j) = 0$$</p>
<p><strong>and this mean-independence assumption implies that Cor($\zeta_j, x_{ij} $)=0 and Cor($\zeta_j, \overline{x}_{.j} $)=0. We call the lack of correlation between the covariates and the random intercept &ldquo;level-2 exogeneity&rdquo;.</strong> Violations of the exogeneity assumptions are called level-1 endogeneity and level-2 endogeneity, respectively.</p>
<p>We assume that the level-1 residual is homoskedastic (has constant variance) for given covariates and random intercept,</p>
<p>$$Var(\epsilon_{ij}|X_j,\zeta_j) = θ$$</p>
<p>which implies that Var($\epsilon_{ij}$) = θ and that Cor($\epsilon_{ij},\zeta_j$) = 0. It is also assumed that the random intercept is homoskedastic given the covariates,</p>
<p>$$Var(\zeta_j|X_j) = ψ$$</p>
<p>which implies that $Var(\zeta_j) = ψ.$</p>
<p>It is assumed that the level-1 residuals are uncorrelated for two units i and i&rsquo; (whether they are nested in the same cluster j or in different clusters j and j&rsquo;) given the covariates and random intercept(s),</p>
<p>$$\mathrm{Cov}(\epsilon_{ij},\epsilon_{i^{\prime}j^{\prime}}|\mathbf X_j,\mathbf X_{j^{\prime}},\zeta_j,\zeta_{j^{\prime}}) = 0\quad\mathrm{if}\quad i\neq i^{\prime}\quad\mathrm{or}\quad j\neq j^{\prime}\quad(3.7)$$</p>
<p>and that random intercepts are uncorrelated for different clusters j and j&rsquo; given the covariates,</p>
<p>$$\mathrm{Cov}(\zeta_j,\zeta_{j^{\prime}}|\mathbf X_j,\mathbf X_{j^{\prime}}) = 0\quad\mathrm{~if~} j\neq j^{\prime}\quad(3.8)$$</p>
<p>These assumptions imply the mean and residual covariance structure of the responses described in sections 3.3.3 and 3.3.4.</p>
<p>For (restricted) maximum likelihood estimation, normal distributions are specified for $\epsilon_{ij}| \mathbf X_j, \zeta_j$ and $\zeta_j| \mathbf X_{-j}.$ (Together with the assumptions (3.3) and (3.5), this implies that $\zeta_j$ and $\epsilon_{ij}$ are independent&ndash;a stronger property than lack of correlation). <strong>Such specification of the distributions is necessary to construct the likelihood and restricted likelihood for ML and REML estimation, respectively. However, it is important to note that the estimators behave well even if the distributions are different from normal.</strong> Indeed, consistent estimation of the regression coefficients $\beta_1,&hellip;,\beta_p$ relies only on correct specification of the mean structure. If, additionally, the total residuals have a symmetric distribution, estimation of the regression coefficients is also unbiased.</p>
<p>Correct specification of both the mean and covariance structure is needed only for consistent model-based standard errors, efficient estimation of the regression coefficients, and consistent estimation of $\psi$ and $\theta$. If the covariance structure is misspecified, robust standard errors are consistent and perform well if there are enough clusters in the data. How many clusters are needed for reliable robust standard errors? We can use our rule of thumb of 42 discussed in display 2.1, where 42 now refers to the number of clusters $minus$ the number $(q)$ of level-2 covariates, that is, $J-q\geq42$.</p>
<ul>
<li><strong>协变量和随机截距</strong></li>
</ul>
<p>首先，我们来讨论协变量和随机截距的概念。在统计模型中，协变量是我们用来解释响应变量（比如婴儿的出生体重）的变量。在群组（比如家庭）数据中，我们通常有两级变量：</p>
<ul>
<li>
<p><strong>一级协变量</strong> ($\mathbf{x}_{ij}$)：指的是与单个观测单位（比如一个婴儿）相关的变量。</p>
</li>
<li>
<p><strong>二级协变量</strong>：可能与群组（比如一个家庭）有关，但在模型中通常不直接使用。</p>
</li>
</ul>
<p>随机截距 ($\zeta_j$) 是每个群组特有的效应，它反映了群组内所有成员共享的未观测到的因素。在婴儿出生体重的例子中，这可能包括母亲的遗传特征、生活方式等。</p>
<ul>
<li><strong>残差的期望为零</strong></li>
</ul>
<p>残差（或误差项）是实际观测值与模型预测值之间的差异。在一个好的模型中，我们希望这个差异是随机的，而不是系统性的。期望为零的假设意味着，平均来说，我们的模型没有系统性地高估或低估响应变量的值。</p>
<ul>
<li><strong>一级残差</strong> ($\epsilon_{ij}$)：指的是单个观测单位的误差。</li>
<li><strong>期望为零</strong>：$E(\epsilon_{ij}|\mathbf{X}_j,\zeta_j)=0$ 表示，给定所有协变量和随机截距，我们期望误差项的平均值为零。</li>
</ul>
<ul>
<li><strong>外生性</strong></li>
</ul>
<p>外生性是指模型中的误差项与解释变量不相关。这有两个层面：</p>
<ul>
<li><strong>一级外生性</strong>：指的是一级残差与一级协变量不相关。</li>
<li><strong>二级外生性</strong>：指的是随机截距与一级协变量不相关。
如果违反了这些外生性假设，我们可能会遇到内生性问题，这可能导致估计的参数有偏误。</li>
</ul>
<ul>
<li><strong>同质性（Homoscedasticity）</strong></li>
</ul>
<p>同质性假设指的是残差的方差不依赖于解释变量的值。这有两个层面：</p>
<ul>
<li><strong>一级同质性</strong>：指的是给定协变量和随机截距后，一级残差的方差是恒定的。</li>
<li><strong>二级同质性</strong>：指的是给定协变量后，随机截距的方差是恒定的。</li>
</ul>
<ul>
<li><strong>残差的无相关性</strong></li>
</ul>
<p>这个假设表明，不同观测单位的残差之间是不相关的。这包括：</p>
<ul>
<li>不同婴儿之间的残差不相关。</li>
<li>不同母亲（群组）之间的随机截距不相关。</li>
</ul>
<ul>
<li><strong>最大似然估计</strong></li>
</ul>
<p>最大似然估计（MLE）是一种常用的参数估计方法。在给定数据的情况下，我们寻找参数值，使得观测到的数据出现的概率（似然性）最大。在本例中，我们假设残差和随机截距都遵循正态分布，这有助于我们构建似然函数。</p>
<ul>
<li><strong>模型的一致性和效率</strong></li>
</ul>
<ul>
<li><strong>一致性</strong>：指的是随着样本量的增加，估计量会收敛到真实的参数值。</li>
<li><strong>效率</strong>：指的是在所有一致估计量中，具有最小方差的估计量。
正确指定模型的均值和协方差结构对于获得一致和高效的估计至关重要。如果协方差结构被错误指定，我们可以使用稳健标准误差来获得一致的估计量，尤其是在群组数量足够多的情况下。</li>
</ul>
<ul>
<li><strong>例子</strong></li>
</ul>
<p>假设我们有100位母亲和她们的200个婴儿的数据。每位母亲可能有一个或多个婴儿。我们想要估计母亲的吸烟习惯如何影响婴儿的出生体重。</p>
<ul>
<li>我们收集每位母亲的年龄、体重、是否吸烟等协变量。</li>
<li>对于每个婴儿，我们记录其出生体重。</li>
<li>我们假设每个母亲的吸烟习惯和其他协变量可以解释婴儿出生体重的大部分变异。</li>
<li>我们进一步假设，即使在考虑了这些协变量之后，同一个母亲的婴儿之间仍然存在出生体重的相关性，这是由母亲的未观测到的特征（比如遗传）所导致的。</li>
<li>我们使用线性混合模型来估计吸烟对出生体重的影响，同时考虑到每个母亲特有的随机截距。
通过这个模型，我们可以更准确地估计吸烟对出生体重的影响，同时考虑到数据的群组结构。
希望这个更详细的解释能帮助你更好地理解这些统计模型的假设和它们的意义。如果还有任何疑问，请随时提问。</li>
</ul>
<h3 id="33-mean-structure">3.3 Mean structure</h3>
<p>Assumption (3.3) implies that the cluster-specific or conditional regression (averaged over $\epsilon_{ij}$ but given $\zeta_j$ and $X_j$) is linear:</p>
<p>$$E(y_{ij}|X_j,\zeta_j)=E(\beta_1+\beta_2x_{2ij}+\cdots+\beta_px_{pij})+E(\zeta_j|X_j,\zeta_j)+E(\epsilon_{ij}|X_j,\zeta_j)$$
$$=\beta_1+\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\zeta_j$$</p>
<p>We see that the covariates for other units in the cluster do not affect the mean response for unit $i$ once we control for the covariates $x_{ij}$ for unit $i$ and the random intercept $\zeta_j$. The covariates $X_j$ for the cluster are then said to be &ldquo;strictly exogenous given the random intercept&rdquo;.</p>
<p>It follows from $(3.4)$ that the population-averaged or marginal regression (averaged over $\zeta_j$ and $\epsilon_{ij}$ but given $X_j$ ) is linear:</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png"
        data-srcset="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png 1.5x, https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png 2x"
        data-sizes="auto"
        alt="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png"
        title="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.png" /></p>
<p>We sometimes refer to this relationship between the mean and covariates as the mean structure.</p>
<ul>
<li><strong>公式分解</strong>
首先，我们来看一个公式，这个公式描述了在给定随机截距 $\zeta_j$ 和协变量 $X_j$ 的条件下，单位 $i$ 的响应变量 $y_{ij}$ 的期望值：</li>
</ul>
<p>$$
E(y_{ij}|X_j,\zeta_j)=\beta_1+\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\zeta_j
$$</p>
<p>这个公式实际上是在说，对于群组 $j$ 中的单位 $i$，其响应变量 $y_{ij}$ 的平均值（或期望值）可以通过以下步骤计算得出：</p>
<ol>
<li>
<p><strong>固定效应部分</strong>：这部分是模型的主体，其中 $\beta_1, \beta_2, \ldots, \beta_p$ 是模型参数，$x_{2ij}, \ldots, x_{pij}$ 是单位 $i$ 的协变量。这部分表示了在不考虑随机截距的情况下，协变量对响应变量的平均影响。</p>
</li>
<li>
<p><strong>随机截距部分</strong>：这是群组 $j$ 的特定效应，反映了该群组中所有单位共享的、未被协变量捕捉到的影响。这个效应是随机的，意味着它在不同的群组之间是变化的。</p>
</li>
</ol>
<ul>
<li><strong>公式直观理解</strong></li>
</ul>
<p>这个公式的核心思想是，每个单位的响应变量不仅受到其自身协变量的影响，还受到其所属群组的特定效应的影响。这种效应是“随机”的，因为它是随机分配给每个群组的，而不是由协变量直接决定的。</p>
<ul>
<li><strong>公式中的“严格外生性”</strong></li>
</ul>
<p>当我们说协变量 $X_j$ 对于随机截距是“严格外生的”，我们是在说协变量不会影响到随机截距的值。这意味着，尽管随机截距 $\zeta_j$ 可能会影响到群组内所有单位的响应变量，但它本身并不受这些协变量的直接影响。</p>
<ul>
<li><strong>人口平均或边际回归</strong></li>
</ul>
<p>接下来，我们考虑整个人群中的响应变量 $y_{ij}$ 的期望值，这就是所谓的人口平均或边际回归：
$$
E(y_{ij}|X_j) = \beta_1 + \beta_2x_{2ij} + \cdots + \beta_px_{pij}
$$
这个公式告诉我们，当我们不考虑随机截距（即，我们对所有可能的群组取平均）时，响应变量 $y_{ij}$ 的期望值只取决于协变量。这意味着，随机截距 $\zeta_j$ 对于整个人口的平均响应没有影响。</p>
<ul>
<li><strong>例子：学校和学生成绩</strong></li>
</ul>
<p>假设我们想要研究学校环境对学生成绩的影响。我们有以下数据：</p>
<ul>
<li>
<p><strong>群组 $j$</strong>：学校</p>
</li>
<li>
<p><strong>单位 $i$</strong>：学生</p>
</li>
<li>
<p><strong>协变量 $x_{ij}$</strong>：包括学生的家庭背景、学习时间等</p>
</li>
<li>
<p><strong>随机截距 $\zeta_j$</strong>：表示每个学校特有的效应，比如学校的教学质量</p>
</li>
</ul>
<p>在这个模型中，我们假设：</p>
<ul>
<li>一旦我们控制了学生的家庭背景和学习时间，以及学校的教学质量，其他学生的家庭背景和学习时间就不会影响这个学生的成绩。</li>
<li>学生的成绩期望值只与他们自己的家庭背景、学习时间以及学校的教学质量有关。</li>
</ul>
<ul>
<li><strong>总结</strong></li>
</ul>
<p>通过这些假设和公式，我们可以更好地理解线性混合模型中的固定效应和随机效应如何影响响应变量的期望值。这些假设帮助我们构建一个合理的模型，以便更准确地估计协变量对响应变量的影响。
希望这个更详细的解释能帮助你更好地理解这些概念。如果还有任何疑问，请随时提问。</p>
<h3 id="34-residual-covariance-structure">3.4 Residual covariance structure</h3>
<p>It follows from assumptions (3.5) and (3.6) that total residuals or error terms are homoskedastic (having constant variance) given the covariates $X_{j}$,</p>
<p>$$\mathrm{Var}(\xi_{ij}|\mathbf{X_j}) = \mathrm{Var}(\zeta_j+\epsilon_{ij}|\mathbf{X}_j)=\psi+\theta $$</p>
<p>or, equivalently, that the responses , given the covariates, are homoskedastic,</p>
<p>$$\mathrm{Var}(y_{ij}|\mathbf{X}_j)=\psi+\theta $$</p>
<p>The conditional correlation between the total residuals for any two children $i$ and $i&rsquo;$ of the same mother $j$, given the covariates, also called the residual correlation, is</p>
<p>$$\rho\equiv\mathrm{Cor}(\xi_{ij},\xi_{i^{\prime}j}|\mathbf{X}_j) = \frac\psi{\psi+\theta}$$</p>
<p>where $\psi $ is the corresponding covariance. Thus, $\rho$ is also the conditional or residual intraclass correlation of responses $y_{ij} $ and $y_{i&rsquo;j&rsquo;}$ given the covariates:</p>
<p>$$\rho\equiv\mathrm{Cor}(y_{ij},y_{i&rsquo;j}|\mathbf{X}_j) = \frac{\psi}{\psi+\theta}$$</p>
<p>It is important to distinguish between the intraclass correlation in a model not containing any covariates—sometimes called the <em>unconditional</em> intraclass correlation—and the <em>conditional</em> or <em>residual</em> intraclass correlation in a model containing covariates. The residual covariance structure is shown in matrix form in display 3.2.</p>
<p>让我们深入探讨同质性（Homoscedasticity）和残差相关性（Residual Correlation）的概念，并用更详细的例子来说明。</p>
<ul>
<li>
<p><strong>同质性（Homoscedasticity）的详细解释</strong>
同质性是指在给定协变量的条件下，不同观测值的误差项具有相同的方差。这在统计模型中是一个重要的假设，因为它允许我们对模型的误差项进行一致的解释。</p>
</li>
<li>
<p><strong>公式的详细分解</strong></p>
</li>
</ul>
<p>$$
\text{Var}(\xi_{ij}|\mathbf{X}<em>j) = \text{Var}(\zeta_j+\epsilon</em>{ij}|\mathbf{X}<em>j) = \psi + \theta
$$
这个公式告诉我们，给定协变量 $\mathbf{X}<em>j$ 后，总残差 $\xi</em>{ij}$ 的方差等于随机截距 $\zeta_j$ 的方差 $\psi$ 加上一级残差 $\epsilon</em>{ij}$ 的方差 $\theta$。</p>
<ul>
<li>$\text{Var}(\xi_{ij}|\mathbf{X}<em>j)$：这是给定协变量后，总残差 $\xi</em>{ij}$ 的方差。</li>
<li>$\text{Var}(\zeta_j+\epsilon_{ij}|\mathbf{X}_j)$：这是给定协变量后，随机截距和一级残差之和的方差。</li>
<li>$\psi + \theta$：这是两个方差的和，表示总的方差。</li>
</ul>
<ul>
<li>
<p><strong>残差相关性（Residual Correlation）的详细解释</strong>
残差相关性描述了在给定协变量的条件下，同一个群组内不同观测值的残差之间的相关性。</p>
</li>
<li>
<p><strong>公式的详细分解</strong></p>
</li>
</ul>
<p>$$
\rho \equiv \text{Cor}(\xi_{ij}, \xi_{i&rsquo;j}|\mathbf{X}_j) = \frac{\psi}{\psi + \theta}
$$</p>
<p>这个公式告诉我们，同一个母亲 $j$ 的两个孩子 $i$ 和 $i&rsquo;$ 的总残差之间的相关性是由随机截距的方差 $\psi$ 与总方差（$\psi + \theta$）的比值决定的。</p>
<ul>
<li>$\rho$：这是残差之间的条件相关性。</li>
<li>$\text{Cor}(\xi_{ij}, \xi_{i&rsquo;j}|\mathbf{X}_j)$：这是给定协变量后，两个孩子的总残差之间的相关性。</li>
<li>$\frac{\psi}{\psi + \theta}$：这是随机截距方差与总方差的比值，它决定了残差之间的相关性。</li>
</ul>
<ul>
<li><strong>无条件与条件内类相关性的区别</strong></li>
</ul>
<ul>
<li><strong>无条件内类相关性</strong>：这是在不考虑任何协变量的情况下，群组内观测值之间的相关性。它反映了群组内成员之间的天然联系。</li>
<li><strong>条件内类相关性</strong>：这是在控制了协变量后，群组内观测值之间的相关性。它反映了在考虑了已知因素后，群组内成员之间仍然存在的相关性。</li>
</ul>
<p>让我们通过一个具体的例子来深入理解同质性和残差相关性的概念。</p>
<ul>
<li>
<p><strong>例子：学校和学生考试成绩</strong>
假设我们正在进行一项研究，目的是了解不同学校环境对学生考试成绩的影响。我们的数据集包括来自多个学校的学生，每个学生都有自己的考试成绩和一些相关的协变量，比如家庭背景、学习时间等。此外，我们还考虑了每个学校可能具有的独特影响，这可能包括学校的教育资源、教师质量等因素。</p>
</li>
<li>
<p><strong>数据结构</strong></p>
</li>
</ul>
<ul>
<li><strong>群组 $j$</strong>：学校</li>
<li><strong>单位 $i$</strong>：学生</li>
<li><strong>协变量 $\mathbf{X}_j$</strong>：包括学生的家庭背景、学习时间等</li>
<li><strong>随机截距 $\zeta_j$</strong>：表示每个学校特有的效应，比如学校的教学质量</li>
<li><strong>一级残差 $\epsilon_{ij}$</strong>：表示每个学生特有的随机波动</li>
</ul>
<ul>
<li><strong>模型设定</strong></li>
</ul>
<p>我们构建了一个线性混合模型来分析数据：</p>
<p>$$
y_{ij} = \beta_0 + \beta_1 x_{1ij} + \ldots + \beta_p x_{pij} + \zeta_j + \epsilon_{ij}
$$</p>
<p>其中：</p>
<ul>
<li>$ y_{ij} $ 是第 $ i $ 个学生在第 $ j $ 所学校的考试成绩。</li>
<li>$ x_{1ij}, \ldots, x_{pij} $ 是第 $ i $ 个学生的协变量。</li>
<li>$ \beta_0, \ldots, \beta_p $ 是模型参数。</li>
<li>$ \zeta_j $ 是第 $ j $ 所学校的随机截距。</li>
<li>$ \epsilon_{ij} $ 是第 $ i $ 个学生的成绩误差。</li>
</ul>
<ul>
<li><strong>同质性的应用</strong></li>
</ul>
<p>在模型中，我们假设给定协变量 $ \mathbf{X}_j $ 后，所有学生的考试成绩残差的方差是恒定的，即同质性。这意味着，无论我们观察哪个学生或哪所学校，只要协变量相同，残差的方差就保持不变。</p>
<p>$$
\text{Var}(\xi_{ij}|\mathbf{X}<em>j) = \text{Var}(\zeta_j+\epsilon</em>{ij}|\mathbf{X}_j) = \psi + \theta
$$</p>
<p>这个假设允许我们对模型的误差项进行一致的解释，并且使得模型更加可靠。</p>
<ul>
<li><strong>残差相关性的解释</strong></li>
</ul>
<p>我们还假设同一个学校内不同学生的成绩残差之间存在一定的相关性，这种相关性是由学校的未观测到的特征（如教学质量）所导致的。</p>
<p>$$
\rho \equiv \text{Cor}(\xi_{ij}, \xi_{i&rsquo;j}|\mathbf{X}_j) = \frac{\psi}{\psi + \theta}
$$</p>
<p>这里，$ \rho $ 表示同一个学校内两个学生成绩残差之间的条件相关性。这个相关性是由随机截距 $ \zeta_j $ 的方差 $ \psi $ 与总方差（$ \psi + \theta $）的比值决定的。</p>
<ul>
<li><strong>无条件与条件内类相关性的比较</strong></li>
</ul>
<ul>
<li><strong>无条件内类相关性</strong>：如果我们不考虑任何协变量，只是简单地观察同一个学校内学生的成绩，我们可能会发现学生成绩之间存在一定的天然联系，这就是无条件内类相关性。</li>
<li><strong>条件内类相关性</strong>：当我们在模型中控制了学生的协变量（如家庭背景、学习时间）后，我们仍然发现同一个学校内学生的成绩之间存在相关性，这就是条件内类相关性。这种相关性更能反映学校环境对学生成绩的实际影响。</li>
</ul>
<ul>
<li><strong>总结</strong>
通过这些假设和公式，我们可以更好地理解线性混合模型中的固定效应和随机效应如何影响响应变量的方差和相关性。这些假设帮助我们构建一个合理的模型，以便更准确地估计协变量对响应变量的影响。
希望这个更详细的解释能帮助你更好地理解这些概念。如果还有任何疑问，请随时提问。</li>
</ul>
<h3 id="35-graphical-illustration-of-random-intercept-model">3.5 Graphical illustration of random-intercept model</h3>
<p>A graphical illustration of the random-intercept model, $y_{ij} = \beta_1 +\beta_2 x_{ij} + \zeta_j + \epsilon_{ij}$, with a single covariate $x_{ij}$ is given in figure 3.1.</p>
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.1.png" style="width:540px;height:400px;" alt="图片描述">
  <figcaption><strong>Figure 3.1: Illustration of random-intercept model for one mother</strong></figcaption>
</figure>
<p>The bottom line is the population-averaged line, averaged across all mothers, with intercept $\beta_1$ and slope $\beta_2$. Mother $j$ &rsquo;s regression line has a positive random intercept $\zeta_j$ and therefore a regression line that is above the population-averaged line and parallel to it.</p>
<p>Another graphical illustration of this model with distributional assumptions is given in figure 3.2.</p>
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.17.png" style="width:540px;height:270px;" alt="图片描述">
  <figcaption><strong>Figure 3.2: Illustration of random-intercept model for one mother</strong></figcaption>
</figure>
<p>Here the solid line is $E(y_{ij}|x_{ij}) = \beta_1 + \beta_2 x_{ij}$, the population-averaged regression line for the population of all mothers j. The normal density curve centered on this line represents the random-intercept distribution with variance $\psi$ and the hollow circle represents a realization $\zeta_j$ from this distribution for mother j (this could have been placed anywhere along the line). This negative random intercept $\zeta_j$ produces the dotted mother-specific regression line $E(y_{ij}|x_{ij},\zeta_j)=(\beta_1+\zeta_j)+\beta_2 x_{ij}$. This line is parallel to and below the population-averaged regression line. For a mother with a positive $\zeta_j$, the mother-specific regression line would be parallel to and above the population-averaged regression line. Observed responses $y_{ij}=(\beta_1+\zeta_j)+\beta_2 x_{ij}+\epsilon_{ij}$ are shown for two values of $x_{ij}$. The responses are sampled from the two normal distributions [with means $(\beta_1+\zeta_j)+\beta_2 x_{ij}$ and variance $\theta$] shown on the dotted line.</p>
<p>首先，我们从基础的概念开始。</p>
<ol>
<li>总体平均回归线 (Population-Averaged Regression Line)
首先，我们有一个公式：</li>
</ol>
<p>$$
E(y_{ij}|x_{ij}) = \beta_1 + \beta_2 x_{ij}
$$</p>
<p>这个公式表示的是，对于所有的母亲（用 j 表示），在给定她们的某个特征 $x_{ij}$（比如年龄、收入等）的情况下，她们的某个结果 $y_{ij}$（比如孩子的身高、体重等）的期望值（平均值）。</p>
<ul>
<li>$\beta_1$ 是截距，即使 $x_{ij}$ 为0时，$y_{ij}$ 的期望值。</li>
<li>$\beta_2$ 是斜率，表示 $x_{ij}$ 每增加一个单位，$y_{ij}$ 期望值增加的量。</li>
</ul>
<p><strong>2. 随机截距分布 (Random-Intercept Distribution)</strong></p>
<p>在这个模型中，我们假设每个母亲都有一个随机的截距 $\zeta_j$，这个截距是从某个分布中随机抽取的，通常假设是从正态分布中抽取，其方差为 $\psi$。</p>
<ul>
<li>$\psi$ 表示随机截距的方差，也就是不同母亲之间截距的变异程度。</li>
</ul>
<p><strong>3. 个体特定的回归线 (Mother-Specific Regression Line)</strong></p>
<p>对于每个母亲 j，她的个体特定的回归线可以表示为：</p>
<p>$$
E(y_{ij}|x_{ij},\zeta_j) = (\beta_1 + \zeta_j) + \beta_2 x_{ij}
$$
这里，$\zeta_j$ 是随机截距，它使得每个母亲的回归线与总体平均回归线平行，但位置不同。</p>
<ul>
<li>如果 $\zeta_j$ 是负的，那么个体特定的回归线就会低于总体平均回归线。</li>
<li>如果 $\zeta_j$ 是正的，那么个体特定的回归线就会高于总体平均回归线。</li>
</ul>
<p><strong>4. 观察到的响应 (Observed Responses)</strong></p>
<p>实际观察到的数据 $y_{ij}$ 不仅仅是由回归线决定的，还受到随机误差 $\epsilon_{ij}$ 的影响：</p>
<p>$$
y_{ij} = (\beta_1 + \zeta_j) + \beta_2 x_{ij} + \epsilon_{ij}
$$</p>
<ul>
<li>$\epsilon_{ij}$ 通常假设是从正态分布中抽取，其方差为 $\theta$。</li>
</ul>
<p><strong>5. 正态分布和观察值</strong></p>
<p>对于每个 $x_{ij}$ 的值，观察到的 $y_{ij}$ 值是从具有特定均值和方差的正态分布中抽取的。均值由个体特定的回归线决定，方差 $\theta$ 通常认为是固定的。</p>
<ul>
<li><strong>例子</strong></li>
</ul>
<p>假设：</p>
<ul>
<li>$\beta_1 = 10$</li>
<li>$\beta_2 = 2$</li>
<li>$\psi = 4$（随机截距的方差）</li>
<li>$\theta = 1$（误差的方差）
对于一个特定的母亲，假设她的随机截距 $\zeta_j = -2$，则她的个体特定回归线为：</li>
</ul>
<p>$$
E(y_{ij}|x_{ij},\zeta_j) = (10 - 2) + 2 x_{ij} = 8 + 2 x_{ij}
$$</p>
<p>如果 $x_{ij} = 3$，则她的预测值是：</p>
<p>$$
E(y_{ij}|x_{ij},\zeta_j) = 8 + 2 \times 3 = 14
$$
实际观察到的值 $y_{ij}$ 可能会因为随机误差 $\epsilon_{ij}$ 而略有不同，比如 $y_{ij} = 14 + \epsilon_{ij}$。</p>
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.2.png" style="width:540px;height:400px;" alt="图片描述">
  <figcaption><strong>Figure 3.3: Illustration of different $\psi$, $\theta$, and the corresponding residual intraclass correlations $\rho$</strong></figcaption>
</figure>
<p>In the top left panel where $\rho = 0.9$, vertical distances $|\zeta_j|$ of lines from the population average line tend to be greater than distances $|e_{ij}|$ of responses from cluster-specific lines, whereas the opposite is true in the bottom left panel where $\rho = 0.1$. In the right panels, the scatter of lines around the population-average line is of the same magnitude as the scatter of points around their cluster-specific lines, giving $\rho = 0.5$.</p>
<h2 id="4-estimation-using-stata">4 Estimation using Stata</h2>
<h2 id="5-coefficients-of-determination-or-variance-explained">5 Coefficients of determination or variance explained</h2>
<p>As discussed in section 1.5 for standard linear regression (without random intercepts), the coefficient of determination, or R-squared, can be viewed as the proportional reduction in prediction error variance, comparing the model of interest with the null model that does not include any covariates.</p>
<p>$$R^2 = \frac{\mathrm{TSS-SSE}}{\mathrm{TSS}}$$</p>
<p>Here TSS is the sum of squared prediction errors, or residuals $y_{i}-\bar{y}$, for the null model and SSE is the sum of squared residuals, $y_{i}-\hat{y}_{i}$, for the model of interest. Therefore, $R^{2}$ can be written as</p>
<p>$$R^2 = \frac{\sum_i(y_i-\overline{y})^2-\sum_i(y_i-\widehat{y}_i)^2}{\sum_i(y_i-\overline{y})^2} \approx \frac{\frac{\sum_i(y_i-\overline{y})^2}{N-1}-\frac{\sum_i(y_i-\widehat{y}_i)^2}{N-p}}{\frac{\sum_i(y_i-\overline{y})^2}{N-1}} = \frac{\widehat{\sigma_0^2}-\widehat{\sigma_1^2}}{\widehat{\sigma_0^2}}$$</p>
<p>where $\widehat{\sigma_{1}^{2}}$ is the estimated residual variance for the model of interest and $\widehat{\sigma_{0}^{2}}$ is the estimated residual variance for the null model. The final quantity on the right is also called the adjusted $R$ square . We see that $R^{2}$ is approximately the proportional reduction in the estimated residual variance, where the approximation improves as $N$ increases.
This idea can easily be applied to a linear random-intercept model, where the total residual variance is given by</p>
<p>$$\mathrm{Var}(\zeta_j+\epsilon_{ij}) = \psi+\theta $$</p>
<p>Snijders and Bosker (2012, chap. 7) define a coefficient of determination for this model as the proportional reduction in the estimated total residual variance comparing the model of interest with the null model without covariates.</p>
<p>$$R^2~=~\frac{(\widehat{\psi}_0+\widehat{\theta}_0)-(\widehat{\psi}_1+\widehat{\theta}_1)}{\widehat{\psi}_0+\widehat{\theta}_0}$$</p>
<p>where $\widehat{\psi}_0$ and $\widehat{\theta}_0$ are the estimates for the null model, and $\widehat{\psi}_1$ and $\widehat{\theta}_1$ are the estimates for the model of interest.</p>
<ul>
<li><strong>1. 决定系数 $ R^2 $ 的定义</strong></li>
</ul>
<p>决定系数 $ R^2 $，也称为系数的确定性，是衡量线性回归模型拟合优度的一个统计量。它表示模型中自变量对因变量变异性的解释程度。$ R^2 $ 的值通常在0到1之间，值越接近1，表示模型解释的变异性越多。</p>
<ul>
<li><strong>2. $ R^2 $ 的计算</strong></li>
</ul>
<p>在标准线性回归（没有随机截距）的情况下，$ R^2 $ 可以通过以下步骤计算：</p>
<p><strong>步骤 1：计算总平方和（TSS）</strong>
总平方和（TSS）是因变量真实值与其均值之差的平方和。它衡量了如果我们没有任何自变量，只用因变量的均值来预测，会有多大的预测误差。</p>
<p>$$
\text{TSS} = \sum_{i} (y_i - \bar{y})^2
$$</p>
<ul>
<li>$ y_i $ 是第 $ i $ 个观测值</li>
<li>$ \bar{y} $ 是所有观测值的均值</li>
</ul>
<p><strong>步骤 2：计算残差平方和（SSE）</strong></p>
<p>残差平方和（SSE）是因变量真实值与模型预测值之差的平方和。它衡量了我们的模型预测与实际观测值之间的误差。</p>
<p>$$
\text{SSE} = \sum_{i} (y_i - \hat{y}_i)^2
$$</p>
<ul>
<li>$ \hat{y}_i $ 是模型预测的第 $ i $ 个观测值</li>
</ul>
<p><strong>步骤 3：计算 $ R^2 $</strong></p>
<p>$$
R^2 = \frac{\text{TSS} - \text{SSE}}{\text{TSS}}
$$
这个公式告诉我们，$ R^2 $ 是模型预测误差减少的比例。</p>
<ul>
<li><strong>3. $ R^2 $ 的另一种表达方式</strong></li>
</ul>
<p>$$
R^2 = \frac{\sum_i(y_i - \overline{y})^2 - \sum_i(y_i - \hat{y}_i)^2}{\sum_i(y_i - \overline{y})^2}
$$</p>
<p>这个公式可以进一步近似为：</p>
<p>$$
R^2 = \frac{\widehat{\sigma_0^2} - \widehat{\sigma_1^2}}{\widehat{\sigma_0^2}}
$$</p>
<ul>
<li>$ \widehat{\sigma_0^2} $ 是空模型（没有自变量）的残差方差的估计值</li>
<li>$ \widehat{\sigma_1^2} $ 是感兴趣模型（包含自变量）的残差方差的估计值
这个公式告诉我们，$ R^2 $ 可以看作是估计的残差方差减少的比例。</li>
</ul>
<ul>
<li><strong>4. 随机截距模型中的 $ R^2 $</strong></li>
</ul>
<p>在随机截距模型中，我们考虑了不同群体（例如不同学校的学生）之间的变异性。这种模型的残差方差包括了群体内和群体间的变异性。</p>
<p>$$
\text{Var}(\zeta_j + \epsilon_{ij}) = \psi + \theta
$$</p>
<ul>
<li>$ \zeta_j $ 是随机截距，代表了第 $ j $ 个群体的效应</li>
<li>$ \epsilon_{ij} $ 是随机误差，代表了第 $ j $ 个群体中第 $ i $ 个观测值的误差</li>
</ul>
<ul>
<li><strong>5. 随机截距模型的 $ R^2 $ 计算</strong></li>
</ul>
<p>$$
R^2 = \frac{(\widehat{\psi}_0 + \widehat{\theta}_0) - (\widehat{\psi}_1 + \widehat{\theta}_1)}{\widehat{\psi}_0 + \widehat{\theta}_0}
$$</p>
<ul>
<li>$ \widehat{\psi}_0 $ 和 $ \widehat{\theta}_0 $ 是空模型（没有自变量）的群体间和群体内残差方差的估计值</li>
<li>$ \widehat{\psi}_1 $ 和 $ \widehat{\theta}_1 $ 是感兴趣模型（包含自变量）的群体间和群体内残差方差的估计值
这个公式告诉我们，随机截距模型中的 $ R^2 $ 是模型包含自变量后，估计的总残差方差减少的比例。</li>
</ul>
<ul>
<li><strong>6. 例子</strong></li>
</ul>
<p>假设我们想研究不同学校的学生考试成绩。我们有以下数据：</p>
<table>
<thead>
<tr>
<th>学校</th>
<th>学生</th>
<th>成绩 (y)</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>60</td>
</tr>
<tr>
<td>A</td>
<td>2</td>
<td>70</td>
</tr>
<tr>
<td>A</td>
<td>3</td>
<td>80</td>
</tr>
<tr>
<td>B</td>
<td>1</td>
<td>90</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>100</td>
</tr>
</tbody>
</table>
<p><strong>步骤 1：计算 TSS 和 SSE</strong></p>
<p>假设成绩的平均值 $ \bar{y} $ 是 80。</p>
<p>$$
\text{TSS} = (60-80)^2 + (70-80)^2 + (80-80)^2 + (90-80)^2 + (100-80)^2
$$</p>
<p>$$
\text{TSS} = 400 + 100 + 0 + 100 + 400 = 1000
$$</p>
<p>如果我们的随机截距模型预测成绩 $ \hat{y}_i $ 为：</p>
<ul>
<li>学校A的预测成绩均值为75</li>
<li>学校B的预测成绩均值为95
那么：</li>
</ul>
<p>$$
\text{SSE} = (60-75)^2 + (70-75)^2 + (80-75)^2 + (90-95)^2 + (100-95)^2
$$</p>
<p>$$
\text{SSE} = 225 + 25 + 25 + 25 + 25 = 350
$$</p>
<p><strong>步骤 2：计算 $ R^2 $</strong></p>
<p>$$
R^2 = \frac{1000 - 350}{1000}
$$</p>
<p>$$
R^2 = 0.65
$$
这个结果告诉我们，我们的模型能解释65%的成绩变异性。</p>
<p><strong>步骤 3：随机截距模型的 $ R^2 $</strong></p>
<p>假设空模型（没有自变量）的残差方差估计值为：</p>
<ul>
<li>学校间：$ \widehat{\psi}_0 = 100 $</li>
<li>学校内：$ \widehat{\theta}_0 = 20 $
感兴趣模型（包含自变量）的残差方差估计值为：</li>
<li>学校间：$ \widehat{\psi}_1 = 50 $</li>
<li>学校内：$ \widehat{\theta}_1 = 10 $</li>
</ul>
<p>$$
R^2 = \frac{(100 + 20) - (50 + 10)}{100 + 20}
$$</p>
<p>$$
R^2 = \frac{120 - 60}{120}
$$</p>
<p>$$
R^2 = 0.5
$$
这个结果告诉我们，当我们使用包含自变量的模型时，我们能解释总残差方差的一半。这意味着我们的模型在考虑了学校间和学校内的差异后，能显著减少预测误差。</p>
<p>通过这些步骤和例子，我们可以看到 $ R^2 $ 是一个重要的统计指标，它告诉我们模型相比于一个没有任何自变量的模型，能解释多少因变量的变异性。在随机截距模型中，它衡量的是模型在考虑了群体间和群体内变异性后，能解释多少总变异性。这个指标帮助我们评估模型的拟合程度和预测能力。</p>
<ul>
<li><strong>7. 理解 $ R^2 $ 的含义</strong></li>
</ul>
<p>$ R^2 $ 值提供了模型解释变异性的比例，但它并不完美。以下是一些关键点，帮助我们更全面地理解 $ R^2 $：</p>
<ul>
<li><strong>范围</strong>：$ R^2 $ 的值在0到1之间，0表示模型不解释任何变异性，1表示模型解释了所有的变异性。</li>
<li><strong>改进的指标</strong>：随着模型的改进（例如添加更多的自变量），$ R^2 $ 通常会增加。但是，即使 $ R^2 $ 增加，模型也可能是过度拟合的。</li>
<li><strong>过度拟合</strong>：如果模型中添加了太多自变量，可能会导致过度拟合，即模型在训练数据上表现很好，但在新的、未见过的数据上表现不佳。</li>
<li><strong>惩罚项</strong>：调整后的 $ R^2 $ 考虑了模型中自变量的数量，对 $ R^2 $ 进行惩罚，以避免过度拟合。</li>
</ul>
<ul>
<li><strong>8. 调整后的 $ R^2 $</strong></li>
</ul>
<p>调整后的 $ R^2 $ 是对普通 $ R^2 $ 的调整，考虑了模型中自变量的数量。计算公式如下：</p>
<p>$$
\text{Adjusted } R^2 = 1 - (1-R^2)\frac{N-1}{N-p}
$$</p>
<ul>
<li>$ N $ 是观测值的数量。</li>
<li>$ p $ 是模型中自变量的数量。
调整后的 $ R^2 $ 通常会低于普通的 $ R^2 $，因为它对自变量的数量进行了惩罚。</li>
</ul>
<ul>
<li><strong>9. 例子：调整后的 $ R^2 $</strong>
假设我们有100个观测值（$ N = 100 $）和5个自变量（$ p = 5 $），并且我们的模型的 $ R^2 $ 是0.8。</li>
</ul>
<p>$$
\text{Adjusted } R^2 = 1 - (1-0.8)\frac{100-1}{100-5}
$$</p>
<p>$$
\text{Adjusted } R^2 = 1 - 0.2 \times \frac{99}{95}
$$</p>
<p>$$
\text{Adjusted } R^2 = 1 - 0.2 \times 1.042
$$</p>
<p>$$
\text{Adjusted } R^2 = 1 - 0.2084
$$</p>
<p>$$
\text{Adjusted } R^2 = 0.7916
$$</p>
<p>调整后的 $ R^2 $ 考虑了自变量的数量，提供了一个更现实的模型拟合优度的指标。</p>
<p>First, we fit the null model, also often called the <em>unconditional model</em> :</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">xtreg birwt, mle vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Iteration 0:  Log likelihood = -65475.527
Iteration 1:  Log likelihood = -65475.486

Random-effects ML regression                          Number of obs    = 8,604
Group variable: momid                                 Number of groups = 3,978

Random effects u_i ~ Gaussian                         Obs per group:
                                                                   min =     2
                                                                   avg =   2.2
                                                                   max =     3

                                                      Wald chi2(0)     =     .
Log likelihood = -65475.486                           Prob &gt; chi2      =     .

                              (Std. err. adjusted for 3,978 clusters in momid)
------------------------------------------------------------------------------
             |               Robust
       birwt | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
       _cons |    3467.97       7.14   485.95   0.000      3453.98     3481.96
-------------+----------------------------------------------------------------
    /sigma_u |     368.29       7.27                        354.30      382.82
    /sigma_e |     377.66       6.19                        365.73      389.98
         rho |       0.49       0.01                          0.46        0.51
------------------------------------------------------------------------------
</code></pre>
<p>The estimates for this model were also given under “Null model” in table 3.1. The total variance is estimated as</p>
<p>$$\widehat{\psi}_0+\widehat{\theta}_0 = 368.2866^2+377.6578^2=278260.43$$</p>
<p>For the model including all covariates, whose estimates were given under “Full model” in table 3.1, the total residual variance is estimated as</p>
<p>$$\widehat{\psi}_1+\widehat{\theta}_1 = 338.7674^2+370.6654^2=252156.19$$</p>
<p>It follows that</p>
<p>$$R^2~=~\frac{278260.43-252156.19}{278260.43}=0.10$$</p>
<p>so 10% of the variance is explained by the covariates</p>
<p>Raudenbush and Bryk (2002, chap. 4) suggest considering the proportional reduction in each of the variance components separately. In our example, the proportion of level-2 variance explained by the covariates is</p>
<p>$$R_2^2 = \frac{\widehat{\psi}_0-\widehat{\psi}_1}{\widehat{\psi}_0}=\frac{368.2866^2-338.7674^2}{368.2866^2}=0.15$$</p>
<p>and the proportion of level-1 variance explained by covariates is</p>
<p>$$R_{1}^{2}~=~\frac{\widehat{\theta}<em>{0}-\widehat{\theta}</em>{1}}{\widehat{\theta}_{0}}=\frac{377.6578^{2}-370.6654^{2}}{377.6578^{2}}=0.04$$</p>
<p>Stata&rsquo;s versions, which can be obtained by <strong><code>xtreg</code></strong> with the <strong><code>re</code></strong> option, are based on interpreting the coefficient of determination in standard linear regression as the squared correlation between $y_{i}$ and its prediction $\hat{y}_{i}$  and generalizing that concept to two-level models, instead of using the notion of proportional reduction in residual variance.</p>
<p>Let us now fit a random-intercept model that includes only the level-2 covariates:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">xtreg birwt hsgrad somecoll collgrad married black, mle vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Fitting constant-only model:
Iteration 0:  Log likelihood = -65475.527
Iteration 1:  Log likelihood = -65475.486

Fitting full model:
Iteration 0:  Log likelihood = -65330.325
Iteration 1:  Log likelihood = -65330.247

Random-effects ML regression                         Number of obs    =  8,604
Group variable: momid                                Number of groups =  3,978

Random effects u_i ~ Gaussian                        Obs per group:
                                                                  min =      2
                                                                  avg =    2.2
                                                                  max =      3

                                                     Wald chi2(5)     = 288.27
Log likelihood = -65330.247                          Prob &gt; chi2      = 0.0000

                              (Std. err. adjusted for 3,978 clusters in momid)
------------------------------------------------------------------------------
             |               Robust
       birwt | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      hsgrad |     131.44      26.66     4.93   0.000        79.18      183.70
    somecoll |     180.69      28.14     6.42   0.000       125.53      235.85
    collgrad |     232.89      27.27     8.54   0.000       179.44      286.35
     married |     114.77      27.24     4.21   0.000        61.37      168.16
       black |    -201.48      29.75    -6.77   0.000      -259.78     -143.17
       _cons |    3216.48      27.04   118.94   0.000      3163.48     3269.49
-------------+----------------------------------------------------------------
    /sigma_u |     348.14       7.10                        334.51      362.33
    /sigma_e |     377.76       6.19                        365.82      390.09
         rho |       0.46       0.01                          0.43        0.49
------------------------------------------------------------------------------
</code></pre>
<p>In general, and as we can see from comparing the estimates for this model (given under &ldquo;Level-2 covariates&rdquo; in table 3.1) with the estimates from the null model, adding level-2 covariates will reduce mostly the level-2 variance. Consequently, the residual intraclass correlation for the model with only level-2 covariates (0.46) is smaller than the intraclass correlation for the null model (0.49). However, adding level-1 covariates can reduce both variances, as we can see by comparing the estimates for the above model with the full model. The reason is that many level-1 covariates vary both within and between clusters and can hence be decomposed as $x_{ij} = (x_{ij} - \bar x_{.j}) + \bar x_{.j}$, where $x_{ij} - \bar x_{.j}$ only varies at level-1 and $\bar x_{.j}$ only varies at level-2. Note|that the estimated level-2 variance can increase when adding level-1 covariates, potentially producing a negative $R_2^2$.</p>
<p>Keep in mind that the coefficient of determination expresses to what extent the responses can be predicted from the covariates and not how appropriate the model is for the data. Indeed, a data-generating model could very well have a small $R^2$.</p>
<p><strong>1. 无条件模型（Null Model）与有条件模型（Full Model）</strong></p>
<p>首先，我们需要理解无条件模型和有条件模型的概念：</p>
<ul>
<li><strong>无条件模型</strong>：这个模型不包含任何自变量（covariates），它只估计因变量在不同群体（如学校、医院）的平均水平是否存在差异。这个模型可以给我们一个基准，用来比较添加自变量后的模型。</li>
<li><strong>有条件模型</strong>：这个模型包括了自变量，用来解释因变量的变异性。自变量可以是群体内部的（level-1）或群体间的（level-2）。</li>
</ul>
<p><strong>2. 自变量对残差方差的影响</strong></p>
<p>当我们添加群体间自变量（level-2 covariates）时，通常会减少群体间的残差方差。这是因为这些自变量解释了一部分群体间的差异。</p>
<ul>
<li><strong>类内相关性（Intraclass Correlation）</strong>：这是一个统计指标，用来衡量同一个群体内个体之间的相似度。类内相关性降低意味着个体之间的差异更多是由于群体内部因素，而不是群体间因素。</li>
</ul>
<p><strong>3. 添加群体内自变量（Level-1 Covariates）</strong></p>
<p>当我们添加群体内自变量时，可以同时减少群体内和群体间的残差方差。这是因为这些自变量在群体内和群体间都有变化，可以解释更多的变异性。</p>
<ul>
<li><strong>分解自变量</strong>：群体内自变量可以被分解为两部分：一部分只与群体内的变化有关（$x_{ij} - \bar x_{.j}$），另一部分只与群体间的变化有关（$\bar{x}_{.j}$）。</li>
</ul>
<p><strong>4. 公式解释</strong></p>
<p>$$
x_{ij} = (x_{ij} - \bar x_{.j}) + \bar x_{.j}
$$</p>
<ul>
<li>$x_{ij}$：表示第 $i$ 个观测值在第 $j$ 个群体的自变量值。</li>
<li>$\bar{x}_{.j}$：表示第 $j$ 个群体的自变量的平均值。</li>
<li>$x_{ij} - \bar{x}_{.j}$：表示第 $i$ 个观测值与它所在群体的平均值的差，这部分只与群体内的变化有关。</li>
</ul>
<p><strong>5. 例子</strong></p>
<p>假设我们研究学生的考试成绩，我们有以下数据：</p>
<table>
<thead>
<tr>
<th>学生</th>
<th>学校</th>
<th>成绩</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>60</td>
</tr>
<tr>
<td>B</td>
<td>1</td>
<td>70</td>
</tr>
<tr>
<td>C</td>
<td>2</td>
<td>80</td>
</tr>
<tr>
<td>D</td>
<td>2</td>
<td>90</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>无条件模型</strong>：只考虑成绩的平均值和群体（学校）间的差异。</li>
<li><strong>有条件模型</strong>：包括学生的性别、家庭背景等自变量。</li>
</ul>
<p><strong>6. 系数的确定性（Coefficient of Determination）</strong></p>
<p>$R^2$ 是一个统计指标，用来衡量模型中自变量对因变量变异性的解释程度。但它并不表示模型对数据的适用性。</p>
<ul>
<li><strong>$R^2$ 的计算</strong>：$R^2 = 1 - \frac{\text{Residual Variance}}{\text{Total Variance}}$。</li>
<li><strong>负的 $R^2$</strong>：如果添加自变量后，群体间残差方差增加，可能会导致负的 $R^2$，这并不意味着模型更差，只是说明自变量对群体间变异性的解释不如群体内。</li>
</ul>
<p><strong>7. 总结</strong>
通过添加自变量，我们可以更好地理解数据中的变异性，并减少残差方差。但重要的是要记住，$R^2$ 只是衡量预测能力的一个指标，并不完全反映模型的适用性。有时候，即使 $R^2$ 很小，数据生成模型也可能是合适的。</p>
<h2 id="6-hypothesis-tests-and-confidence-intervals">6 Hypothesis tests and confidence intervals</h2>
<h3 id="61-hypothesis-tests-for-individual-regression-coefficients">6.1 Hypothesis tests for individual regression coefficients</h3>
<p>The most commonly used hypothesis test concerns an individual regression parameter, say, $\beta_2$ , with null hypothesis</p>
<p>$$H_{0}:\beta_{2}=0$$</p>
<p>versus the two-sided alternative</p>
<p>$$H_a:\beta_2\neq0$$</p>
<p>Stata reports the test statistic</p>
<p>$$z~=~\frac{\widehat{\beta_2}}{\widehat{\mathrm{SE}}(\widehat{\beta}_{2})}$$</p>
<p>which has an asymptotic standard normal null distribution. For instance, in the output from mixed in section 3.4.2, the z statistic for the coefficient of smoke is -11.41, which gives a two-sided p-value of less than 0.001.</p>
<p>The square of the z statistic is called a Wald statistic,</p>
<!--
$$w~=~\left\{\frac{\widehat{\beta}_{2}}{\widehat{\mathrm{SE}}(\widehat{\beta}_{2})}\right\}^{2}$$
-->
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.3.png" style="width:250px;height:140px;" alt="图片描述">
  <figcaption><strong></strong></figcaption>
</figure>
<p>which has an asymptotic $\chi^2(1)$ distribution under the null hypothesis. The distribution has 1 degree of freedom because the null hypothesis imposes one restriction, $\beta_2=0$.</p>
<ol>
<li>第一步：理解假设检验</li>
</ol>
<p>假设检验是一种统计方法，用来决定我们是否有足够的证据拒绝一个假设（零假设）。在回归分析中，我们经常测试某个变量（比如 $\beta_2$）是否对模型有显著影响。</p>
<p><strong>例子</strong>：假设你是一名老师，想要知道学生是否因为吸烟（变量 $\beta_2$）而影响他们的考试成绩。你的零假设 $H_0$ 可能是“吸烟对考试成绩没有影响”，而备择假设 $H_a$ 是“吸烟对考试成绩有影响”。</p>
<ol start="2">
<li>第二步：检验统计量
Stata 计算了一个叫做 $z$ 的统计量来帮助我们决定是否拒绝零假设。</li>
</ol>
<p><strong>公式</strong>：</p>
<p>$ z = \frac{\widehat{\beta_2}}{\widehat{\mathrm{SE}}(\widehat{\beta}_{2})} $$</p>
<ul>
<li>$\widehat{\beta}_{2}$ 是回归分析中计算出的 $\beta_2$ 的估计值。</li>
<li>$\widehat{\mathrm{SE}}(\widehat{\beta_2})$ 是 $\widehat{\beta}_{2}$ 的标准误差。</li>
</ul>
<p><strong>例子</strong>：假设你发现吸烟的学生的平均考试成绩比不吸烟的学生低5分。这个5分就是 $\widehat{\beta}_{2}$。如果这个估计的标准误差是1分，那么 $z$ 值就是 $5 / 1 = 5$。</p>
<ol start="3">
<li>第三步：解释 $z$ 统计量</li>
</ol>
<p>$z$ 值告诉我们 $\widehat{\beta}_{2}$ 与其标准误差相比有多大。$z$ 值越大，我们越有理由拒绝零假设。</p>
<p><strong>例子</strong>：如果 $z$ 值是5，这意味着吸烟对成绩的影响比标准误差大5倍。这通常被认为是非常显著的，因为正常情况下，我们不会期望看到这么大的偏离。</p>
<ol start="4">
<li>第四步：Wald 统计量</li>
</ol>
<p>Wald 统计量是 $z$ 值的平方，它遵循一个自由度为1的卡方分布。</p>
<p><strong>公式</strong>：</p>
<!--
$$w~=~\left\{\frac{\widehat{\beta}_{2}}{\widehat{\mathrm{SE}}(\widehat{\beta}_{2})}\right\}^{2}$$
-->
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.16.3.png" style="width:250px;height:140px;" alt="图片描述">
  <figcaption><strong></strong></figcaption>
</figure>
<p><strong>例子</strong>：在我们的例子中，如果 $z$ 值是5，那么 Wald 统计量 $w$ 就是 $5^2 = 25$。</p>
<ol start="5">
<li>第五步：渐近分布的局限性</li>
</ol>
<p>渐近分布假设随着样本量的增加，我们的估计会越来越准确。但在样本量小的情况下，这种假设可能不成立。</p>
<p><strong>例子</strong>：如果你只调查了10个学生，那么得出的结论可能不太可靠。但如果调查了1000个学生，那么结论就更可信。</p>
<ol start="6">
<li>第六步：Kenward-Roger 近似</li>
</ol>
<p>Kenward-Roger 近似是一种更准确的估计自由度的方法，特别是在样本量小的情况下。</p>
<p><strong>例子</strong>：假设你在一个小城镇的学校进行调查，样本量不大。使用 Kenward-Roger 近似可以帮助你更准确地估计 $z$ 值或 Wald 统计量的显著性。</p>
<ol start="7">
<li>第七步：应用到实际数据</li>
</ol>
<p>在实际应用中，我们通常会使用软件（如 Stata）来计算这些统计量，并根据结果做出决策。</p>
<p><strong>例子</strong>：如果你是一名研究人员，你可能会使用 Stata 来分析吸烟和考试成绩之间的关系。Stata 会计算出 $z$ 值和 Wald 统计量，并告诉你是否有足够的证据拒绝零假设。</p>
<p>The asymptotic distributions treat the standard error as known which is a poor approximation when the number of clusters is small. For this reason, a $t$ (or $F$) distribution is sometimes used instead of the standard normal (or chi-square), where various approximations are used for the error degrees of freedom. The Kenward-Roger approximation generally appears to be preferable to the others (Kenward and Roger 1997; Schaalie, McBride, and Fellingham 2002), and can be obtained using mixed with the reml and dfmethod(kroger) options (dfmethod() was introduced in Stata 14). We now demonstrate the use of these options although the default asymptotic distributions should perform well here because there are thousands of clusters in the birthweight data ($J-q ＞＞ 42$):</p>
<ul>
<li><strong>渐近分布与标准误差</strong>
在统计学中，渐近分布是指当样本量变得非常大时，某些统计量的分布。在回归分析中，我们经常使用渐近分布来近似检验统计量，如 $z$ 值和 Wald 统计量。</li>
<li><strong>渐近分布的局限性</strong>：
渐近分布假设标准误差（$\widehat{\mathrm{SE}}$）是已知的，这在样本量很大时是合理的。但是，当样本量较小，特别是聚类数量较少时，这种假设可能不准确。</li>
</ul>
<p><strong>例子</strong>：假设你在做一项研究，研究吸烟对小城镇中学生考试成绩的影响。如果这个城镇只有几个学校（聚类），那么每个学校的
吸烟学生数量可能很少。在这种情况下，你估计的标准误差可能不够准确。</p>
<ul>
<li><strong>使用 $t$ 或 $F$ 分布</strong>
由于渐近分布在小样本情况下可能不够准确，我们有时会使用 $t$ 分布或 $F$ 分布来代替标准正态分布或卡方分布。这些分布考虑了标准误差的不确定性。</li>
</ul>
<p><strong>例子</strong>：如果你在研究中发现吸烟学生的平均成绩比不吸烟的学生低5分，但这个估计的标准误差是1分，你可能会使用 $t$ 分布来计算 $t$ 值：
$$ t = \frac{5}{1} $$
这将考虑标准误差的不确定性。</p>
<ul>
<li><strong>Kenward-Roger 近似</strong>
Kenward-Roger 近似是一种用于估计自由度的方法，它在小样本情况下通常比其他方法更准确。</li>
</ul>
<p><strong>例子</strong>：继续上面的例子，如果你使用 Kenward-Roger 近似来估计自由度，你可能会得到一个更准确的 $t$ 值或 $F$ 值，从而更准确地评估吸烟对考试成绩的影响。</p>
<ul>
<li><strong>在 Stata 中使用 Kenward-Roger 近似</strong>
在 Stata 中，你可以使用 <code>mixed</code> 命令和 <code>reml</code> 选项来请求受限最大似然估计，然后使用 <code>dfmethod(kroger)</code> 选项来指定 Kenward-Roger 近似来估计自由度。</li>
</ul>
<p><strong>例子</strong>：假设你在分析一个包含成千上万个聚类（如成千上万个学校）的大数据集。虽然在这种情况下，渐近分布可能已经足够准确，但你仍然可以选择使用 Kenward-Roger 近似来确保准确性：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">stata
</span></span><span class="line"><span class="cl">mixed y x1 x2, reml dfmethod(kroger)
</span></span></code></pre></td></tr></table>
</div>
</div><p>这里 <code>y</code> 是因变量，<code>x1</code> 和 <code>x2</code> 是自变量。</p>
<ul>
<li><strong>总结</strong></li>
</ul>
<ul>
<li>渐近分布在小样本情况下可能不够准确。</li>
<li>$t$ 分布和 $F$ 分布考虑了标准误差的不确定性，适用于小样本。</li>
<li>Kenward-Roger 近似是一种在小样本情况下更准确的自由度估计方法。</li>
<li>在 Stata 中，你可以使用 <code>mixed</code> 命令和相关选项来实现这些方法。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">mixed birwt smoke male mage hsgrad somecoll collgrad      ///
</span></span><span class="line"><span class="cl">  married black kessner2 kessner3 novisit pretri2 pretri3 ///
</span></span><span class="line"><span class="cl">  || momid:, reml dfmethod(kroger) stddeviations
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Performing EM optimization ...

Performing gradient-based optimization: 
Iteration 0:  Log restricted-likelihood = -65093.489  
Iteration 1:  Log restricted-likelihood = -65093.484  

Computing standard errors ...

Computing degrees of freedom ...

Mixed-effects REML regression                      Number of obs    =    8,604
Group variable: momid                              Number of groups =    3,978
                                                   Obs per group:
                                                                min =        2
                                                                avg =      2.2
                                                                max =        3
DF method: Kenward–Roger                           DF:          min = 4,002.61
                                                                avg = 6,074.95
                                                                max = 7,886.19
                                                   F(13, 7344.24)   =    53.24
Log restricted-likelihood = -65093.484             Prob &gt; F         =   0.0000

------------------------------------------------------------------------------
       birwt | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       smoke |    -218.27      18.18   -12.01   0.000      -253.91     -182.64
        male |     120.94       9.57    12.64   0.000       102.19      139.69
        mage |       8.10       1.35     6.02   0.000         5.47       10.74
      hsgrad |      56.85      25.06     2.27   0.023         7.71      105.99
    somecoll |      80.68      27.34     2.95   0.003        27.08      134.28
    collgrad |      90.82      28.03     3.24   0.001        35.87      145.77
     married |      49.92      25.53     1.96   0.051        -0.13       99.98
       black |    -211.41      28.31    -7.47   0.000      -266.91     -155.90
    kessner2 |     -92.92      19.94    -4.66   0.000      -132.01      -53.82
    kessner3 |    -150.85      40.87    -3.69   0.000      -230.96      -70.74
     novisit |     -30.02      65.75    -0.46   0.648      -158.91       98.87
     pretri2 |      92.85      23.21     4.00   0.000        47.35      138.35
     pretri3 |     178.70      51.68     3.46   0.001        77.39      280.01
       _cons |    3117.08      40.94    76.15   0.000      3036.83     3197.33
------------------------------------------------------------------------------

------------------------------------------------------------------------------
  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]
-----------------------------+------------------------------------------------
momid: Identity              |
                   sd(_cons) |     339.28       6.31        327.15      351.87
-----------------------------+------------------------------------------------
                sd(Residual) |     370.86       3.87        363.35      378.52
------------------------------------------------------------------------------
LR test vs. linear model: chibar2(01) = 1110.69       Prob &gt;= chibar2 = 0.0000
</code></pre>
<p>The degrees of freedom range between 4,002.61 and 7,886.19, depending on the covariate. These numbers are clearly large enough to rely on the asymptotic standard normal distribution, but we briefly look at
the degrees of freedom in more detail. The estat df command can be used to see the degrees of freedom associated with each test:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">estat df
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Degrees of freedom
------------------------------
             |   Kenward–Roger
-------------+----------------
birwt        |
       smoke |        7886.193
        male |        7170.964
        mage |        5879.349
      hsgrad |         4106.56
    somecoll |        4210.434
    collgrad |        4416.463
     married |        4173.793
       black |        4002.613
    kessner2 |        7634.771
    kessner3 |        7518.665
     novisit |         7649.74
     pretri2 |        7503.903
     pretri3 |        7467.864
       _cons |        5428.044
------------------------------
</code></pre>
<p>The degrees of freedom are smaller for level-2 covariates (for example, 4002.6 for black) than for level-1 covariates (for example, 7886.2 for smoke). These agree roughly with the simple approximations discussed by Snijders and Bosker (2012, 95), namely about $J-q-1$ for level-2 covariates (for example, for black, df ≈ 3978 - 5 - 1) and $N-p$ for level-1 covariates (for example, for smoke, df ≈ 8604 - 14), where N is the total sample size and p is the total number of regression parameters, including the intercept.</p>
<p>A likelihood-ratio test (described below) is less commonly used for testing individual regression parameters.</p>
<h3 id="62-joint-hypothesis-tests-for-several-regression-coefficients">6.2 Joint hypothesis tests for several regression coefficients</h3>
<p>Consider now the null hypothesis that the regression coefficients of two covariates $x_{2i j}$ and $x_{3 i j}$ are both 0 ,</p>
<p>$$H_0:\beta_2=\beta_3=0$$</p>
<p>versus the alternative hypothesis that at least one of the parameters is nonzero. For example, for the smoking-and-birthweight application, we may want to test the null hypothesis that the quality of prenatal care (as measured by the Kessner index) makes no difference to birthweight (controlling for the other covariates), where the Kessner index is represented by two dummy variables, <strong><code>kessner2</code></strong> and <strong><code>kessner3</code></strong>.</p>
<p>We can also test the simultaneous hypothesis that three or more regression coefficients are all 0, but the expression for the Wald statistic becomes convoluted unless matrix expressions are used.</p>
<p>The Wald test for the null hypothesis that the coefficients of the dummy variables <strong><code>kessner2</code></strong> and <strong><code>kessner3</code></strong> are both 0 can be performed using the <strong><code>testparm</code></strong> command. To base the test on robust standard errors, we first reestimate the model by using <strong><code>xtreg</code></strong> with the <strong><code>mle</code></strong> and <strong><code>vce(robust)</code></strong> options:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">** 3.6.2 Joint hypothesis tests for several regression coefficients
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">quietly xtreg birwt smoke male mage hsgrad somecoll collgrad  ///
</span></span><span class="line"><span class="cl">  married black kessner2 kessner3 novisit pretri2 pretri3, mle vce(robust)
</span></span><span class="line"><span class="cl">testparm kessner2 kessner3
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>. testparm kessner2 kessner3

 ( 1)  [birwt]kessner2 = 0
 ( 2)  [birwt]kessner3 = 0

           chi2(  2) =   23.75
         Prob &gt; chi2 =    0.0000
</code></pre>
<p>We reject the null hypothesis at the 5% level with $w = 23.75$, degrees of freedom $(df)=2, p&lt;0.001$.</p>
<p>If the number of clusters is small, with <strong><code>J-q &lt; 42</code></strong> (see display 2.1), it is better to perform an approximate F test, which can be obtained by estimating the model using <strong><code>mixed</code></strong> with the <strong><code>reml</code></strong> and <strong><code>dfmethod(kroger)</code></strong> options and then using the <strong><code>testparm</code></strong> command with the <strong><code>small</code></strong> option. In addition to providing a finite-sample approximation to the sampling distribution, this approach also has the advantage that the standard errors perform better than ML-based or robust standard errors when the number of clusters is small.</p>
<p>The analogous likelihood-ratio test statistic is</p>
<p>$$L~=~2(l_1-l_0)$$</p>
<p>where $l_1$ and $l_0$ are now the maximized log likelihoods for the models including and excluding both kessner2 and kessner3, respectively. Under the null hypothesis, the likelihood-ratio statistic also has an asymptotic $\chi^2(2)$ null distribution (there is no finite-sample approximation).</p>
<p>A likelihood-ratio test of the null hypothesis that the coefficients of the dummy variables <strong><code>kessner2</code></strong> and <strong><code>kessner3</code></strong> are both 0 can be performed by estimating both models by maximum likelihood and then using the <strong><code>lrtest</code></strong> command:</p>
<ul>
<li>
<p><strong>第一步：理解问题背景</strong>
在统计分析中，我们经常需要评估模型中的某些变量是否对结果有显著影响。当我们有多个数据组（或称为“聚类”）时，我们可能会使用多级模型或混合效应模型。如果聚类的数量不多，我们就需要一种更精确的方法来评估这些变量的影响。</p>
</li>
<li>
<p><strong>第二步：近似F检验</strong></p>
</li>
</ul>
<p><strong>近似F检验</strong>是一种在聚类数量较少时使用的统计方法。它通过以下步骤进行：</p>
<ol>
<li><strong>使用<code>mixed</code>命令</strong>：这是一个用于估计混合效应模型的命令。<code>mixed</code>命令可以让我们考虑数据的层次结构或聚类结构。</li>
<li><strong><code>reml</code>选项</strong>：<code>reml</code>代表“限制最大似然”，这是一种估计模型参数的方法，它考虑了缺失数据的情况，通常用于多级模型。</li>
<li><strong><code>dfmethod(kroger)</code>选项</strong>：这是自由度的计算方法。Kroger方法是一种计算自由度的方法，它在小样本情况下表现更好。</li>
<li><strong><code>testparm</code>命令</strong>：这个命令用于测试模型中参数的显著性。当我们加上<code>small</code>选项时，它会提供一个针对小样本的近似F检验。</li>
</ol>
<ul>
<li>
<p><strong>第三步：似然比检验</strong></p>
</li>
<li>
<p>(1) 第一步：理解似然比检验
似然比检验是一种统计方法，用于比较两个嵌套模型（一个模型是另一个模型的特殊情况）的拟合优度。这种方法基于两个模型的对数似然值。</p>
</li>
<li>
<p>(2) 第二步：完全模型和缩减模型
假设我们有两个模型：</p>
</li>
</ul>
<ul>
<li><strong>完全模型</strong>：$ y = \beta_0 + \beta_1 x + \beta_2 kessner2 + \beta_3 kessner3 + \epsilon $</li>
<li><strong>缩减模型</strong>：$ y = \beta_0 + \beta_1 x + \epsilon $</li>
</ul>
<p>其中：</p>
<ul>
<li>$ y $ 是观测到的结果。</li>
<li>$ x $ 是解释变量。</li>
<li>$ kessner2 $ 和 $ kessner3 $ 是我们感兴趣的两个虚拟变量。</li>
<li>$ \epsilon $ 是误差项。</li>
</ul>
<ul>
<li>(3) 第三步：估计两个模型</li>
</ul>
<ol>
<li><strong>完全模型</strong>：包含所有感兴趣的变量。</li>
<li><strong>缩减模型</strong>：不包含某些感兴趣的变量。
我们需要使用最大似然估计来估计这两个模型。</li>
</ol>
<ul>
<li>(4) 第四步：计算对数似然值</li>
</ul>
<p>对于每个模型，我们计算它的对数似然值：</p>
<ul>
<li>$ l_1 $ 是完全模型的最大对数似然值。</li>
<li>$ l_0 $ 是缩减模型的最大对数似然值。</li>
</ul>
<ul>
<li>(5) 第五步：似然比统计量的计算</li>
</ul>
<p>似然比统计量 $ L $ 由下式给出：</p>
<p>$$
L = 2(l_1 - l_0)
$$</p>
<p>这里：</p>
<ul>
<li>$ l_1 $ 是完全模型的对数似然值。</li>
<li>$ l_0 $ 是缩减模型的对数似然值。</li>
</ul>
<ul>
<li>(6) 第六步：零假设和备择假设</li>
</ul>
<p>在似然比检验中，我们通常测试的零假设是：</p>
<ul>
<li>$ H_0 $：两个模型没有显著差异，即 $ \beta_2 = \beta_3 = 0 $。</li>
</ul>
<p>备择假设是：</p>
<ul>
<li>$ H_1 $：两个模型有显著差异，即 $ \beta_2 \neq 0 $ 或 $ \beta_3 \neq 0 $。</li>
</ul>
<ul>
<li>(7) 第七步：卡方分布</li>
</ul>
<p>在零假设下，似然比统计量 $ L $ 遵循自由度为2的卡方分布（$\chi^2(2)$）。这是因为我们在比较两个模型时，完全模型比缩减模型多出了两个参数（$ \beta_2 $ 和 $ \beta_3 $）。</p>
<ul>
<li>(8) 第八步：执行检验</li>
</ul>
<ol>
<li><strong>计算 $ L $ 值</strong>：首先计算 $ L = 2(l_1 - l_0) $。</li>
<li><strong>查找卡方分布表</strong>：找到自由度为2的卡方分布的临界值。</li>
<li><strong>比较</strong>：如果计算出的 $ L $ 值大于临界值，则拒绝零假设，认为 $ kessner2 $ 和 $ kessner3 $ 的系数至少有一个不为0。</li>
</ol>
<ul>
<li>(9) 例子
假设：</li>
</ul>
<ul>
<li>$ l_1 = 10 $（完全模型的对数似然值）</li>
<li>$ l_0 = 8 $（缩减模型的对数似然值）</li>
</ul>
<p>计算 $ L $ 值：</p>
<p>$$
L = 2(10 - 8) = 4
$$</p>
<p>查找自由度为2的卡方分布表，通常在显著性水平0.05时，临界值约为5.99。
因为 $ 4 &lt; 5.99 $，我们不能拒绝零假设，即没有足够的证据表明 $ kessner2 $ 和 $ kessner3 $ 的系数不为0。</p>
<ul>
<li>(10) 总结</li>
</ul>
<p><strong>似然比检验</strong>是比较两个模型的另一种方法：用于比较两个嵌套模型的拟合优度。</p>
<ol>
<li><strong>完全模型</strong>：包含所有感兴趣的变量。</li>
<li><strong>缩减模型</strong>：不包含某些感兴趣的变量。</li>
<li><strong>最大似然估计</strong>：这是估计模型参数的另一种方法，它寻找使模型似然函数最大化的参数值。</li>
<li><strong>似然比统计量</strong> $ L $：这是通过计算两个模型的对数似然值之差，然后乘以2得到的。这个统计量在零假设下遵循卡方分布。</li>
</ol>
<ul>
<li><strong>第四步：执行似然比检验</strong>
执行似然比检验的步骤如下：</li>
</ul>
<ol>
<li><strong>估计两个模型</strong>：首先，你需要使用最大似然估计来估计完全模型和缩减模型。</li>
<li><strong>使用<code>lrtest</code>命令</strong>：这个命令会计算似然比统计量，并告诉你这个统计量在卡方分布下是否显著。</li>
</ol>
<ul>
<li><strong>例子</strong>
假设我们有以下两个模型：</li>
</ul>
<ul>
<li><strong>完全模型</strong>：$ y = \beta_0 + \beta_1 x + \beta_2 kessner2 + \beta_3 kessner3 + \epsilon $</li>
<li><strong>缩减模型</strong>：$ y = \beta_0 + \beta_1 x + \epsilon $
其中，$ y $是我们观测到的结果，$ x $是一个解释变量，$ kessner2 $和$ kessner3 $是我们感兴趣的两个虚拟变量（dummy variables），$ \epsilon $是误差项。</li>
</ul>
<ol>
<li><strong>估计两个模型</strong>：我们首先使用最大似然估计来估计这两个模型。</li>
<li><strong>计算对数似然值</strong>：对于每个模型，我们计算它的对数似然值，记作$ l_1 $和$ l_0 $。</li>
<li><strong>计算似然比统计量</strong>：我们计算$ L = 2(l_1 - l_0) $。</li>
<li><strong>比较卡方分布</strong>：我们将计算出的$ L $值与自由度为2的卡方分布进行比较，以确定$ kessner2 $和$ kessner3 $是否显著。</li>
</ol>
<ul>
<li><strong>总结</strong></li>
</ul>
<ul>
<li><strong>近似F检验</strong>适用于聚类数量较少的情况，它通过<code>mixed</code>命令和<code>testparm</code>命令来执行。</li>
<li><strong>似然比检验</strong>通过比较包含和不包含某些变量的模型来评估这些变量的显著性。</li>
<li><strong>检验统计量</strong> $ L $遵循卡方分布，我们可以通过比较这个统计量与卡方分布的临界值来做出决策。
希望这个更详细的解释能帮助你更好地理解这个问题。如果你还有任何疑问，请随时提问。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">* Likelihood-ratio test
</span></span><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">quietly xtreg birwt smoke male mage hsgrad somecoll collgrad  ///
</span></span><span class="line"><span class="cl">  married black kessner2 kessner3 novisit pretri2 pretri3, mle
</span></span><span class="line"><span class="cl">estimates store full
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">quietly xtreg birwt smoke male mage hsgrad somecoll collgrad   ///
</span></span><span class="line"><span class="cl">  married black novisit pretri2 pretri3, mle
</span></span><span class="line"><span class="cl">lrtest full .
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Likelihood-ratio test
Assumption: . nested within full

 LR chi2(2) =  26.90
Prob &gt; chi2 = 0.0000
</code></pre>
<p>The likelihood-ratio statistic ($L = 26.90$) is similar to the Wald statistic above ($w = 23.66$), and is even closer to the Wald statistic from maximum likelihood estimation with model-based standard errors (not shown here, $w = 26.94$). This similarity is not surprising because the Wald test is an approximation of the likelihood-ratio test as explained in display 2.2. The display also describes the score test, also known as the Lagrange multiplier test, a less commonly used approximation. All three tests are asymptotically equivalent to each other but may produce different conclusions in small samples. In the current setting with a large number of clusters, the Wald test based on robust standard errors would be our test of choice because, unlike the other methods, it does not rely on correct specification of the residual covariance structure. Note that likelihood-ratio tests for regression coefficients cannot be based on log likelihoods from <strong><code>REML</code></strong> estimation.</p>
<p>Sometimes it is required to test hypotheses regarding linear combinations of coefficients, as demonstrated in section 1.8. In section 3.7.4, we will encounter a special case of this when testing the null hypothesis that two regression coefficients are equal, or in other words that the difference between the coefficients is 0, a simple example of a contrast. Wald tests of such hypotheses can be performed in Stata by using the <strong><code>lincom</code></strong> and <strong><code>contrast</code></strong> commands. If the model has been fit using mixed with the <strong><code>reml</code></strong> and <strong><code>dfmethod(kroger)</code></strong> options, <strong><code>lincom</code></strong> and <strong><code>contrast</code></strong> with the small option perform -tests, based on the Kenward–Roger error degrees of freedom.</p>
<h3 id="63-predicted-means-and-confidence-intervals">6.3 Predicted means and confidence intervals</h3>
<p>We can use the <strong><code>margins</code></strong> command to obtain predicted means for mothers and pregnancies with particular covariate values, for example different combinations of education level and smoking status. If we evaluate the other covariates at particular values of our choice, we obtain adjusted means, called adjusted predictions in Stata. Alternatively, we can obtain what Stata calls predictive margins, the mean birthweight we would obtain if the distributions of the other covariates were the same for all combinations of education and smoking status. As mentioned in section 1.7, in linear models, predictive margins can be obtained by evaluating the other covariates at their means.</p>
<p>The <strong><code>margins</code></strong> command works only if factor notation is used for the categorical variables for which we want to make predictions (education and smoking status). We therefore define a categorical variable for level of education with appropriate value labels.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">generate education = hsgrad*1 + somecoll*2 + collgrad*3
</span></span><span class="line"><span class="cl">label define ed 0 &#34;No HS Degree&#34; 1 &#34;HS Degree&#34; 2 &#34;Some Coll&#34; 3 &#34;College&#34;, replace
</span></span><span class="line"><span class="cl">label values education ed
</span></span></code></pre></td></tr></table>
</div>
</div><p>and refit the model, declaring education and smoke as categorical variables by using <strong><code>i.education</code></strong> and <strong><code>i.smoke</code></strong>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">quietly xtreg birwt i.smoke male mage i.education married black ///
</span></span><span class="line"><span class="cl">  kessner2 kessner3 novisit pretri2 pretri3, mle vce(robust)
</span></span><span class="line"><span class="cl">  
</span></span></code></pre></td></tr></table>
</div>
</div><p>We then use the <strong><code>margins</code></strong> command to obtain predictive margins for all combinations of <strong><code>smoke</code></strong> and <strong><code>education</code></strong>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">margins i.smoke#i.education 
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Predictive margins                                       Number of obs = 8,604
Model VCE: Robust

Expression: Linear prediction, predict()

-----------------------------------------------------------------------------------------
                        |            Delta-method
                        |     Margin   std. err.      z    P&gt;|z|     [95% conf. interval]
------------------------+----------------------------------------------------------------
        smoke#education |
Nonsmoker#No HS Degree  |    3430.92      24.67   139.07   0.000      3382.56     3479.27
   Nonsmoker#HS Degree  |    3487.76      13.82   252.32   0.000      3460.67     3514.86
   Nonsmoker#Some Coll  |    3511.60      13.77   254.99   0.000      3484.61     3538.59
     Nonsmoker#College  |    3521.75      12.00   293.42   0.000      3498.22     3545.27
   Smoker#No HS Degree  |    3212.59      26.55   121.01   0.000      3160.55     3264.62
      Smoker#HS Degree  |    3269.43      20.49   159.59   0.000      3229.28     3309.59
      Smoker#Some Coll  |    3293.27      21.87   150.59   0.000      3250.41     3336.14
        Smoker#College  |    3303.42      22.05   149.83   0.000      3260.21     3346.63
-----------------------------------------------------------------------------------------
</code></pre>
<p>Here the interaction syntax <strong><code>i.smoke#i.education</code></strong> was used to specify that we want predictions for all combinations of the values of smoke and education. The standard errors and confidence intervals for the predictions are based on the estimated standard errors from the random intercept model.</p>
<p>We can plot these predictive margins with confidence intervals by using <strong><code>marginsplot</code></strong> (available from Stata 12).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">marginsplot, xdimension(education)
</span></span></code></pre></td></tr></table>
</div>
</div><figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.28.1.png" style="width:590px;height:400px;" alt="图片描述">
  <figcaption><strong></strong></figcaption>
</figure>
<h3 id="64-hypothesis-test-for-random-intercept-variance">6.4 Hypothesis test for random-intercept variance</h3>
<p>Consider testing the null hypothesis that the between-cluster variance is 0:</p>
<p>$$H_0:\psi=0\quad\mathrm{against}\quad H_a:\psi&gt;0$$</p>
<p>This null hypothesis is equivalent to the hypothesis that $\zeta_{j}=0$ or that there is no random intercept in the model. If this is true, a multilevel model is not required.</p>
<p>Likelihood-ratio tests are typically used with the test statistic</p>
<p>$$L = 2(l_1-l_0)$$</p>
<p>where $l_{1}$ is the maximized log likelihood for the random-intercept model (which includes $\zeta_j$ ) and $l_0$ is the maximized log likelihood for an ordinary regression model (without $\zeta_j$ ). This test is also valid if the restricted log likelihood is used. A correct p-value is obtained by dividing the naive p-value based on the $\chi^2(1)$  by 2, as was discussed in more detail in section 2.6.2 . When ML or REML estimation has been used with model-based standard errors (not the vce(robust) option), the result for the correct test procedure is provided in the last row of output from xtmixed and mixed , where the notation chi2bar2(01) indicates that the p value has been divided by 2. You can see this in section 3.6.1 where we fit the full model by using mixed with the reml option and obtained L = 1120 and p &lt; 0.001.
Alternative tests for the random-intercept variance were described in section 2.6.2 .</p>
<h2 id="7-between-and-within-effects-of-level-1-covariates">7 Between and within effects of level-1 covariates</h2>
<p>We now turn to the estimated regression coefficients for the random-intercept model with covariates. For births where the mother smoked during the pregnancy, the population mean birthweight is estimated to be 218 grams lower than for births where the mother did not smoke, holding all other covariates constant. This estimate represents either a comparison between children of different mothers, one of whom smoked during the pregnancy and one of whom did not (holding all other covariates constant), or a comparison between children of the same mother, where the mother smoked during one pregnancy and not during the other (holding all other covariates constant). This is neither purely a between-mother comparison (because smoking status can change between pregnancies) nor purely a within-mother comparison (because some mothers either smoke or do not smoke during all their pregnancies).</p>
<h3 id="71-between-mother-effects">7.1 Between-mother effects</h3>
<p>If we wanted to obtain purely between-mother effects of the covariates, we could average the response and covariates for each mother $j$ over children and perform the regression on the resulting cluster means.</p>
<p>$$\frac{1}{n_{j}}\sum_{i=1}^{n_{j}}y_{ij}\quad=\quad\frac{1}{n_{j}}\sum_{i=1}^{n_{j}}(\beta_{1}+\beta_{2}x_{2ij}+\cdots+\beta_{p}x_{pij}+\zeta_{j}+\epsilon_{ij})$$</p>
<p>or</p>
<p>$$\begin{array}{rcl}\overline y_{\cdot j}&amp;=&amp;\beta_1+\beta_2\overline x_{2\cdot j}+\cdots+\beta_p\overline x_{p\cdot j}+\zeta_j+\overline{\epsilon}_{\cdot j}\end{array}\quad(3.11)$$</p>
<p>Here $\bar y_{j}$ is the mean response for mother $j$, $\bar x_{2, j}$ is the mean of the first covariate smoke for mother $j$, etc., and $\bar \varepsilon_{j}$ is the mean of the level-1 residuals in the original regression model $(3.2)$ . The error term $\zeta_j+\bar \varepsilon_{j}$ has population mean $E\left(\zeta_j+\bar \varepsilon_{j}\right)=0$ and is heteroskedastic with variance $\operatorname{Var}\left(\zeta_j+\bar \varepsilon_{j}\right)=\psi+\theta / n_{j}$. Any information on the regression coefficients from within-mother variability is eliminated, and the coefficients of covariates that do not vary between mothers are absorbed by the intercept.</p>
<p>Ordinary least-squares (OLS) estimates $\hat{\beta}^{\mathrm{B}}$ of the parameters $\beta$ in the between regression $(3.11)$ whose corresponding covariates vary between mothers (here all covariates) can be obtained using xtmeg with the be (between) option (robust standard errors not available):</p>
<ul>
<li>
<p><strong>随机截距模型</strong>
随机截距模型是一种混合效应模型，它考虑了数据的层次结构。在这个例子中，层次结构是母亲和孩子。每个母亲可以看作是一个群体，而她的孩子是这个群体中的个体。</p>
</li>
<li>
<p><strong>母亲间效应（Between-mother effects）</strong></p>
</li>
</ul>
<p><strong>目标：</strong> 我们想要研究不同母亲之间的差异，即不考虑同一个母亲在不同怀孕期的变化。
<strong>方法：</strong> 为了实现这一点，我们对每个母亲 ( j ) 的所有孩子的响应变量（比如出生体重）和协变量（比如母亲是否吸烟）取平均值。
<strong>公式分解：</strong></p>
<ol>
<li><strong>原始模型：</strong></li>
</ol>
<p>$$
y_{ij} = \beta_1 + \beta_2 x_{2ij} + \cdots + \beta_p x_{pij} + \zeta_j + \epsilon_{ij}
$$</p>
<ul>
<li>$ y_{ij} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的出生体重。</li>
<li>$ x_{2ij}, \ldots, x_{pij} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的协变量（比如是否吸烟）。</li>
<li>$ \beta_1, \beta_2, \ldots, \beta_p $ 是回归系数。</li>
<li>$ \zeta_j $ 是随机截距，表示第 $ j $ 个母亲特有的效应。</li>
<li>$ \epsilon_{ij} $ 是误差项。</li>
</ul>
<ol start="2">
<li><strong>平均值模型：</strong></li>
</ol>
<p>$$
\overline y_{\cdot j} = \beta_1 + \beta_2 \overline x_{2\cdot j} + \cdots + \beta_p \overline x_{p\cdot j} + \zeta_j + \overline \epsilon_{\cdot j}
$$</p>
<ul>
<li>$ \overline y_{\cdot j} $ 是第 $ j $ 个母亲所有孩子的出生体重的平均值。</li>
<li>$ \overline x_{2\cdot j}, \ldots, \overline x_{p\cdot j} $ 是第 $ j $ 个母亲所有孩子的协变量的平均值。</li>
<li>$ \overline \epsilon_{\cdot j} $ 是第 $ j $ 个母亲所有孩子的误差项的平均值。</li>
</ul>
<ul>
<li><strong>误差项的方差：</strong></li>
</ul>
<p>$$
\operatorname{Var}(\zeta_j + \overline \epsilon_{\cdot j}) = \psi + \theta / n_{j}
$$</p>
<ul>
<li>$ \psi $ 是随机截距 $ \zeta_j $ 的方差。</li>
<li>$ \theta $ 是误差项 $ \epsilon_{ij} $ 的方差。</li>
<li>$ n_{j} $ 是第 $ j $ 个母亲的孩子数量。</li>
</ul>
<ul>
<li><strong>解释：</strong></li>
</ul>
<ul>
<li>这个模型消除了来自同一个母亲不同怀孕期变化的信息，只考虑了不同母亲之间的差异。</li>
<li>如果某些协变量在不同母亲之间没有变化，那么这些协变量的系数会被截距吸收，因为它们无法在模型中进一步解释变异性。</li>
</ul>
<ul>
<li><strong>普通最小二乘（OLS）估计：</strong></li>
</ul>
<ul>
<li>使用 <code>xtmeg</code> 命令的 <code>be</code>（between）选项可以估计参数 $ \beta $ 的值，这里的协变量在不同母亲之间是变化的。</li>
</ul>
<ul>
<li><strong>例子：</strong></li>
</ul>
<p>假设我们有3个母亲，每个母亲有2个孩子，数据如下：</p>
<table>
<thead>
<tr>
<th>母亲</th>
<th>孩子</th>
<th>出生体重 (g)</th>
<th>母亲吸烟</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>3400</td>
<td>否</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3500</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>3200</td>
<td>是</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>3100</td>
<td>是</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>3000</td>
<td>否</td>
</tr>
</tbody>
</table>
<ol>
<li>
<p><strong>计算平均值：</strong></p>
<ul>
<li>母亲1：平均出生体重 = (3400 + 3500) / 2 = 3450g，平均吸烟 = 0（都不吸烟）</li>
<li>母亲2：平均出生体重 = 3200g，平均吸烟 = 1（吸烟）</li>
<li>母亲3：平均出生体重 = (3100 + 3000) / 2 = 3050g，平均吸烟 = 0.5（一个吸烟，一个不吸烟）</li>
</ul>
</li>
<li>
<p><strong>回归分析：</strong></p>
<ul>
<li>使用这些平均值进行回归分析，估计吸烟对出生体重的影响。</li>
</ul>
</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">xtreg birwt smoke male mage hsgrad somecoll collgrad married black kessner2 ///
</span></span><span class="line"><span class="cl">   kessner3 novisit pretri2 pretri3, be
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Between regression (regression on group means)  Number of obs     =      8,604
Group variable: momid                           Number of groups  =      3,978

R-squared:                                      Obs per group:
     Within  = 0.0299                                         min =          2
     Between = 0.1168                                         avg =        2.2
     Overall = 0.0949                                         max =          3

                                                F(13,3964)        =      40.31
sd(u_i + avg(e_i.)) = 424.7306                  Prob &gt; F          =     0.0000

------------------------------------------------------------------------------
       birwt | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       smoke |    -286.15      23.23   -12.32   0.000      -331.68     -240.61
        male |     104.94      19.50     5.38   0.000        66.72      143.16
        mage |       4.40       1.51     2.92   0.003         1.45        7.35
      hsgrad |      58.81      25.51     2.30   0.021         8.79      108.83
    somecoll |      85.07      28.13     3.02   0.003        29.91      140.23
    collgrad |      99.88      29.35     3.40   0.001        42.33      157.42
     married |      41.91      26.11     1.61   0.108        -9.27       93.10
       black |    -218.40      28.58    -7.64   0.000      -274.43     -162.37
    kessner2 |    -101.49      37.66    -2.70   0.007      -175.32      -27.67
    kessner3 |    -201.96      79.29    -2.55   0.011      -357.41      -46.51
     novisit |     -51.03     124.21    -0.41   0.681      -294.54      192.49
     pretri2 |     125.48      44.72     2.81   0.005        37.80      213.15
     pretri3 |     241.12     100.66     2.40   0.017        43.78      438.46
       _cons |    3241.45      46.16    70.22   0.000      3150.95     3331.95
------------------------------------------------------------------------------
</code></pre>
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.28.2.png" style="width:590px;height:500px;" alt="图片描述">
  <figcaption><strong>Table 3.2: Random-, between-, and within-effects estimates for smoking data (in grams); MLE of random-intercept model (3.2), OLS of (3.11), OLS of (3.12), and MLE of random-intercept model including all cluster means</strong></figcaption>
</figure>
<h3 id="72-within-mother-effects">7.2 Within-mother effects</h3>
<p>If we wanted to obtain purely within-mother effects, we could subtract the between-mother regression (3.11) from the original model (3.2) to obtain the within model.</p>
<p>$$y_{ij}-\overline y_{\cdot j} = \beta_2(x_{2ij}-\overline x_{2\cdot j})+\cdots+\beta_p(x_{pij}-\overline x_{p\cdot j})+\epsilon_{ij}-\overline{\epsilon}_{\cdot j}\quad (3.12)$$</p>
<p>Here the response and all covariates have simply been centered around their respective cluster means. The error term $\varepsilon_{i j}-\bar \varepsilon_{: j}$ has population mean $E(\varepsilon_{i j}-\bar \varepsilon_{: j})=0$ and is heteroskedastic with variance Var$(\varepsilon_{i j}-\bar{\varepsilon}_{: j})=\theta(1-1 / n_j)$. Covariates that do not vary within clusters drop out of the equation because the mean-centered covariate is 0. Importantly, the random intercept $\zeta_j$ drops out for the same reason.</p>
<p>OLS can be used to estimate the within effects $\beta^W$ in $(3.12)$ . The standard errors of the estimated coefficients of covariates that vary little within clusters will be large because estimation is solely based on the within-cluster variability.</p>
<p>Identical estimates of within-mother effects can be obtained by replacing the random intercept $\zeta_j$ for each mother in the original model in $(3.2)$  by a fixed intercept $\alpha_j$. This could be accomplished using dummy variables for each mother and omitting the intercept $\beta_1$ so that $\alpha_j$ represents the total intercept for mother $j$, previously represented by $\beta_1+\zeta_j$. Letting $d_{kj}$ be the dummy variable for the kth mother, ($k=1,\ldots,3,978$), equal to 1 if $j=k$ and 0 otherwise. Then the fixed-effects model can be written as</p>
<p>$$\begin{aligned}y_{ij}&amp;=\quad\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\sum_{k=1}^{3,978}d_{kj}\alpha_k+\epsilon_{ij}\&amp;=\quad\beta_2x_{2ij}+\cdots+\beta_px_{pij}+\alpha_j+\epsilon_{ij}\end{aligned}$$</p>
<p>The text in the image is as follows:
and estimated by OLS. In this model, all mother-specific effects are accommodated by $\alpha_{j}$, leaving only within-mother variation to be explained by covariates. The coefficients of level-2 covariates can therefore not be estimated, which can also be seen by considering that the set of dummy variables is collinear with any such covariates. For example, black is the sum of the dummy variables for all Black mothers. In practice, it is more convenient to eliminate the intercepts by mean-centering all covariates, as in $(3.12)$, instead of estimating 3,978 intercepts.</p>
<p>The within estimates $\hat{\beta}^{W}$ for the coefficients of covariates that vary within mothers can be obtained using xtmixed with the fe (fixed effects) option:</p>
<p>我们的目标是研究同一个母亲在不同怀孕期的变化，即同一个母亲在不同孩子之间的差异。</p>
<ul>
<li><strong>方法</strong></li>
</ul>
<p>为了实现这个目标，我们可以从原始模型中减去母亲间效应的回归模型，得到母亲内部效应的模型。</p>
<ul>
<li>原始模型（模型 3.2）</li>
</ul>
<p>原始模型是：</p>
<p>$$ y_{ij} = \beta_1 + \beta_2 x_{2ij} + \cdots + \beta_p x_{pij} + \zeta_j + \epsilon_{ij} $$</p>
<ul>
<li>$ y_{ij} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的出生体重。</li>
<li>$ x_{2ij}, \ldots, x_{pij} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的协变量（比如是否吸烟）。</li>
<li>$ \beta_1, \beta_2, \ldots, \beta_p $ 是回归系数。</li>
<li>$ \zeta_j $ 是随机截距，表示第 $ j $ 个母亲特有的效应。</li>
<li>$ \epsilon_{ij} $ 是误差项。</li>
</ul>
<ul>
<li><strong>母亲间效应的回归模型（模型 3.11）</strong></li>
</ul>
<p>母亲间效应的回归模型是：</p>
<p>$$ \overline y_{\cdot j} = \beta_1 + \beta_2 \overline x_{2\cdot j} + \cdots + \beta_p \overline x_{p\cdot j} + \zeta_j + \overline \epsilon_{\cdot j} $$</p>
<ul>
<li>$ \overline y_{\cdot j} $ 是第 $ j $ 个母亲所有孩子的出生体重的平均值。</li>
<li>$ \overline x_{2\cdot j}, \ldots, \overline{x}_{p\cdot j} $ 是第 $ j $ 个母亲所有孩子的协变量的平均值。</li>
<li>$ \overline \epsilon_{\cdot j} $ 是第 $ j $ 个母亲所有孩子的误差项的平均值。</li>
</ul>
<ul>
<li><strong>母亲内部效应的回归模型（模型 3.12）</strong></li>
</ul>
<p>通过从原始模型中减去母亲间效应的回归模型，我们得到：</p>
<p>$$ y_{ij} - \overline y_{\cdot j} = \beta_2(x_{2ij} - \overline x_{2\cdot j}) + \cdots + \beta_p(x_{pij} - \overline x_{p\cdot j}) + \epsilon_{ij} - \overline \epsilon_{\cdot j} $$</p>
<ul>
<li>$ y_{ij} - \overline y_{\cdot j} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的出生体重与该母亲所有孩子的出生体重平均值的差。</li>
<li>$ x_{2ij} - \overline x_{2\cdot j}, \ldots, x_{pij} - \overline x_{p\cdot j} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的协变量与该母亲所有孩子的协变量平均值的差。</li>
<li>$ \epsilon_{ij} - \overline \epsilon_{\cdot j} $ 是第 $ j $ 个母亲第 $ i $ 个孩子的误差项与该母亲所有孩子的误差项平均值的差。</li>
</ul>
<p>步骤：</p>
<ul>
<li>
<ol>
<li><strong>计算每个母亲的平均值：</strong></li>
</ol>
<ul>
<li>对于每个母亲，计算她所有孩子的出生体重的平均值。</li>
<li>对于每个母亲，计算她所有孩子的协变量的平均值。</li>
</ul>
</li>
<li>
<ol start="2">
<li><strong>计算每个孩子的差值：</strong></li>
</ol>
<ul>
<li>对于每个孩子，计算他的出生体重与他母亲的出生体重平均值的差。</li>
<li>对于每个孩子，计算他的协变量与他母亲的协变量平均值的差。</li>
</ul>
</li>
<li>
<ol start="3">
<li><strong>构建新的回归模型：</strong></li>
</ol>
<ul>
<li>使用这些差值构建新的回归模型，这个模型将只包含母亲内部的变化。</li>
</ul>
</li>
<li><strong>误差项的方差：</strong>
$$ \text{Var}(\epsilon_{ij} - \overline{\epsilon}_{\cdot j}) = \theta(1 - \frac{1}{n_j}) $$</li>
<li>$ \theta $ 是误差项 $ \epsilon_{ij} $ 的方差。</li>
<li>$ n_j $ 是第 $ j $ 个母亲的孩子数量。
这个方差表达式告诉我们，误差项的方差会随着每个母亲的孩子数量的增加而减小。</li>
</ul>
<ul>
<li><strong>解释：</strong></li>
</ul>
<ul>
<li>这个模型通过将每个孩子的出生体重和协变量减去它们各自的平均值，来消除母亲间的差异。</li>
<li>随机截距 $ \zeta_j $ 和不在同一母亲不同孩子之间变化的协变量在模型中消失了，因为它们的平均值为0。</li>
<li>误差项 $ \epsilon_{ij} - \overline{\epsilon}_{\cdot j} $ 的方差是异方差的，取决于每个母亲的孩子数量 $ n_j $。</li>
</ul>
<ul>
<li><strong>固定效应模型的详细解释</strong></li>
</ul>
<p>另一种方法是用固定效应模型来估计母亲内部效应。我们可以为每个母亲设置一个固定截距 $ \alpha_j $。
$$ y_{ij} = \beta_2 x_{2ij} + \cdots + \beta_p x_{pij} + \sum_{k=1}^{3,978} d_{kj} \alpha_k + \epsilon_{ij} $$</p>
<ul>
<li>$ d_{kj} $ 是第 $ k $ 个母亲的虚拟变量，如果 $ j = k $ 则为1，否则为0。</li>
<li>$ \alpha_k $ 是第 $ k $ 个母亲的固定截距。
<strong>步骤：</strong></li>
<li>
<ol>
<li><strong>为每个母亲创建虚拟变量：</strong></li>
</ol>
<ul>
<li>对于每个母亲，创建一个虚拟变量，如果孩子属于这个母亲，则虚拟变量为1，否则为0。</li>
</ul>
</li>
<li>
<ol start="2">
<li><strong>构建新的回归模型：</strong></li>
</ol>
<ul>
<li>使用这些虚拟变量和协变量构建新的回归模型。</li>
</ul>
</li>
<li><strong>优点：</strong></li>
<li>这个模型通过为每个母亲设置一个唯一的截距来考虑母亲特定的效应，只留下母亲内部的变化由协变量来解释。</li>
<li><strong>缺点：</strong></li>
<li>如果母亲的数量很多，模型中会有很多虚拟变量，这可能会导致模型估计的复杂性和计算成本。</li>
</ul>
<ul>
<li><strong>普通最小二乘（OLS）估计</strong></li>
</ul>
<p>我们可以使用普通最小二乘法来估计模型（3.12）中的系数 $ \beta^W $。
<strong>优点：</strong></p>
<ul>
<li>OLS是一种简单且常用的估计方法。
<strong>缺点：</strong></li>
<li>如果协变量在同一母亲的孩子之间变化不大，那么估计的标准误差会很大，因为估计完全基于母亲内部的变异性。</li>
</ul>
<ul>
<li><strong>例子</strong></li>
</ul>
<p>假设我们有3个母亲，每个母亲有2个孩子，数据如下：</p>
<table>
<thead>
<tr>
<th>母亲</th>
<th>孩子</th>
<th>出生体重 (g)</th>
<th>母亲吸烟</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>3400</td>
<td>否</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3500</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>3200</td>
<td>是</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>3100</td>
<td>是</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>3000</td>
<td>否</td>
</tr>
</tbody>
</table>
<ul>
<li>
<ol>
<li><strong>计算平均值：</strong></li>
</ol>
<ul>
<li>母亲1：平均出生体重 = 3450g，平均吸烟 = 0</li>
<li>母亲2：平均出生体重 = 3200g，平均吸烟 = 1</li>
<li>母亲3：平均出生体重 = 3050g，平均吸烟 = 0.5</li>
</ul>
</li>
<li>
<ol start="2">
<li><strong>计算差值：</strong></li>
</ol>
<ul>
<li>母亲1的孩子1：$ y_{11} - \overline y_{\cdot 1} = 3400 - 3450 = -50 $，$ x_{21} - \overline x_{2\cdot 1} = 0 - 0 = 0 $</li>
<li>母亲1的孩子2：$ y_{12} - \overline y_{\cdot 1} = 3500 - 3450 = 50 $，$ x_{22} - \overline x_{2\cdot 1} = 0 - 0 = 0 $</li>
<li>母亲2的孩子1：$ y_{21} - \overline y_{\cdot 2} = 3200 - 3200 = 0 $，$ x_{21} - \overline x_{2\cdot 2} = 1 - 1 = 0 $</li>
<li>母亲3的孩子1：$ y_{31} - \overline y_{\cdot 3} = 3100 - 3050 = 50 $，$ x_{32} - \overline x_{3\cdot 2} = 1 - 0.5 = 0.5 $</li>
<li>母亲3的孩子2：$ y_{32} - \overline y_{\cdot 3} = 3000 - 3050 = -50 $，$ x_{32} - \overline x_{3\cdot 2} = 0 - 0.5 = -0.5 $</li>
</ul>
</li>
<li>
<ol start="3">
<li><strong>回归分析：</strong></li>
</ol>
<ul>
<li>使用这些差值进行回归分析，估计吸烟对出生体重的影响。</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">quietly xtset momid
</span></span><span class="line"><span class="cl">xtreg birwt smoke male mage kessner2 kessner3 novisit pretri2 pretri3, ///
</span></span><span class="line"><span class="cl">   fe vce(robust)
</span></span></code></pre></td></tr></table>
</div>
</div><pre><code>Fixed-effects (within) regression               Number of obs     =      8,604
Group variable: momid                           Number of groups  =      3,978

R-squared:                                      Obs per group:
     Within  = 0.0465                                         min =          2
     Between = 0.0557                                         avg =        2.2
     Overall = 0.0546                                         max =          3

                                                F(8, 3977)        =      26.78
corr(u_i, Xb) = -0.0733                         Prob &gt; F          =     0.0000

                              (Std. err. adjusted for 3,978 clusters in momid)
------------------------------------------------------------------------------
             |               Robust
       birwt | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
       smoke |    -104.55      31.64    -3.30   0.001      -166.58      -42.52
        male |     125.64      11.08    11.34   0.000       103.92      147.35
        mage |      23.16       3.08     7.52   0.000        17.12       29.20
    kessner2 |     -91.49      25.56    -3.58   0.000      -141.61      -41.38
    kessner3 |    -128.09      49.02    -2.61   0.009      -224.20      -31.98
     novisit |      -4.81      91.23    -0.05   0.958      -183.68      174.07
     pretri2 |      81.29      28.68     2.83   0.005        25.06      137.52
     pretri3 |     153.06      61.63     2.48   0.013        32.23      273.89
       _cons |    2767.50      88.42    31.30   0.000      2594.14     2940.86
-------------+----------------------------------------------------------------
     sigma_u |  440.05052
     sigma_e |  368.91787
         rho |  .58725545   (fraction of variance due to u_i)
------------------------------------------------------------------------------
</code></pre>
<p>The estimates of the within-mother effects were also reported under “Within effects” in table 3.2. The estimated coefficient of <code>smoke</code>, $\widehat \beta_{2}^{W}=-105$ grams, is dramatically smaller, in absolute value, than the corresponding ML estimate for the random-intercept model, $\widehat \beta_{2}^{\mathrm{ML}}=-218$ grams. The within-effect can be interpreted as the difference in mean birthweight between births for a given mother who changes smoking status between pregnancies, conditioning on the level-1 covariates. Level-2 covariates, whether observed or unobserved, are implicitly controlled for because mother is held constant in the comparison, along with all her characteristics. Therefore each mother truly serves as her own control.</p>
<p>Although $\beta_{1}$ is eliminated in the fixed-effects approach and there is no concept of a random-intercept standard deviation $\sqrt{\psi}$, the output from <strong><code>xtreg,fe</code></strong> provides estimates of both parameters ($2767.504$ next to <code>cons</code> and $440.05052$ next to <code>sigma_u</code>^{2}).</p>
<p>The original random-intercept model in (3.2) implicitly assumes that the between and within effects of the set of covariates that vary both between and within mothers are identical because the between-mother model (3.11) and the within-mother model (3.12) derived from the random-intercepts model (3.2) have the same regression coefficients, $\beta=(\beta_{1}, \beta_{2}, \ldots, \beta_{p})^{\prime}$. The estimators for the random-intercept model therefore use both within- and between-mother information. Not surprisingly therefore, the estimate of $\beta_{2}$ in the smoking-and-birthweight example lies between the within-effect estimate and between-effect estimate, $-105&gt;-218&gt;-286$.</p>
<p>这段话主要解释了固定效应模型和随机截距模型估计结果之间的差异，以及这些差异的意义。让我们一步步分析：</p>
<p><strong>1. 固定效应模型的估计结果</strong></p>
<p><strong>固定效应模型估计的“within-mother effects”（母亲内部效应）</strong>：</p>
<ul>
<li>在固定效应模型中，对于吸烟（<code>smoke</code>）的估计系数（$ \widehat \beta_{2}^{W}$）是 -105 克。这意味着，在控制了其他变量后，如果同一个母亲在不同怀孕期改变吸烟状态，她的孩子的平均出生体重预期会相差 105 克。</li>
</ul>
<p><strong>2. 随机截距模型的估计结果</strong></p>
<p><strong>随机截距模型的估计</strong>：</p>
<ul>
<li>随机截距模型给出的吸烟对孩子出生体重影响的估计（$\widehat \beta_{2}^{\mathrm{ML}}$）是 -218 克。这比固定效应模型的估计结果的绝对值要大。</li>
</ul>
<p><strong>3. 母亲内部效应的解释</strong></p>
<p><strong>母亲内部效应的含义</strong>：</p>
<ul>
<li>固定效应模型中的“within-mother effects”可以理解为，在考虑了一级协变量（level-1 covariates，即每次怀孕特有的协变量）后，对于同一个母亲在不同怀孕期改变吸烟状态的孩子们的平均出生体重的差异。</li>
<li>这种模型考虑了所有母亲特有的、在比较中保持不变的二级协变量（level-2 covariates），无论是观察到的还是未观察到的。因此，每个母亲都作为她自己的对照组。</li>
</ul>
<p><strong>4. 固定效应模型的参数估计</strong></p>
<p><strong>固定效应模型的参数</strong>：</p>
<ul>
<li>尽管在固定效应方法中消除了 $\beta_1$（模型的截距项），并且没有随机截距标准差（$\sqrt \psi$）的概念，<code>xtreg, fe</code>命令的输出还是提供了这两个参数的估计值：
<ul>
<li><code>cons</code>（常数项）旁边的值是 2767.504，这是在所有协变量为零时的预期出生体重。</li>
<li><code>sigma_u</code>² 旁边的值是 440.05052，这是不同母亲之间变异性的估计。</li>
</ul>
</li>
</ul>
<p><strong>5. 随机截距模型的假设</strong></p>
<p><strong>随机截距模型的假设</strong>：</p>
<ul>
<li>随机截距模型（3.2）隐含地假设在不同母亲之间和同一个母亲不同怀孕期内，协变量的效应是相同的，因为从随机截距模型（3.2）推导出的母亲间模型（3.11）和母亲内部模型（3.12）具有相同的回归系数 $\beta=(\beta_1, \beta_2, \ldots, \beta_p)^{\prime}$。</li>
<li>因此，随机截距模型的估计器使用了母亲之间和母亲内部的信息。</li>
</ul>
<p><strong>6. 吸烟对出生体重影响的估计值比较</strong></p>
<p><strong>吸烟对出生体重影响的估计值</strong>：</p>
<ul>
<li>
<p>在吸烟和出生体重的例子中，$\beta_2$ 的估计值介于母亲内部效应估计值和母亲间效应估计值之间，即 -105 &gt; -218 &gt; -286。</p>
</li>
<li>
<p>总结</p>
</li>
</ul>
<p>这段话说明了固定效应模型和随机截距模型在估计同一个协变量（如吸烟）对因变量（如出生体重）影响时的差异。固定效应模型只关注同一个母亲在不同怀孕期的变化，而随机截距模型同时考虑了不同母亲之间的差异以及同一个母亲在不同怀孕期的变化。<strong>因此，固定效应模型的估计结果通常更适用于评估协变量在个体内部变化的影响。</strong></p>
<h2 id="8-fixed-versus-random-effects-revisited">8 Fixed versus random effects revisited</h2>
<p>In section 2.8, we discussed whether the effects of clusters should be treated as random or fixed in models without covariates, and we revisit the issues involved in making this decision in table 3.3. We have previously argued that the decision depends on whether inferences are for the population of clusters or only for the clusters included in the sample. This appears as the first question in table 3.3.</p>
<figure style="text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/forest293/Hugo-image/2024.9.28.3.png" style="width:590px;height:630px;" alt="图片描述">
  <figcaption><strong></strong></figcaption>
</figure>
<p>To make inferences regarding the population of clusters (or the datagenerating mechanism for the clusters), the random-effects model must be used.</p>
<p>Turning to the next question in the table, the random-effects model allows estimation of coefficients of cluster-level covariates, unlike the fixed好的，以下是图片中的英文原文：
effects model. However, these inferences require a sufficient number of clusters and assumptions regarding the random-intercept distribution. The most important of these assumptions that is relaxed by the fixed-effects approach is level-2 exogeneity of level-1 covariates (lack of correlation between $\zeta_j$ and $\overline{x}_{j}$ or no cluster-level unobserved confounding). Another assumption made by the random-effects approach is that $\zeta_j$ has a constant variance $\psi$, although this assumption can be relaxed using robust standard errors if there are enough clusters. The standard assumption of a normal distribution for $\zeta_j$ is actually not required for consistent estimation of regression coefficients.</p>
<p>The main reason for using a fixed-effects approach is to estimate the within-cluster effects of covariates, free from bias due to unobserved cluster-level confounding. Although this endogeneity problem can be addressed using a random-effects model that also includes the cluster means of level-1 covariates, this approach yields inconsistent estimates of parameters pertaining to the between-cluster relationships. Fortunately, there is no endogeneity problem due to omitted covariates when estimating a treatment or intervention effect in a randomized experiment.</p>
<p>In section 2.10.3, we stressed that the standard error for the estimator of the mean $\beta$ in a random-effects model without covariates is for the population of clusters (allowing for random sampling of clusters), whereas the standard error in the corresponding fixed-effects model is for the particular clusters at hand. Generalization to the population of clusters is clearly a necessity for inferences regarding the coefficients of cluster-level covariates (which require a random-effects model). Should we worry about the standard errors from the fixed effects model because they pertain only to the clusters that happen to be in the sample? Not if the coefficients of the level-1 covariates are assumed to be identical across clusters (as they have been in this chapter). In this case, the same relationship is assumed to hold for other clusters not included in the sample and generalizes in that sense. We will see in the next chapter that the random-effect approach allows the assumption of identical within-cluster relationships to be relaxed by including random slopes.</p>
<p>While the cluster-specific intercepts are model parameters in the fixed-effects model and can be estimated via the dummy-variable approach, they are just random residuals in the random-effects model, and only their variance is estimated as a model parameter. However, the $c_{j}$ can be predicted by empirical Bayes (EB) after estimating the model parameters. If inference regarding the cluster-specific effects are of interest, cluster sizes should not be too small, and the random-effects approach performs better with small cluster sizes than the fixed-effects approach because of shrinkage or partial pooling as discussed in section 2.11.2.</p>
<p>For inferences regarding regression coefficients, there are no particular requirements regarding cluster sizes in either fixed or random-effects models. In fixed-effects models, singletons clusters (of size 1) provide no information on the regression coefficients ($\beta_2,\cdots,\beta_p$), and it makes no difference whether or not they are discarded. In contrast, it is important not to discard singleton clusters in random-effects models because they do provide some information on the regression coefficients and total residual variance. Singletons obviously provide no information on the decomposition of the total residual variance into $\psi$ and $\theta$.</p>
<p>The fixed-effects model is much less parsimonious than the random-intercept model because it includes one parameter $\alpha_j$ for each cluster, whereas the random-intercept model has only one parameter $\psi$ for the variance of the random intercepts $\xi_j$. Eliminating the $\alpha_j$ by mean centering, as shown in section 3.7.2, simplifies the estimation problem but does not make the estimates of the remaining parameters any more efficient.</p>
<p>As the cluster-size becomes large, the random effects estimators for the coefficients of level-1 covariates approach their fixed-effects counterparts, and the coefficients of level-2 covariates become consistent even under level-2 endogeneity of the level-1 covariates. Unfortunately, both the fixed-effects and random-effects models assume exogeneity of the covariates with respect to the level-1 residual $\epsilon_{ij}$ (level-1 exogeneity). It is not straightforward to check for level-1 endogeneity. To correct for level-1 endogeneity, external instrumental variables are usually required (see section 5.7).</p>
<p><strong>固定效应模型和随机效应模型的区别，以及它们在模型中处理群体（如学校、医院或母亲群体）效应时的应用</strong></p>
<h3 id="第一部分模型选择的决策">第一部分：模型选择的决策</h3>
<p><strong>是否将群体效应视为随机或固定</strong>：</p>
<ul>
<li>
<p>在没有协变量的模型中，决定是将群体效应视为随机还是固定，取决于推断的目标是针对群体总体还是仅针对样本中的群体。</p>
</li>
<li>
<p>如果目标是针对群体总体（或群体的数据生成机制），则必须使用随机效应模型。</p>
</li>
<li>
<p><strong>例子</strong>：假设你是一位教育研究员，想要研究不同学校的学生数学成绩。每个学校都有其独特的文化和教学方法，这可能会影响学生的成绩。如果你只关心从你研究的几所学校中得到的结果，那么固定效应模型可能更合适。但如果你想从这几所学校推断出所有学校的情况，那么随机效应模型将更适合。</p>
</li>
<li>
<p><strong>决策依据</strong>：选择哪种模型取决于你的目标。如果你的目标是推广到所有可能的学校（即群体总体），那么随机效应模型是必要的。</p>
</li>
</ul>
<h3 id="第二部分模型的特点和应用">第二部分：模型的特点和应用</h3>
<p><strong>随机效应模型</strong>：</p>
<ul>
<li>
<p>允许估计群体水平协变量的系数，这是固定效应模型所不允许的。</p>
</li>
<li>
<p>这些推断需要足够数量的群体，并假设随机截距分布的某些条件。最重要的假设是一级协变量的二级外生性（即 $\zeta_j$ 与 $\overline{x}_j$ 之间没有相关性，或者没有群体水平的未观测混杂因素）。</p>
</li>
<li>
<p>随机效应方法的另一个假设是 $\zeta_j$ 具有恒定的方差 $\psi$，但如果有足够的群体，即使使用稳健标准误差，这个假设也可以放宽。</p>
</li>
<li>
<p><strong>例子</strong>：继续上面的例子，随机效应模型就像你认为每所学校都有其独特的教学质量，但这些质量是随机分布的。你感兴趣的是学校类型（如公立或私立）如何普遍影响学生的成绩。</p>
</li>
<li>
<p><strong>特点</strong>：这种模型允许你估计学校特征（如学校类型）对学生成绩的影响，但它需要足够的学校数量，并假设这些学校是随机选取的。</p>
</li>
</ul>
<p><strong>固定效应模型</strong>：</p>
<ul>
<li>
<p>主要用于估计协变量在群体内部效应，不受未观测群体水平混杂因素的影响。</p>
</li>
<li>
<p>尽管可以通过包含群体平均数的随机效应模型来解决这种内生性问题，但这种方法会产生不一致的群体间关系的参数估计。</p>
</li>
<li>
<p><strong>例子</strong>：在同一个学校内，如果学校决定实施一种新的教学方法，固定效应模型可以帮助你了解这种变化如何影响学生的成绩，同时控制学校的独特因素。</p>
</li>
<li>
<p><strong>特点</strong>：这种模型专注于学校内部的变化，可以控制那些未观测到的学校特定因素。</p>
</li>
</ul>
<p><strong>实验中的处理效应</strong>：</p>
<ul>
<li>在随机实验中估计处理或干预效应时，由于忽略了协变量，因此不存在由于遗漏协变量而导致的内生性问题。</li>
</ul>
<p><strong>标准误差的解释</strong>：</p>
<ul>
<li>随机效应模型中的标准误差是针对群体总体的（允许群体的随机抽样），而固定效应模型中的标准误差是针对手头特定群体的。</li>
<li>如果假设一级协变量的系数在群体间是相同的（如本章所讨论的），则不需要担心固定效应模型的标准误差仅针对样本中的群体。在这种情况下，相同的关系被假设适用于未包含在样本中的其他群体，并且在这种意义上具有普遍性。</li>
</ul>
<p><strong>模型参数</strong>：</p>
<ul>
<li>在固定效应模型中，群体特定的截距是模型参数，可以通过虚拟变量方法估计。</li>
<li>在随机效应模型中，这些截距只是随机残差，只有它们的方差被估计为模型参数。</li>
</ul>
<p><strong>模型的简洁性</strong>：</p>
<ul>
<li>固定效应模型比随机截距模型更不简洁，因为它为每个群体包含一个参数 $\alpha_j$，而随机截距模型只有一个参数 $\psi$ 用于随机截距的方差。</li>
<li><strong>例子</strong>：固定效应模型可能会变得复杂，因为它需要为每所学校估计一个特定的效应。相比之下，随机效应模型只需要估计随机效应的方差，这使得模型更简单。</li>
</ul>
<p><strong>群体大小的影响</strong>：</p>
<ul>
<li>
<p>随着群体大小的增加，随机效应模型中一级协变量系数的估计值接近其固定效应对应值，即使在一级协变量的二级内生性下，二级协变量的系数也变得一致。</p>
</li>
<li>
<p>不幸的是，固定效应和随机效应模型都假设协变量与一级残差 $\epsilon_{ij}$ 无关（一级外生性）。检查一级内生性并不直接。为了纠正一级内生性，通常需要外部工具变量。</p>
</li>
<li>
<p><strong>例子</strong>：如果你的数据中只有少数几所学校，随机效应模型可能不会很有效，因为它需要足够的群体数量来准确估计随机效应的分布。在这种情况下，固定效应模型可能更合适。</p>
</li>
<li>
<p><strong>选择依据</strong>：如果你的数据集中群体数量较少，或者你只关心这些特定的群体，固定效应模型可能更合适。</p>
</li>
</ul>
<h3 id="第三部分模型选择的具体应用">第三部分：模型选择的具体应用</h3>
<p><strong>随机效应模型的应用</strong>：</p>
<ul>
<li>当我们想要从样本中的群体推广到群体总体时，随机效应模型是合适的。</li>
<li>如果我们对群体水平的协变量如何影响群体内部的个体感兴趣，随机效应模型可以提供这种估计。</li>
</ul>
<p><strong>固定效应模型的应用</strong>：</p>
<ul>
<li>如果我们只对样本中的特定群体内的变化感兴趣，并且我们担心存在未观测到的群体水平的混杂因素，那么固定效应模型是更好的选择。</li>
<li>固定效应模型通过为每个群体分配一个固定的截距，可以控制所有时间不变的群体特定效应。</li>
</ul>
<h3 id="第四部分模型的比较和选择">第四部分：模型的比较和选择</h3>
<p><strong>群体大小的影响</strong>：</p>
<ul>
<li>在固定效应模型中，如果群体大小为1（即只包含一个观测值的群体），那么这个群体对于估计回归系数没有提供任何信息，可以丢弃它们而不影响估计结果。</li>
<li>相比之下，在随机效应模型中，即使是大小为1的群体也提供了关于回归系数和总残差方差的一些信息，因此不应丢弃这些群体。</li>
</ul>
<p><strong>模型的简洁性</strong>：</p>
<ul>
<li>固定效应模型由于为每个群体估计一个参数，因此模型较为复杂。</li>
<li>随机效应模型通常更为简洁，因为它只估计随机截距的方差这一个参数。</li>
</ul>
<p><strong>模型的效率</strong>：</p>
<ul>
<li>通过均值中心化可以简化固定效应模型的估计问题，但这并不会提高剩余参数的估计效率。</li>
<li>随着群体大小的增加，随机效应模型的估计量会逐渐接近固定效应模型的估计量。</li>
</ul>
<p><strong>模型的假设</strong>：</p>
<ul>
<li>两种模型都假设协变量与一级残差（$\epsilon_{ij}$）不相关（一级外生性）。</li>
<li>如果存在一级内生性问题，通常需要使用外部工具变量来纠正。</li>
</ul>
<h3 id="第五部分模型的预测和应用">第五部分：模型的预测和应用</h3>
<p><strong>预测</strong>：</p>
<ul>
<li><strong>固定效应模型</strong>：可以通过为每个群体分配一个特定的截距来进行预测。</li>
<li><strong>随机效应模型</strong>：可以通过估计随机截距的分布来进行预测。</li>
</ul>
<p><strong>应用</strong>：</p>
<ul>
<li><strong>固定效应模型</strong>：适用于政策评估、处理效应分析等，特别是当我们有理由相信群体特定效应可能会影响结果时。</li>
<li><strong>随机效应模型</strong>：适用于多层次模型、群体随机试验等，特别是当我们想要从样本推广到总体时。</li>
</ul>
<p><strong>预测</strong>：</p>
<ul>
<li><strong>例子</strong>：如果你使用固定效应模型发现实施新教学方法可以提高成绩，你可以预测在这所学校实施这种方法将如何影响学生。随机效应模型可以帮助你预测这种效果在其他学校的可能性。</li>
<li><strong>应用</strong>：固定效应模型适用于当你想要控制特定群体的所有独特因素时，而随机效应模型适用于当你想要从样本推广到总体时。</li>
</ul>
<h3 id="第六部分模型的选择和实际操作">第六部分：模型的选择和实际操作</h3>
<p><strong>实际操作</strong>：</p>
<ul>
<li><strong>固定效应模型</strong>：可以通过创建虚拟变量或使用特定估计技术来实现。</li>
<li><strong>随机效应模型</strong>：可以通过最大似然估计或贝叶斯方法来实现。</li>
</ul>
<p><strong>选择建议</strong>：</p>
<ul>
<li>
<p>考虑研究设计、数据结构、群体大小和研究目标。</p>
</li>
<li>
<p>考虑模型的假设和限制，以及是否需要对未观测到的混杂因素进行调整。</p>
</li>
<li>
<p><strong>例子</strong>：在实际操作中，固定效应模型可以通过创建虚拟变量（比如为每所学校一个变量）来实现。随机效应模型通常需要更复杂的统计软件来估计。</p>
</li>
<li>
<p><strong>选择建议</strong>：选择哪种模型取决于你的数据结构、研究目标和对模型假设的舒适度。</p>
</li>
</ul>
<h3 id="实际应用中的考虑">实际应用中的考虑</h3>
<ol>
<li>
<p><strong>数据结构</strong>：如果群体内部的变异性很大，而群体之间的变异性相对较小，固定效应模型可能更合适。如果群体之间的变异性很大，随机效应模型可能更合适。</p>
</li>
<li>
<p><strong>推断目标</strong>：如果目标是进行群体间的比较，随机效应模型可能更合适。如果目标是研究群体内的变化，固定效应模型可能更合适。</p>
</li>
<li>
<p><strong>群体大小</strong>：如果群体很小，随机效应模型可能由于收缩效应（shrinkage）或部分汇总（partial pooling）而表现更好。</p>
</li>
<li>
<p><strong>模型假设</strong>：如果对随机截距的分布有明确假设，随机效应模型可能更合适。如果没有这些假设，或者担心群体特定的效应可能与协变量相关，固定效应模型可能更合适。</p>
</li>
</ol>
<h3 id="总结-1">总结</h3>
<p>选择固定效应模型还是随机效应模型取决于研究的具体目标、数据结构、以及对模型假设的考虑。在实际应用中，可能需要尝试不同的模型，并比较它们的估计结果和解释能力。</p>
<h3 id="11-summary">11 Summary</h3>
<p>We discussed linear random-intercept models, which are important for investigating the relationship between a continuous response and a set of covariates when the data have a clustered or hierarchical structure. Topics included hypothesis testing, different kinds of coefficients of determination, the choice between fixed- and random-effects approaches, model diagnostics, consequences of using standard regression for clustered data, and power and sample-size determination.</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2024-09-29</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/chapter-3-random-intercept-models-with-covariates/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/multilevel-longitudinal-models/">Multilevel &amp; Longitudinal Models</a>,&nbsp;<a href="/tags/stata/">stata</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/chapter-2-variance-components-models/" class="prev" rel="prev" title="[Multilevel  Longitudinal Models] Chapter 2 ：Variance-components models"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>[Multilevel  Longitudinal Models] Chapter 2 ：Variance-components models</a>
            <a href="/4.chapter-4-random-coefficient-models/" class="next" rel="next" title="[Multilevel  Longitudinal Models] Chapter 4 - Random-coefficient models">[Multilevel  Longitudinal Models] Chapter 4 - Random-coefficient models<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2023 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Alex_Wang</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"valine":{"appId":"QGzwQXOqs5JOhN4RGPOkR2mR-MdYXbMMI","appKey":"WBmoGyJtbqUswvfLh6L8iEBr","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"zh-CN","pageSize":10,"placeholder":"你的评论 ...","recordIP":true,"serverURLs":"https://leancloud.hugoloveit.com","visitor":true}},"lightgallery":true,"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
